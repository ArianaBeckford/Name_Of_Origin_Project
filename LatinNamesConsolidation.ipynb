{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was originally for frequency distributions for Latin names!\n",
    "but we can also concat the other dfs / do model training after in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo = pd.read_csv('df_indo.csv')\n",
    "df_malay = pd.read_csv('df_malay.csv')\n",
    "df_viet = pd.read_csv('viet_df.csv')\n",
    "df_cnrom = pd.read_csv('cnrom_df.csv')\n",
    "df_cnchar = pd.read_csv('cnchar_df.csv')\n",
    "# also import other dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names to KEEP: (10 so far)\n",
    "\n",
    "* name_length\n",
    "* avg_token_length\n",
    "* num_tokens\n",
    "* period_freq\n",
    "* dash_freq\n",
    "* apostrophe_freq\n",
    "* space_freq\n",
    "* unigrams_cosine_sim\n",
    "* bigrams_cosine_sim\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding what columns r in viet that aren't in indo\n",
    "# print(df_indo.columns)\n",
    "# print(df_viet.columns)\n",
    "# [col for col in df_viet.columns if col not in df_indo.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk if i can generalize this lol\n",
    "# def rename_columns(df_ref, df_to_change):\n",
    "#     diff_cols = [col for col in df_to_change.columns if col not in df_ref.columns]\n",
    "#     new_names = \n",
    "#     df_to_change.rename(columns = {oldName : newName})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where you rename columns to all match\n",
    "df_viet.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnrom.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnchar.rename(columns = {'word_length': 'name_length'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Keeping numerical columns only for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO FOR EACH DATASET\n",
    "# # dropping non-numerical columns - this is why it would be good to have more numerical features since we don't have a lot\n",
    "# df_indo = df_indo.select_dtypes(exclude = 'object')\n",
    "# # df_indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DROP FOR WHOLE DATASET\n",
    "# # dropping trigrams for indo and malay\n",
    "# df_indo.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "# df_malay.drop('trigrams_cosine_sim', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean up viet / other dfs before combining\n",
    "# df_viet.drop('trigrams', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adding the language (label) to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo['language'] = 'Indonesian'\n",
    "df_malay['language'] = 'Malay'\n",
    "df_viet['language'] = 'Vietnamese'\n",
    "df_cnrom['language'] = 'Chinese (Romanized)'\n",
    "df_cnchar['language'] = 'Chinese (Characters)'\n",
    "# df_indo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining all names to make one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>indiv_trigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supriyadi</td>\n",
       "      <td>Supriyadi</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i']</td>\n",
       "      <td>[('s', 'u'), ('u', 'p'), ('p', 'r'), ('r', 'i'...</td>\n",
       "      <td>[('s', 'u', 'p'), ('u', 'p', 'r'), ('p', 'r', ...</td>\n",
       "      <td>['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i', ...</td>\n",
       "      <td>['supriyadi']</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triyaningsih</td>\n",
       "      <td>Triyaningsih</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...</td>\n",
       "      <td>[('t', 'r'), ('r', 'i'), ('i', 'y'), ('y', 'a'...</td>\n",
       "      <td>[('t', 'r', 'i'), ('r', 'i', 'y'), ('i', 'y', ...</td>\n",
       "      <td>['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...</td>\n",
       "      <td>['triyaningsih']</td>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soerjadi</td>\n",
       "      <td>Soerjadi</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i']</td>\n",
       "      <td>[('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'j'...</td>\n",
       "      <td>[('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i', ('s',...</td>\n",
       "      <td>['soerjadi']</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.    0.    0.    0.    0.    0.125 0.    0....</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0.090295</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undunsyah</td>\n",
       "      <td>Undunsyah</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h']</td>\n",
       "      <td>[('u', 'n'), ('n', 'd'), ('d', 'u'), ('u', 'n'...</td>\n",
       "      <td>[('u', 'n', 'd'), ('n', 'd', 'u'), ('d', 'u', ...</td>\n",
       "      <td>['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h', ...</td>\n",
       "      <td>['undunsyah']</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.060083</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soeripto</td>\n",
       "      <td>Soeripto</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'i', 'p', 't', 'o']</td>\n",
       "      <td>[('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'i'...</td>\n",
       "      <td>[('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'i', 'p', 't', 'o', ('s',...</td>\n",
       "      <td>['soeripto']</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.    0.    0.    0.    0.    0.    0.    0....</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>龚翔宇</td>\n",
       "      <td>['CJK', 'CJK', 'CJK']</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('x',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.15384615 0.07692308 0.         0.         ...</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844943</td>\n",
       "      <td>0.665759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>龚育之</td>\n",
       "      <td>['CJK', 'CJK', 'CJK']</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'y', 'u', ' ', 'z', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('y',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.18181818 0.         0.         0.         ...</td>\n",
       "      <td>[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.501902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>龚蓓苾</td>\n",
       "      <td>['CJK', 'CJK', 'CJK']</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'b', 'e', 'i', ' ', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('b',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.18181818 0.         0.18181818 0.         ...</td>\n",
       "      <td>[[0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.729526</td>\n",
       "      <td>0.363754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>龚贤永</td>\n",
       "      <td>['CJK', 'CJK', 'CJK']</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('x',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.14285714 0.07142857 0.         0.         ...</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>0.637316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>龚鼎</td>\n",
       "      <td>['CJK', 'CJK']</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'd', 'i', 'n', 'g']</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('d',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.11111111 0.         0.         0.         ...</td>\n",
       "      <td>[[0.    0.    0.    0.    0.125 0.    0.    0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688529</td>\n",
       "      <td>0.522372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37977 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fullname original_fullname  \\\n",
       "0         supriyadi         Supriyadi   \n",
       "1      triyaningsih      Triyaningsih   \n",
       "2          soerjadi          Soerjadi   \n",
       "3         undunsyah         Undunsyah   \n",
       "4          soeripto          Soeripto   \n",
       "...             ...               ...   \n",
       "37972           NaN               龚翔宇   \n",
       "37973           NaN               龚育之   \n",
       "37974           NaN               龚蓓苾   \n",
       "37975           NaN               龚贤永   \n",
       "37976           NaN                龚鼎   \n",
       "\n",
       "                                                alphabet  \\\n",
       "0      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "1      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "2      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "3      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "4      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "...                                                  ...   \n",
       "37972                              ['CJK', 'CJK', 'CJK']   \n",
       "37973                              ['CJK', 'CJK', 'CJK']   \n",
       "37974                              ['CJK', 'CJK', 'CJK']   \n",
       "37975                              ['CJK', 'CJK', 'CJK']   \n",
       "37976                                     ['CJK', 'CJK']   \n",
       "\n",
       "                                                unigrams  \\\n",
       "0          ['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i']   \n",
       "1      ['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...   \n",
       "2               ['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i']   \n",
       "3          ['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h']   \n",
       "4               ['s', 'o', 'e', 'r', 'i', 'p', 't', 'o']   \n",
       "...                                                  ...   \n",
       "37972  ['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...   \n",
       "37973  ['g', 'o', 'n', 'g', ' ', 'y', 'u', ' ', 'z', ...   \n",
       "37974  ['g', 'o', 'n', 'g', ' ', 'b', 'e', 'i', ' ', ...   \n",
       "37975  ['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...   \n",
       "37976      ['g', 'o', 'n', 'g', ' ', 'd', 'i', 'n', 'g']   \n",
       "\n",
       "                                                 bigrams  \\\n",
       "0      [('s', 'u'), ('u', 'p'), ('p', 'r'), ('r', 'i'...   \n",
       "1      [('t', 'r'), ('r', 'i'), ('i', 'y'), ('y', 'a'...   \n",
       "2      [('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'j'...   \n",
       "3      [('u', 'n'), ('n', 'd'), ('d', 'u'), ('u', 'n'...   \n",
       "4      [('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'i'...   \n",
       "...                                                  ...   \n",
       "37972  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37973  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37974  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37975  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37976  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "\n",
       "                                                trigrams  \\\n",
       "0      [('s', 'u', 'p'), ('u', 'p', 'r'), ('p', 'r', ...   \n",
       "1      [('t', 'r', 'i'), ('r', 'i', 'y'), ('i', 'y', ...   \n",
       "2      [('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...   \n",
       "3      [('u', 'n', 'd'), ('n', 'd', 'u'), ('d', 'u', ...   \n",
       "4      [('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...   \n",
       "...                                                  ...   \n",
       "37972  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37973  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37974  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37975  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37976  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "\n",
       "                                             char_ngrams       word_ngrams  \\\n",
       "0      ['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i', ...     ['supriyadi']   \n",
       "1      ['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...  ['triyaningsih']   \n",
       "2      ['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i', ('s',...      ['soerjadi']   \n",
       "3      ['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h', ...     ['undunsyah']   \n",
       "4      ['s', 'o', 'e', 'r', 'i', 'p', 't', 'o', ('s',...      ['soeripto']   \n",
       "...                                                  ...               ...   \n",
       "37972  [('g',), ('o',), ('n',), ('g',), (' ',), ('x',...               NaN   \n",
       "37973  [('g',), ('o',), ('n',), ('g',), (' ',), ('y',...               NaN   \n",
       "37974  [('g',), ('o',), ('n',), ('g',), (' ',), ('b',...               NaN   \n",
       "37975  [('g',), ('o',), ('n',), ('g',), (' ',), ('x',...               NaN   \n",
       "37976  [('g',), ('o',), ('n',), ('g',), (' ',), ('d',...               NaN   \n",
       "\n",
       "       name_length  avg_token_length  ...  dash_freq apostrophe_freq  \\\n",
       "0                9          9.000000  ...          0               0   \n",
       "1               12         12.000000  ...          0               0   \n",
       "2                8          8.000000  ...          0               0   \n",
       "3                9          9.000000  ...          0               0   \n",
       "4                8          8.000000  ...          0               0   \n",
       "...            ...               ...  ...        ...             ...   \n",
       "37972           13          3.666667  ...          0               0   \n",
       "37973           11          3.000000  ...          0               0   \n",
       "37974           11          3.000000  ...          0               0   \n",
       "37975           14          4.000000  ...          0               0   \n",
       "37976            9          4.000000  ...          0               0   \n",
       "\n",
       "       space_freq                               indiv_unigrams_fdist  \\\n",
       "0               0  [[0.         0.         0.         0.         ...   \n",
       "1               0  [[0.         0.         0.         0.         ...   \n",
       "2               0  [[0.    0.    0.    0.    0.    0.125 0.    0....   \n",
       "3               0  [[0.         0.         0.         0.         ...   \n",
       "4               0  [[0.    0.    0.    0.    0.    0.    0.    0....   \n",
       "...           ...                                                ...   \n",
       "37972           2  [[0.15384615 0.07692308 0.         0.         ...   \n",
       "37973           2  [[0.18181818 0.         0.         0.         ...   \n",
       "37974           2  [[0.18181818 0.         0.18181818 0.         ...   \n",
       "37975           2  [[0.14285714 0.07142857 0.         0.         ...   \n",
       "37976           1  [[0.11111111 0.         0.         0.         ...   \n",
       "\n",
       "                                     indiv_bigrams_fdist  \\\n",
       "0                              [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "1                              [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "2                              [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "3                              [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "4                              [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "...                                                  ...   \n",
       "37972  [[0.         0.         0.         0.         ...   \n",
       "37973  [[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  ...   \n",
       "37974  [[0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  ...   \n",
       "37975  [[0.         0.         0.         0.         ...   \n",
       "37976  [[0.    0.    0.    0.    0.125 0.    0.    0....   \n",
       "\n",
       "            indiv_trigrams_fdist unigrams_cosine_sim bigrams_cosine_sim  \\\n",
       "0      [[0. 0. 0. ... 0. 0. 0.]]            0.664809           0.250640   \n",
       "1      [[0. 0. 0. ... 0. 0. 0.]]            0.686625           0.353292   \n",
       "2      [[0. 0. 0. ... 0. 0. 0.]]            0.688312           0.197139   \n",
       "3      [[0. 0. 0. ... 0. 0. 0.]]            0.581396           0.155386   \n",
       "4      [[0. 0. 0. ... 0. 0. 0.]]            0.463215           0.176917   \n",
       "...                          ...                 ...                ...   \n",
       "37972                        NaN            0.844943           0.665759   \n",
       "37973                        NaN            0.837370           0.501902   \n",
       "37974                        NaN            0.729526           0.363754   \n",
       "37975                        NaN            0.808012           0.637316   \n",
       "37976                        NaN            0.688529           0.522372   \n",
       "\n",
       "      trigrams_cosine_sim              language  \n",
       "0                0.085949            Indonesian  \n",
       "1                0.117226            Indonesian  \n",
       "2                0.090295            Indonesian  \n",
       "3                0.060083            Indonesian  \n",
       "4                0.052811            Indonesian  \n",
       "...                   ...                   ...  \n",
       "37972                 NaN  Chinese (Characters)  \n",
       "37973                 NaN  Chinese (Characters)  \n",
       "37974                 NaN  Chinese (Characters)  \n",
       "37975                 NaN  Chinese (Characters)  \n",
       "37976                 NaN  Chinese (Characters)  \n",
       "\n",
       "[37977 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see from output, we need the columns in the concatenated df (in this case, viet) to match\n",
    "# it's okay if some values are NaN bc we'll drop all non-numerical columns anyway\n",
    "merged_df = pd.concat([df_indo, df_malay, df_viet, df_cnrom, df_cnchar], ignore_index = True, join = 'outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Keeping numerical columns only for each dataset (Same process as step 4, except we don't have to repeat lines of code...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37972</th>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844943</td>\n",
       "      <td>0.665759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37973</th>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.501902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37974</th>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.729526</td>\n",
       "      <td>0.363754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>14</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>0.637316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37976</th>\n",
       "      <td>9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688529</td>\n",
       "      <td>0.522372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37977 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0                9          9.000000           1            0          0   \n",
       "1               12         12.000000           1            0          0   \n",
       "2                8          8.000000           1            0          0   \n",
       "3                9          9.000000           1            0          0   \n",
       "4                8          8.000000           1            0          0   \n",
       "...            ...               ...         ...          ...        ...   \n",
       "37972           13          3.666667           3            0          0   \n",
       "37973           11          3.000000           3            0          0   \n",
       "37974           11          3.000000           3            0          0   \n",
       "37975           14          4.000000           3            0          0   \n",
       "37976            9          4.000000           2            0          0   \n",
       "\n",
       "       apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \n",
       "0                    0           0             0.664809            0.250640  \n",
       "1                    0           0             0.686625            0.353292  \n",
       "2                    0           0             0.688312            0.197139  \n",
       "3                    0           0             0.581396            0.155386  \n",
       "4                    0           0             0.463215            0.176917  \n",
       "...                ...         ...                  ...                 ...  \n",
       "37972                0           2             0.844943            0.665759  \n",
       "37973                0           2             0.837370            0.501902  \n",
       "37974                0           2             0.729526            0.363754  \n",
       "37975                0           2             0.808012            0.637316  \n",
       "37976                0           1             0.688529            0.522372  \n",
       "\n",
       "[37977 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df.select_dtypes(exclude = 'object')\n",
    "merged_df.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Clean up columns so we can combine dataframes into one (focus on making an all-Latin dataset first)\n",
    "    - do not combine in this step\n",
    "2. Frequency distributions for Latin names -> redo\n",
    "3. Add a_hat_freq\n",
    "4. Only keep numerical columns\n",
    "    - turn some categorical features -> numerical so we have more things to feed into model\n",
    "5. Add in label (language) for each dataset\n",
    "6. Combine Latin and non-Latin names to make one big dataset\n",
    "    - may need to repeat some of the above steps for non-Latin names\n",
    "7. Train test split\n",
    "8. MODEL TRAINING!\n",
    "9. Model evaluation\n",
    "\n",
    "Reminder:\n",
    "- We decided to keep period_freq, dash_freq, apostrophe_freq for now. After our first run of model training, we can remove them to see if it improves the performance\n",
    "\n",
    "**You can work on these steps out of order** (act as if the previous steps r there), but in the end we ideally want all of these steps implemented in this order.\n",
    "\n",
    "For example, you could write the code for model training and train the model on one or a few datasets. Later on, we'll just replace the variables you used with the ones containing all the languages/names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
