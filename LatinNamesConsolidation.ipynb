{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was originally for frequency distributions for Latin names!\n",
    "but we can also concat the other dfs / do model training after in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo = pd.read_csv('df_indo.csv')\n",
    "df_malay = pd.read_csv('df_malay.csv')\n",
    "df_viet = pd.read_csv('viet_df.csv')\n",
    "df_cnrom = pd.read_csv('cnrom_df.csv')\n",
    "df_cnchar = pd.read_csv('cnchar_df.csv')\n",
    "df_turk = pd.read_csv(\"turkish_df.csv\")\n",
    "#df_korean = pd.read_csv(\"korean_df.csv\") (Have to fix)\n",
    "# also import other dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names to KEEP: (10 so far)\n",
    "\n",
    "* name_length\n",
    "* avg_token_length\n",
    "* num_tokens\n",
    "* period_freq\n",
    "* dash_freq\n",
    "* apostrophe_freq\n",
    "* space_freq\n",
    "* unigrams_cosine_sim\n",
    "* bigrams_cosine_sim\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding what columns r in viet that aren't in indo\n",
    "# print(df_indo.columns)\n",
    "# print(df_viet.columns)\n",
    "# [col for col in df_viet.columns if col not in df_indo.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk if i can generalize this lol\n",
    "# def rename_columns(df_ref, df_to_change):\n",
    "#     diff_cols = [col for col in df_to_change.columns if col not in df_ref.columns]\n",
    "#     new_names = \n",
    "#     df_to_change.rename(columns = {oldName : newName})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where you rename columns to all match\n",
    "df_viet.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnrom.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnchar.rename(columns = {'word_length': 'name_length'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Keeping numerical columns only for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DO FOR EACH DATASET\n",
    "# # dropping non-numerical columns - this is why it would be good to have more numerical features since we don't have a lot\n",
    "# df_indo = df_indo.select_dtypes(exclude = 'object')\n",
    "# # df_indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DROP FOR WHOLE DATASET\n",
    "# # dropping trigrams for indo and malay\n",
    "# df_indo.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "# df_malay.drop('trigrams_cosine_sim', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean up viet / other dfs before combining\n",
    "# df_viet.drop('trigrams', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adding the language (label) to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo['language'] = 'Indonesian'\n",
    "df_malay['language'] = 'Malay'\n",
    "df_viet['language'] = 'Vietnamese'\n",
    "df_cnrom['language'] = 'Chinese (Romanized)'\n",
    "df_cnchar['language'] = 'Chinese (Characters)'\n",
    "df_turk['language'] = 'Turkish'\n",
    "#df_korean['language'] = 'Korean (Romanized & Characters)'  Have to fix\n",
    "# df_indo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining all names to make one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>indiv_trigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>label_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supriyadi</td>\n",
       "      <td>Supriyadi</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i']</td>\n",
       "      <td>[('s', 'u'), ('u', 'p'), ('p', 'r'), ('r', 'i'...</td>\n",
       "      <td>[('s', 'u', 'p'), ('u', 'p', 'r'), ('p', 'r', ...</td>\n",
       "      <td>['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i', ...</td>\n",
       "      <td>['supriyadi']</td>\n",
       "      <td>9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triyaningsih</td>\n",
       "      <td>Triyaningsih</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...</td>\n",
       "      <td>[('t', 'r'), ('r', 'i'), ('i', 'y'), ('y', 'a'...</td>\n",
       "      <td>[('t', 'r', 'i'), ('r', 'i', 'y'), ('i', 'y', ...</td>\n",
       "      <td>['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...</td>\n",
       "      <td>['triyaningsih']</td>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soerjadi</td>\n",
       "      <td>Soerjadi</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i']</td>\n",
       "      <td>[('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'j'...</td>\n",
       "      <td>[('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i', ('s',...</td>\n",
       "      <td>['soerjadi']</td>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.    0.    0.    0.    0.    0.125 0.    0....</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0.090295</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undunsyah</td>\n",
       "      <td>Undunsyah</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h']</td>\n",
       "      <td>[('u', 'n'), ('n', 'd'), ('d', 'u'), ('u', 'n'...</td>\n",
       "      <td>[('u', 'n', 'd'), ('n', 'd', 'u'), ('d', 'u', ...</td>\n",
       "      <td>['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h', ...</td>\n",
       "      <td>['undunsyah']</td>\n",
       "      <td>9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.060083</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soeripto</td>\n",
       "      <td>Soeripto</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'i', 'p', 't', 'o']</td>\n",
       "      <td>[('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'i'...</td>\n",
       "      <td>[('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...</td>\n",
       "      <td>['s', 'o', 'e', 'r', 'i', 'p', 't', 'o', ('s',...</td>\n",
       "      <td>['soeripto']</td>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.    0.    0.    0.    0.    0.    0.    0....</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56009</th>\n",
       "      <td>nil i̇pek hülagü öztürkmen</td>\n",
       "      <td>Nil İpek Hülagü Öztürkmen</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>['n', 'i', 'l', ' ', 'i', '̇', 'p', 'e', 'k', ...</td>\n",
       "      <td>[('n', 'i'), ('i', 'l'), ('l', ' '), (' ', 'i'...</td>\n",
       "      <td>[('n', 'i', 'l'), ('i', 'l', ' '), ('l', ' ', ...</td>\n",
       "      <td>['n', 'i', 'l', ' ', 'i', '̇', 'p', 'e', 'k', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11538462 0.         0.         0.03846154 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.766280</td>\n",
       "      <td>0.250772</td>\n",
       "      <td>0.100388</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>http://www.wikidata.org/entity/Q49703809</td>\n",
       "      <td>Nil İpek Hülagü Öztürkmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56010</th>\n",
       "      <td>fatma betül sayan kaya</td>\n",
       "      <td>Fatma Betül Sayan Kaya</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>['f', 'a', 't', 'm', 'a', ' ', 'b', 'e', 't', ...</td>\n",
       "      <td>[('f', 'a'), ('a', 't'), ('t', 'm'), ('m', 'a'...</td>\n",
       "      <td>[('f', 'a', 't'), ('a', 't', 'm'), ('t', 'm', ...</td>\n",
       "      <td>['f', 'a', 't', 'm', 'a', ' ', 'b', 'e', 't', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>4.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.13636364 0.         0.         0.27272727 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.812166</td>\n",
       "      <td>0.453787</td>\n",
       "      <td>0.210581</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>http://www.wikidata.org/entity/Q24230049</td>\n",
       "      <td>Fatma Betül Sayan Kaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56011</th>\n",
       "      <td>elif nur bozkurt tandoğan</td>\n",
       "      <td>Elif Nur Bozkurt Tandoğan</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>['e', 'l', 'i', 'f', ' ', 'n', 'u', 'r', ' ', ...</td>\n",
       "      <td>[('e', 'l'), ('l', 'i'), ('i', 'f'), ('f', ' '...</td>\n",
       "      <td>[('e', 'l', 'i'), ('l', 'i', 'f'), ('i', 'f', ...</td>\n",
       "      <td>['e', 'l', 'i', 'f', ' ', 'n', 'u', 'r', ' ', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.12 0.   0.   0.08 0.04 0.   0.04 0.04 0.04...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.820321</td>\n",
       "      <td>0.366293</td>\n",
       "      <td>0.123383</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6053953</td>\n",
       "      <td>Elif Nur Bozkurt Tandoğan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56012</th>\n",
       "      <td>muhammed ali fatih erbakan</td>\n",
       "      <td>Muhammed Ali Fatih Erbakan</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>['m', 'u', 'h', 'a', 'm', 'm', 'e', 'd', ' ', ...</td>\n",
       "      <td>[('m', 'u'), ('u', 'h'), ('h', 'a'), ('a', 'm'...</td>\n",
       "      <td>[('m', 'u', 'h'), ('u', 'h', 'a'), ('h', 'a', ...</td>\n",
       "      <td>['m', 'u', 'h', 'a', 'm', 'm', 'e', 'd', ' ', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.11538462 0.         0.         0.19230769 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.462341</td>\n",
       "      <td>0.148177</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6085044</td>\n",
       "      <td>Muhammed Ali Fatih Erbakan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56013</th>\n",
       "      <td>vedat ali özkan kayacı</td>\n",
       "      <td>Vedat Ali Özkan Kayacı</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>['v', 'e', 'd', 'a', 't', ' ', 'a', 'l', 'i', ...</td>\n",
       "      <td>[('v', 'e'), ('e', 'd'), ('d', 'a'), ('a', 't'...</td>\n",
       "      <td>[('v', 'e', 'd'), ('e', 'd', 'a'), ('d', 'a', ...</td>\n",
       "      <td>['v', 'e', 'd', 'a', 't', ' ', 'a', 'l', 'i', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>4.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.13636364 0.         0.         0.22727273 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.828399</td>\n",
       "      <td>0.489544</td>\n",
       "      <td>0.313943</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6071196</td>\n",
       "      <td>Vedat Ali Özkan Kayacı</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56014 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fullname           original_fullname  \\\n",
       "0                       supriyadi                   Supriyadi   \n",
       "1                    triyaningsih                Triyaningsih   \n",
       "2                        soerjadi                    Soerjadi   \n",
       "3                       undunsyah                   Undunsyah   \n",
       "4                        soeripto                    Soeripto   \n",
       "...                           ...                         ...   \n",
       "56009  nil i̇pek hülagü öztürkmen   Nil İpek Hülagü Öztürkmen   \n",
       "56010      fatma betül sayan kaya      Fatma Betül Sayan Kaya   \n",
       "56011   elif nur bozkurt tandoğan   Elif Nur Bozkurt Tandoğan   \n",
       "56012  muhammed ali fatih erbakan  Muhammed Ali Fatih Erbakan   \n",
       "56013      vedat ali özkan kayacı      Vedat Ali Özkan Kayacı   \n",
       "\n",
       "                                                alphabet  \\\n",
       "0      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "1      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "2      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "3      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "4      ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "...                                                  ...   \n",
       "56009                                              LATIN   \n",
       "56010                                              LATIN   \n",
       "56011                                              LATIN   \n",
       "56012                                              LATIN   \n",
       "56013                                              LATIN   \n",
       "\n",
       "                                                unigrams  \\\n",
       "0          ['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i']   \n",
       "1      ['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...   \n",
       "2               ['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i']   \n",
       "3          ['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h']   \n",
       "4               ['s', 'o', 'e', 'r', 'i', 'p', 't', 'o']   \n",
       "...                                                  ...   \n",
       "56009  ['n', 'i', 'l', ' ', 'i', '̇', 'p', 'e', 'k', ...   \n",
       "56010  ['f', 'a', 't', 'm', 'a', ' ', 'b', 'e', 't', ...   \n",
       "56011  ['e', 'l', 'i', 'f', ' ', 'n', 'u', 'r', ' ', ...   \n",
       "56012  ['m', 'u', 'h', 'a', 'm', 'm', 'e', 'd', ' ', ...   \n",
       "56013  ['v', 'e', 'd', 'a', 't', ' ', 'a', 'l', 'i', ...   \n",
       "\n",
       "                                                 bigrams  \\\n",
       "0      [('s', 'u'), ('u', 'p'), ('p', 'r'), ('r', 'i'...   \n",
       "1      [('t', 'r'), ('r', 'i'), ('i', 'y'), ('y', 'a'...   \n",
       "2      [('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'j'...   \n",
       "3      [('u', 'n'), ('n', 'd'), ('d', 'u'), ('u', 'n'...   \n",
       "4      [('s', 'o'), ('o', 'e'), ('e', 'r'), ('r', 'i'...   \n",
       "...                                                  ...   \n",
       "56009  [('n', 'i'), ('i', 'l'), ('l', ' '), (' ', 'i'...   \n",
       "56010  [('f', 'a'), ('a', 't'), ('t', 'm'), ('m', 'a'...   \n",
       "56011  [('e', 'l'), ('l', 'i'), ('i', 'f'), ('f', ' '...   \n",
       "56012  [('m', 'u'), ('u', 'h'), ('h', 'a'), ('a', 'm'...   \n",
       "56013  [('v', 'e'), ('e', 'd'), ('d', 'a'), ('a', 't'...   \n",
       "\n",
       "                                                trigrams  \\\n",
       "0      [('s', 'u', 'p'), ('u', 'p', 'r'), ('p', 'r', ...   \n",
       "1      [('t', 'r', 'i'), ('r', 'i', 'y'), ('i', 'y', ...   \n",
       "2      [('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...   \n",
       "3      [('u', 'n', 'd'), ('n', 'd', 'u'), ('d', 'u', ...   \n",
       "4      [('s', 'o', 'e'), ('o', 'e', 'r'), ('e', 'r', ...   \n",
       "...                                                  ...   \n",
       "56009  [('n', 'i', 'l'), ('i', 'l', ' '), ('l', ' ', ...   \n",
       "56010  [('f', 'a', 't'), ('a', 't', 'm'), ('t', 'm', ...   \n",
       "56011  [('e', 'l', 'i'), ('l', 'i', 'f'), ('i', 'f', ...   \n",
       "56012  [('m', 'u', 'h'), ('u', 'h', 'a'), ('h', 'a', ...   \n",
       "56013  [('v', 'e', 'd'), ('e', 'd', 'a'), ('d', 'a', ...   \n",
       "\n",
       "                                             char_ngrams       word_ngrams  \\\n",
       "0      ['s', 'u', 'p', 'r', 'i', 'y', 'a', 'd', 'i', ...     ['supriyadi']   \n",
       "1      ['t', 'r', 'i', 'y', 'a', 'n', 'i', 'n', 'g', ...  ['triyaningsih']   \n",
       "2      ['s', 'o', 'e', 'r', 'j', 'a', 'd', 'i', ('s',...      ['soerjadi']   \n",
       "3      ['u', 'n', 'd', 'u', 'n', 's', 'y', 'a', 'h', ...     ['undunsyah']   \n",
       "4      ['s', 'o', 'e', 'r', 'i', 'p', 't', 'o', ('s',...      ['soeripto']   \n",
       "...                                                  ...               ...   \n",
       "56009  ['n', 'i', 'l', ' ', 'i', '̇', 'p', 'e', 'k', ...               NaN   \n",
       "56010  ['f', 'a', 't', 'm', 'a', ' ', 'b', 'e', 't', ...               NaN   \n",
       "56011  ['e', 'l', 'i', 'f', ' ', 'n', 'u', 'r', ' ', ...               NaN   \n",
       "56012  ['m', 'u', 'h', 'a', 'm', 'm', 'e', 'd', ' ', ...               NaN   \n",
       "56013  ['v', 'e', 'd', 'a', 't', ' ', 'a', 'l', 'i', ...               NaN   \n",
       "\n",
       "       name_length  avg_token_length  ...  space_freq  \\\n",
       "0                9              9.00  ...           0   \n",
       "1               12             12.00  ...           0   \n",
       "2                8              8.00  ...           0   \n",
       "3                9              9.00  ...           0   \n",
       "4                8              8.00  ...           0   \n",
       "...            ...               ...  ...         ...   \n",
       "56009           23              5.75  ...           3   \n",
       "56010           19              4.75  ...           3   \n",
       "56011           22              5.50  ...           3   \n",
       "56012           23              5.75  ...           3   \n",
       "56013           19              4.75  ...           3   \n",
       "\n",
       "                                    indiv_unigrams_fdist  \\\n",
       "0      [[0.         0.         0.         0.         ...   \n",
       "1      [[0.         0.         0.         0.         ...   \n",
       "2      [[0.    0.    0.    0.    0.    0.125 0.    0....   \n",
       "3      [[0.         0.         0.         0.         ...   \n",
       "4      [[0.    0.    0.    0.    0.    0.    0.    0....   \n",
       "...                                                  ...   \n",
       "56009  [[0.11538462 0.         0.         0.03846154 ...   \n",
       "56010  [[0.13636364 0.         0.         0.27272727 ...   \n",
       "56011  [[0.12 0.   0.   0.08 0.04 0.   0.04 0.04 0.04...   \n",
       "56012  [[0.11538462 0.         0.         0.19230769 ...   \n",
       "56013  [[0.13636364 0.         0.         0.22727273 ...   \n",
       "\n",
       "             indiv_bigrams_fdist       indiv_trigrams_fdist  \\\n",
       "0      [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "1      [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "2      [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "3      [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "4      [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "...                          ...                        ...   \n",
       "56009  [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "56010  [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "56011  [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "56012  [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "56013  [[0. 0. 0. ... 0. 0. 0.]]  [[0. 0. 0. ... 0. 0. 0.]]   \n",
       "\n",
       "       unigrams_cosine_sim  bigrams_cosine_sim trigrams_cosine_sim  \\\n",
       "0                 0.664809            0.250640            0.085949   \n",
       "1                 0.686625            0.353292            0.117226   \n",
       "2                 0.688312            0.197139            0.090295   \n",
       "3                 0.581396            0.155386            0.060083   \n",
       "4                 0.463215            0.176917            0.052811   \n",
       "...                    ...                 ...                 ...   \n",
       "56009             0.766280            0.250772            0.100388   \n",
       "56010             0.812166            0.453787            0.210581   \n",
       "56011             0.820321            0.366293            0.123383   \n",
       "56012             0.894470            0.462341            0.148177   \n",
       "56013             0.828399            0.489544            0.313943   \n",
       "\n",
       "         language                                        id  \\\n",
       "0      Indonesian                                       NaN   \n",
       "1      Indonesian                                       NaN   \n",
       "2      Indonesian                                       NaN   \n",
       "3      Indonesian                                       NaN   \n",
       "4      Indonesian                                       NaN   \n",
       "...           ...                                       ...   \n",
       "56009     Turkish  http://www.wikidata.org/entity/Q49703809   \n",
       "56010     Turkish  http://www.wikidata.org/entity/Q24230049   \n",
       "56011     Turkish   http://www.wikidata.org/entity/Q6053953   \n",
       "56012     Turkish   http://www.wikidata.org/entity/Q6085044   \n",
       "56013     Turkish   http://www.wikidata.org/entity/Q6071196   \n",
       "\n",
       "                         label_tr  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "56009   Nil İpek Hülagü Öztürkmen  \n",
       "56010      Fatma Betül Sayan Kaya  \n",
       "56011   Elif Nur Bozkurt Tandoğan  \n",
       "56012  Muhammed Ali Fatih Erbakan  \n",
       "56013      Vedat Ali Özkan Kayacı  \n",
       "\n",
       "[56014 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see from output, we need the columns in the concatenated df (in this case, viet) to match\n",
    "# it's okay if some values are NaN bc we'll drop all non-numerical columns anyway\n",
    "merged_df = pd.concat([df_indo, df_malay, df_viet, df_cnrom, df_cnchar,df_turk], ignore_index = True, join = 'outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Keeping numerical columns only for each dataset (Same process as step 4, except we don't have to repeat lines of code...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56009</th>\n",
       "      <td>23</td>\n",
       "      <td>5.75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.766280</td>\n",
       "      <td>0.250772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56010</th>\n",
       "      <td>19</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.812166</td>\n",
       "      <td>0.453787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56011</th>\n",
       "      <td>22</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820321</td>\n",
       "      <td>0.366293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56012</th>\n",
       "      <td>23</td>\n",
       "      <td>5.75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.894470</td>\n",
       "      <td>0.462341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56013</th>\n",
       "      <td>19</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828399</td>\n",
       "      <td>0.489544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56014 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0                9              9.00           1            0          0   \n",
       "1               12             12.00           1            0          0   \n",
       "2                8              8.00           1            0          0   \n",
       "3                9              9.00           1            0          0   \n",
       "4                8              8.00           1            0          0   \n",
       "...            ...               ...         ...          ...        ...   \n",
       "56009           23              5.75           4            0          0   \n",
       "56010           19              4.75           4            0          0   \n",
       "56011           22              5.50           4            0          0   \n",
       "56012           23              5.75           4            0          0   \n",
       "56013           19              4.75           4            0          0   \n",
       "\n",
       "       apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \n",
       "0                  0.0           0             0.664809            0.250640  \n",
       "1                  0.0           0             0.686625            0.353292  \n",
       "2                  0.0           0             0.688312            0.197139  \n",
       "3                  0.0           0             0.581396            0.155386  \n",
       "4                  0.0           0             0.463215            0.176917  \n",
       "...                ...         ...                  ...                 ...  \n",
       "56009              NaN           3             0.766280            0.250772  \n",
       "56010              NaN           3             0.812166            0.453787  \n",
       "56011              NaN           3             0.820321            0.366293  \n",
       "56012              NaN           3             0.894470            0.462341  \n",
       "56013              NaN           3             0.828399            0.489544  \n",
       "\n",
       "[56014 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df.select_dtypes(exclude = 'object')\n",
    "merged_df.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Clean up columns so we can combine dataframes into one (focus on making an all-Latin dataset first)\n",
    "    - do not combine in this step\n",
    "2. Frequency distributions for Latin names -> redo\n",
    "3. Add a_hat_freq\n",
    "4. Only keep numerical columns\n",
    "    - turn some categorical features -> numerical so we have more things to feed into model\n",
    "5. Add in label (language) for each dataset\n",
    "6. Combine Latin and non-Latin names to make one big dataset\n",
    "    - may need to repeat some of the above steps for non-Latin names\n",
    "7. Train test split\n",
    "8. MODEL TRAINING!\n",
    "9. Model evaluation\n",
    "\n",
    "Reminder:\n",
    "- We decided to keep period_freq, dash_freq, apostrophe_freq for now. After our first run of model training, we can remove them to see if it improves the performance\n",
    "\n",
    "**You can work on these steps out of order** (act as if the previous steps r there), but in the end we ideally want all of these steps implemented in this order.\n",
    "\n",
    "For example, you could write the code for model training and train the model on one or a few datasets. Later on, we'll just replace the variables you used with the ones containing all the languages/names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
