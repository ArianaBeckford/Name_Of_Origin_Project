{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was originally for frequency distributions for Latin names!\n",
    "but we can also concat the other dfs / do model training after in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo = pd.read_csv('df_indo.csv')\n",
    "df_malay = pd.read_csv('df_malay.csv')\n",
    "df_viet = pd.read_csv('viet_df.csv')\n",
    "df_cnrom = pd.read_csv('cnrom_df.csv')\n",
    "df_cnchar = pd.read_csv('cnchar_df.csv')\n",
    "# also import other dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names to KEEP: (10 so far)\n",
    "\n",
    "* name_length\n",
    "* avg_token_length\n",
    "* num_tokens\n",
    "* period_freq\n",
    "* dash_freq\n",
    "* apostrophe_freq\n",
    "* space_freq\n",
    "* unigrams_cosine_sim\n",
    "* bigrams_cosine_sim\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fullname', 'original_fullname', 'alphabet', 'unigrams', 'bigrams',\n",
      "       'trigrams', 'char_ngrams', 'word_ngrams', 'name_length',\n",
      "       'avg_token_length', 'num_tokens', 'transliteration', 'period_freq',\n",
      "       'dash_freq', 'apostrophe_freq', 'space_freq', 'indiv_unigrams_fdist',\n",
      "       'indiv_bigrams_fdist', 'indiv_trigrams_fdist', 'unigrams_cosine_sim',\n",
      "       'bigrams_cosine_sim', 'trigrams_cosine_sim'],\n",
      "      dtype='object')\n",
      "Index(['fullname', 'alphabet', 'word_length', 'num_tokens', 'char_ngrams',\n",
      "       'period_freq', 'dash_freq', 'space_freq', 'apostrophe_freq',\n",
      "       'transliteration', 'unigrams', 'bigrams', 'trigrams',\n",
      "       'indiv_unigrams_fdist', 'indiv_bigrams_fdist', 'unigrams_cosine_sim',\n",
      "       'bigrams_cosine_sim'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['word_length']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding what columns r in viet that aren't in indo\n",
    "print(df_indo.columns)\n",
    "print(df_viet.columns)\n",
    "[col for col in df_viet.columns if col not in df_indo.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idk if i can generalize this lol\n",
    "# def rename_columns(df_ref, df_to_change):\n",
    "#     diff_cols = [col for col in df_to_change.columns if col not in df_ref.columns]\n",
    "#     new_names = \n",
    "#     df_to_change.rename(columns = {oldName : newName})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>từ hoàng thông</td>\n",
       "      <td>['LATIN', 'LATIN', 'SPACE', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[('T',), ('ừ',), (' ',), ('H',), ('o',), ('à',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tu hoang thong</td>\n",
       "      <td>['t', 'ừ', ' ', 'h', 'o', 'à', 'n', 'g', ' ', ...</td>\n",
       "      <td>[('t', 'ừ'), ('ừ', ' '), (' ', 'h'), ('h', 'o'...</td>\n",
       "      <td>[('t', 'ừ', ' '), ('ừ', ' ', 'h'), (' ', 'h', ...</td>\n",
       "      <td>[[0.14285714 0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.508198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nguyễn thị phương thảo</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>[('N',), ('g',), ('u',), ('y',), ('ễ',), ('n',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>nguyen thi phuong thao</td>\n",
       "      <td>['n', 'g', 'u', 'y', 'ễ', 'n', ' ', 't', 'h', ...</td>\n",
       "      <td>[('n', 'g'), ('g', 'u'), ('u', 'y'), ('y', 'ễ'...</td>\n",
       "      <td>[('n', 'g', 'u'), ('g', 'u', 'y'), ('u', 'y', ...</td>\n",
       "      <td>[[0.13636364 0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.884792</td>\n",
       "      <td>0.667716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nick út</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'LATIN', 'SPACE', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[('N',), ('i',), ('c',), ('k',), (' ',), ('Ú',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nick ut</td>\n",
       "      <td>['n', 'i', 'c', 'k', ' ', 'ú', 't']</td>\n",
       "      <td>[('n', 'i'), ('i', 'c'), ('c', 'k'), ('k', ' '...</td>\n",
       "      <td>[('n', 'i', 'c'), ('i', 'c', 'k'), ('c', 'k', ...</td>\n",
       "      <td>[[0.14285714 0.         0.         0.14285714 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.592690</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cao văn lầu</td>\n",
       "      <td>['LATIN', 'LATIN', 'LATIN', 'SPACE', 'LATIN', ...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[('C',), ('a',), ('o',), (' ',), ('V',), ('ă',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>cao van lau</td>\n",
       "      <td>['c', 'a', 'o', ' ', 'v', 'ă', 'n', ' ', 'l', ...</td>\n",
       "      <td>[('c', 'a'), ('a', 'o'), ('o', ' '), (' ', 'v'...</td>\n",
       "      <td>[('c', 'a', 'o'), ('a', 'o', ' '), ('o', ' ', ...</td>\n",
       "      <td>[[0.18181818 0.09090909 0.         0.09090909 ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.665965</td>\n",
       "      <td>0.243176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tạ thu thâu</td>\n",
       "      <td>['LATIN', 'LATIN', 'SPACE', 'LATIN', 'LATIN', ...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[('T',), ('ạ',), (' ',), ('T',), ('h',), ('u',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ta thu thau</td>\n",
       "      <td>['t', 'ạ', ' ', 't', 'h', 'u', ' ', 't', 'h', ...</td>\n",
       "      <td>[('t', 'ạ'), ('ạ', ' '), (' ', 't'), ('t', 'h'...</td>\n",
       "      <td>[('t', 'ạ', ' '), ('ạ', ' ', 't'), (' ', 't', ...</td>\n",
       "      <td>[[0.18181818 0.         0.         0.         ...</td>\n",
       "      <td>[[0. 0. 0. ... 0. 0. 0.]]</td>\n",
       "      <td>0.596114</td>\n",
       "      <td>0.288942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fullname                                           alphabet  \\\n",
       "0          từ hoàng thông  ['LATIN', 'LATIN', 'SPACE', 'LATIN', 'LATIN', ...   \n",
       "1  nguyễn thị phương thảo  ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'LATIN', ...   \n",
       "2                 nick út  ['LATIN', 'LATIN', 'LATIN', 'LATIN', 'SPACE', ...   \n",
       "3             cao văn lầu  ['LATIN', 'LATIN', 'LATIN', 'SPACE', 'LATIN', ...   \n",
       "4             tạ thu thâu  ['LATIN', 'LATIN', 'SPACE', 'LATIN', 'LATIN', ...   \n",
       "\n",
       "   name_length  num_tokens                                        char_ngrams  \\\n",
       "0           14           3  [('T',), ('ừ',), (' ',), ('H',), ('o',), ('à',...   \n",
       "1           22           4  [('N',), ('g',), ('u',), ('y',), ('ễ',), ('n',...   \n",
       "2            7           2  [('N',), ('i',), ('c',), ('k',), (' ',), ('Ú',...   \n",
       "3           11           3  [('C',), ('a',), ('o',), (' ',), ('V',), ('ă',...   \n",
       "4           11           3  [('T',), ('ạ',), (' ',), ('T',), ('h',), ('u',...   \n",
       "\n",
       "   period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "0            0          0           2                0   \n",
       "1            0          0           3                0   \n",
       "2            0          0           1                0   \n",
       "3            0          0           2                0   \n",
       "4            0          0           2                0   \n",
       "\n",
       "          transliteration                                           unigrams  \\\n",
       "0          tu hoang thong  ['t', 'ừ', ' ', 'h', 'o', 'à', 'n', 'g', ' ', ...   \n",
       "1  nguyen thi phuong thao  ['n', 'g', 'u', 'y', 'ễ', 'n', ' ', 't', 'h', ...   \n",
       "2                 nick ut                ['n', 'i', 'c', 'k', ' ', 'ú', 't']   \n",
       "3             cao van lau  ['c', 'a', 'o', ' ', 'v', 'ă', 'n', ' ', 'l', ...   \n",
       "4             ta thu thau  ['t', 'ạ', ' ', 't', 'h', 'u', ' ', 't', 'h', ...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [('t', 'ừ'), ('ừ', ' '), (' ', 'h'), ('h', 'o'...   \n",
       "1  [('n', 'g'), ('g', 'u'), ('u', 'y'), ('y', 'ễ'...   \n",
       "2  [('n', 'i'), ('i', 'c'), ('c', 'k'), ('k', ' '...   \n",
       "3  [('c', 'a'), ('a', 'o'), ('o', ' '), (' ', 'v'...   \n",
       "4  [('t', 'ạ'), ('ạ', ' '), (' ', 't'), ('t', 'h'...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [('t', 'ừ', ' '), ('ừ', ' ', 'h'), (' ', 'h', ...   \n",
       "1  [('n', 'g', 'u'), ('g', 'u', 'y'), ('u', 'y', ...   \n",
       "2  [('n', 'i', 'c'), ('i', 'c', 'k'), ('c', 'k', ...   \n",
       "3  [('c', 'a', 'o'), ('a', 'o', ' '), ('o', ' ', ...   \n",
       "4  [('t', 'ạ', ' '), ('ạ', ' ', 't'), (' ', 't', ...   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.14285714 0.         0.         0.         ...   \n",
       "1  [[0.13636364 0.         0.         0.         ...   \n",
       "2  [[0.14285714 0.         0.         0.14285714 ...   \n",
       "3  [[0.18181818 0.09090909 0.         0.09090909 ...   \n",
       "4  [[0.18181818 0.         0.         0.         ...   \n",
       "\n",
       "         indiv_bigrams_fdist  unigrams_cosine_sim  bigrams_cosine_sim  \n",
       "0  [[0. 0. 0. ... 0. 0. 0.]]             0.805625            0.508198  \n",
       "1  [[0. 0. 0. ... 0. 0. 0.]]             0.884792            0.667716  \n",
       "2  [[0. 0. 0. ... 0. 0. 0.]]             0.592690            0.005600  \n",
       "3  [[0. 0. 0. ... 0. 0. 0.]]             0.665965            0.243176  \n",
       "4  [[0. 0. 0. ... 0. 0. 0.]]             0.596114            0.288942  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming viet_df columns\n",
    "\n",
    "df_viet.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_viet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Keeping numerical columns only for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0.085949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.117226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0.090295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.060083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.052811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>34</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883198</td>\n",
       "      <td>0.323446</td>\n",
       "      <td>0.099663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>41</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906658</td>\n",
       "      <td>0.559409</td>\n",
       "      <td>0.253901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11243</th>\n",
       "      <td>36</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>0.336306</td>\n",
       "      <td>0.163018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244</th>\n",
       "      <td>53</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905343</td>\n",
       "      <td>0.577418</td>\n",
       "      <td>0.245617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11245</th>\n",
       "      <td>76</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.856026</td>\n",
       "      <td>0.437257</td>\n",
       "      <td>0.170188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11246 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0                9          9.000000           1            0          0   \n",
       "1               12         12.000000           1            0          0   \n",
       "2                8          8.000000           1            0          0   \n",
       "3                9          9.000000           1            0          0   \n",
       "4                8          8.000000           1            0          0   \n",
       "...            ...               ...         ...          ...        ...   \n",
       "11241           34          4.833333           6            0          0   \n",
       "11242           41          6.000000           6            0          0   \n",
       "11243           36          5.166667           6            4          0   \n",
       "11244           53          6.714286           7            0          0   \n",
       "11245           76          5.416667          12            0          0   \n",
       "\n",
       "       apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                    0           0             0.664809            0.250640   \n",
       "1                    0           0             0.686625            0.353292   \n",
       "2                    0           0             0.688312            0.197139   \n",
       "3                    0           0             0.581396            0.155386   \n",
       "4                    0           0             0.463215            0.176917   \n",
       "...                ...         ...                  ...                 ...   \n",
       "11241                0           5             0.883198            0.323446   \n",
       "11242                0           5             0.906658            0.559409   \n",
       "11243                0           5             0.731478            0.336306   \n",
       "11244                0           6             0.905343            0.577418   \n",
       "11245                0          11             0.856026            0.437257   \n",
       "\n",
       "       trigrams_cosine_sim  \n",
       "0                 0.085949  \n",
       "1                 0.117226  \n",
       "2                 0.090295  \n",
       "3                 0.060083  \n",
       "4                 0.052811  \n",
       "...                    ...  \n",
       "11241             0.099663  \n",
       "11242             0.253901  \n",
       "11243             0.163018  \n",
       "11244             0.245617  \n",
       "11245             0.170188  \n",
       "\n",
       "[11246 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO FOR EACH DATASET\n",
    "# dropping non-numerical columns - this is why it would be good to have more numerical features since we don't have a lot\n",
    "df_indo = df_indo.select_dtypes(exclude = 'object')\n",
    "df_indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP FOR WHOLE DATASET\n",
    "# dropping trigrams for indo and malay\n",
    "df_indo.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "df_malay.drop('trigrams_cosine_sim', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up viet / other dfs before combining\n",
    "df_viet.drop('trigrams', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adding the language (label) to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0            9               9.0           1            0          0   \n",
       "1           12              12.0           1            0          0   \n",
       "2            8               8.0           1            0          0   \n",
       "3            9               9.0           1            0          0   \n",
       "4            8               8.0           1            0          0   \n",
       "\n",
       "   apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                0           0             0.664809            0.250640   \n",
       "1                0           0             0.686625            0.353292   \n",
       "2                0           0             0.688312            0.197139   \n",
       "3                0           0             0.581396            0.155386   \n",
       "4                0           0             0.463215            0.176917   \n",
       "\n",
       "     language  \n",
       "0  Indonesian  \n",
       "1  Indonesian  \n",
       "2  Indonesian  \n",
       "3  Indonesian  \n",
       "4  Indonesian  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indo['language'] = 'Indonesian'\n",
    "df_malay['language'] = 'Malay'\n",
    "df_viet['language'] = 'Vietnamese'\n",
    "df_cnrom['language'] = 'Chinese (Romanized)'\n",
    "df_cnchar['language'] = 'Chinese (Characters)'\n",
    "df_indo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining all names to make one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>indiv_trigrams_fdist</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37972</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.844943</td>\n",
       "      <td>0.665759</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>...</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('x',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gong xiang yu</td>\n",
       "      <td>[[0.15384615 0.07692308 0.         0.         ...</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.501902</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>...</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'y', 'u', ' ', 'z', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('y',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gong yu zhi</td>\n",
       "      <td>[[0.18181818 0.         0.         0.         ...</td>\n",
       "      <td>[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.729526</td>\n",
       "      <td>0.363754</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>...</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'b', 'e', 'i', ' ', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('b',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gong bei bi</td>\n",
       "      <td>[[0.18181818 0.         0.18181818 0.         ...</td>\n",
       "      <td>[[0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>0.637316</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>...</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('x',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gong xian yong</td>\n",
       "      <td>[[0.14285714 0.07142857 0.         0.         ...</td>\n",
       "      <td>[[0.         0.         0.         0.         ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688529</td>\n",
       "      <td>0.522372</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>...</td>\n",
       "      <td>['g', 'o', 'n', 'g', ' ', 'd', 'i', 'n', 'g']</td>\n",
       "      <td>[('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...</td>\n",
       "      <td>[('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...</td>\n",
       "      <td>[('g',), ('o',), ('n',), ('g',), (' ',), ('d',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gong ding</td>\n",
       "      <td>[[0.11111111 0.         0.         0.         ...</td>\n",
       "      <td>[[0.    0.    0.    0.    0.125 0.    0.    0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37977 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0              9.0               9.0           1            0          0   \n",
       "1             12.0              12.0           1            0          0   \n",
       "2              8.0               8.0           1            0          0   \n",
       "3              9.0               9.0           1            0          0   \n",
       "4              8.0               8.0           1            0          0   \n",
       "...            ...               ...         ...          ...        ...   \n",
       "37972          NaN               NaN           3            0          0   \n",
       "37973          NaN               NaN           3            0          0   \n",
       "37974          NaN               NaN           3            0          0   \n",
       "37975          NaN               NaN           3            0          0   \n",
       "37976          NaN               NaN           2            0          0   \n",
       "\n",
       "       apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                    0           0             0.664809            0.250640   \n",
       "1                    0           0             0.686625            0.353292   \n",
       "2                    0           0             0.688312            0.197139   \n",
       "3                    0           0             0.581396            0.155386   \n",
       "4                    0           0             0.463215            0.176917   \n",
       "...                ...         ...                  ...                 ...   \n",
       "37972                0           2             0.844943            0.665759   \n",
       "37973                0           2             0.837370            0.501902   \n",
       "37974                0           2             0.729526            0.363754   \n",
       "37975                0           2             0.808012            0.637316   \n",
       "37976                0           1             0.688529            0.522372   \n",
       "\n",
       "                   language  ...  \\\n",
       "0                Indonesian  ...   \n",
       "1                Indonesian  ...   \n",
       "2                Indonesian  ...   \n",
       "3                Indonesian  ...   \n",
       "4                Indonesian  ...   \n",
       "...                     ...  ...   \n",
       "37972  Chinese (Characters)  ...   \n",
       "37973  Chinese (Characters)  ...   \n",
       "37974  Chinese (Characters)  ...   \n",
       "37975  Chinese (Characters)  ...   \n",
       "37976  Chinese (Characters)  ...   \n",
       "\n",
       "                                                unigrams  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "37972  ['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...   \n",
       "37973  ['g', 'o', 'n', 'g', ' ', 'y', 'u', ' ', 'z', ...   \n",
       "37974  ['g', 'o', 'n', 'g', ' ', 'b', 'e', 'i', ' ', ...   \n",
       "37975  ['g', 'o', 'n', 'g', ' ', 'x', 'i', 'a', 'n', ...   \n",
       "37976      ['g', 'o', 'n', 'g', ' ', 'd', 'i', 'n', 'g']   \n",
       "\n",
       "                                                 bigrams  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "37972  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37973  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37974  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37975  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "37976  [('g', 'o'), ('o', 'n'), ('n', 'g'), ('g', ' '...   \n",
       "\n",
       "                                                trigrams  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "37972  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37973  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37974  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37975  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "37976  [('g', 'o', 'n'), ('o', 'n', 'g'), ('n', 'g', ...   \n",
       "\n",
       "                                             char_ngrams word_ngrams  \\\n",
       "0                                                    NaN         NaN   \n",
       "1                                                    NaN         NaN   \n",
       "2                                                    NaN         NaN   \n",
       "3                                                    NaN         NaN   \n",
       "4                                                    NaN         NaN   \n",
       "...                                                  ...         ...   \n",
       "37972  [('g',), ('o',), ('n',), ('g',), (' ',), ('x',...         NaN   \n",
       "37973  [('g',), ('o',), ('n',), ('g',), (' ',), ('y',...         NaN   \n",
       "37974  [('g',), ('o',), ('n',), ('g',), (' ',), ('b',...         NaN   \n",
       "37975  [('g',), ('o',), ('n',), ('g',), (' ',), ('x',...         NaN   \n",
       "37976  [('g',), ('o',), ('n',), ('g',), (' ',), ('d',...         NaN   \n",
       "\n",
       "      transliteration                               indiv_unigrams_fdist  \\\n",
       "0                 NaN                                                NaN   \n",
       "1                 NaN                                                NaN   \n",
       "2                 NaN                                                NaN   \n",
       "3                 NaN                                                NaN   \n",
       "4                 NaN                                                NaN   \n",
       "...               ...                                                ...   \n",
       "37972   gong xiang yu  [[0.15384615 0.07692308 0.         0.         ...   \n",
       "37973     gong yu zhi  [[0.18181818 0.         0.         0.         ...   \n",
       "37974     gong bei bi  [[0.18181818 0.         0.18181818 0.         ...   \n",
       "37975  gong xian yong  [[0.14285714 0.07142857 0.         0.         ...   \n",
       "37976       gong ding  [[0.11111111 0.         0.         0.         ...   \n",
       "\n",
       "                                     indiv_bigrams_fdist indiv_trigrams_fdist  \\\n",
       "0                                                    NaN                  NaN   \n",
       "1                                                    NaN                  NaN   \n",
       "2                                                    NaN                  NaN   \n",
       "3                                                    NaN                  NaN   \n",
       "4                                                    NaN                  NaN   \n",
       "...                                                  ...                  ...   \n",
       "37972  [[0.         0.         0.         0.         ...                  NaN   \n",
       "37973  [[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  ...                  NaN   \n",
       "37974  [[0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  ...                  NaN   \n",
       "37975  [[0.         0.         0.         0.         ...                  NaN   \n",
       "37976  [[0.    0.    0.    0.    0.125 0.    0.    0....                  NaN   \n",
       "\n",
       "      word_length  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "37972        13.0  \n",
       "37973        11.0  \n",
       "37974        11.0  \n",
       "37975        14.0  \n",
       "37976         9.0  \n",
       "\n",
       "[37977 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see from output, we need the columns in the concatenated df (in this case, viet) to match\n",
    "# it's okay if some values are NaN bc we'll drop all non-numerical columns anyway\n",
    "merged_df = pd.concat([df_indo, df_malay, df_viet, df_cnrom, df_cnchar], ignore_index = True, join = 'outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Clean up columns so we can combine dataframes into one (focus on making an all-Latin dataset first)\n",
    "    - do not combine in this step\n",
    "2. Frequency distributions for Latin names -> redo\n",
    "3. Add a_hat_freq\n",
    "4. Only keep numerical columns\n",
    "    - turn some categorical features -> numerical so we have more things to feed into model\n",
    "5. Add in label (language) for each dataset\n",
    "6. Combine Latin and non-Latin names to make one big dataset\n",
    "    - may need to repeat some of the above steps for non-Latin names\n",
    "7. Train test split\n",
    "8. MODEL TRAINING!\n",
    "9. Model evaluation\n",
    "\n",
    "Reminder:\n",
    "- We decided to keep period_freq, dash_freq, apostrophe_freq for now. After our first run of model training, we can remove them to see if it improves the performance\n",
    "\n",
    "**You can work on these steps out of order** (act as if the previous steps r there), but in the end we ideally want all of these steps implemented in this order.\n",
    "\n",
    "For example, you could write the code for model training and train the model on one or a few datasets. Later on, we'll just replace the variables you used with the ones containing all the languages/names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
