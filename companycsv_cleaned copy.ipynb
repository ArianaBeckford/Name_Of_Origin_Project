{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Canal of the Angels</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rescue Renovation</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agatha Christie: The ABC Murders</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siti Akbari</td>\n",
       "      <td>0</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stany</td>\n",
       "      <td>0</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>Robber's Bridge</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>Johan Renck</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>Lyle Stewart</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>Thomas Colclough Watson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>Gavà</td>\n",
       "      <td>0</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name  class lang\n",
       "0                The Canal of the Angels      0   en\n",
       "1                      Rescue Renovation      0   en\n",
       "2       Agatha Christie: The ABC Murders      0   en\n",
       "3                            Siti Akbari      0   ar\n",
       "4                                  Stany      0   pl\n",
       "...                                  ...    ...  ...\n",
       "199995                   Robber's Bridge      0   en\n",
       "199996                       Johan Renck      0   en\n",
       "199997                      Lyle Stewart      1   en\n",
       "199998           Thomas Colclough Watson      1   en\n",
       "199999                              Gavà      0   ca\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"company_person_name_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"class\"]==1]\n",
    "#look into smote for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(df[\"name\"].isnull()))\n",
    "print(np.any(df[\"class\"].isnull()))\n",
    "print(np.any(df[\"lang\"].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48190\n"
     ]
    }
   ],
   "source": [
    "print(len(df.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Raha Etemadi</td>\n",
       "      <td>1</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leena Peltonen-Palotie</td>\n",
       "      <td>1</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Luma Grothe</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Takuya Kakine</td>\n",
       "      <td>1</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ōuyáng Zhènhuá</td>\n",
       "      <td>1</td>\n",
       "      <td>mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>Clyde Donaldson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>Terry Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>Neil Roebuck</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>Lyle Stewart</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>Thomas Colclough Watson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  class lang\n",
       "11                 Raha Etemadi      1   et\n",
       "12       Leena Peltonen-Palotie      1   fi\n",
       "16                  Luma Grothe      1   en\n",
       "20                Takuya Kakine      1   ja\n",
       "21               Ōuyáng Zhènhuá      1   mi\n",
       "...                         ...    ...  ...\n",
       "199976          Clyde Donaldson      1   en\n",
       "199980          Terry Alexander      1   en\n",
       "199989             Neil Roebuck      1   en\n",
       "199997             Lyle Stewart      1   en\n",
       "199998  Thomas Colclough Watson      1   en\n",
       "\n",
       "[47759 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts = df[\"lang\"].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language distribution:\n",
      "<bound method IndexOpsMixin.value_counts of 11        et\n",
      "12        fi\n",
      "16        en\n",
      "20        ja\n",
      "21        mi\n",
      "          ..\n",
      "199976    en\n",
      "199980    en\n",
      "199989    en\n",
      "199997    en\n",
      "199998    en\n",
      "Name: lang, Length: 48188, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(\"Language distribution:\")\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.any(df[\"name\"].isnull()))\n",
    "print(np.any(df[\"class\"].isnull()))\n",
    "print(np.any(df[\"lang\"].isnull()))\n",
    "print(np.any(df.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(df.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language distribution:\n",
      "<bound method IndexOpsMixin.value_counts of 11        et\n",
      "12        fi\n",
      "16        en\n",
      "20        ja\n",
      "21        mi\n",
      "          ..\n",
      "199976    en\n",
      "199980    en\n",
      "199989    en\n",
      "199997    en\n",
      "199998    en\n",
      "Name: lang, Length: 48188, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(\"Language distribution:\")\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language distribution:\n",
      "lang\n",
      "en    23352\n",
      "es     2532\n",
      "it     1224\n",
      "fr     1181\n",
      "ja     1155\n",
      "      ...  \n",
      "my        1\n",
      "sd        1\n",
      "kk        1\n",
      "pa        1\n",
      "si        1\n",
      "Name: count, Length: 103, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"lang\"] = df[\"lang\"].str.strip()\n",
    "language_counts = df[\"lang\"].value_counts()\n",
    "print(\"Language distribution:\")\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Cleaning to Drop Names with Special Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset df index starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name  class lang\n",
      "0                 Raha Etemadi      1   et\n",
      "1       Leena Peltonen-Palotie      1   fi\n",
      "2                  Luma Grothe      1   en\n",
      "3                Takuya Kakine      1   ja\n",
      "4               Ōuyáng Zhènhuá      1   mi\n",
      "...                        ...    ...  ...\n",
      "47754          Clyde Donaldson      1   en\n",
      "47755          Terry Alexander      1   en\n",
      "47756             Neil Roebuck      1   en\n",
      "47757             Lyle Stewart      1   en\n",
      "47758  Thomas Colclough Watson      1   en\n",
      "\n",
      "[47759 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create langname to find the alphabet name of the first character in the first word of a given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "langname = lambda x : unicodedata.name(x[0]).split(' ')[0]\n",
    "langname('Raha Etemadi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using langname to find the alphabet of the first character in the first word of each name in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EQUALS', 'DIGIT', 'HANGUL', 'SINHALA', 'HEBREW', 'CYRILLIC', 'CJK', 'SYRIAC', 'HYPHEN-MINUS', 'KANNADA', 'THAI', 'TELUGU', 'TAMIL', 'MYANMAR', 'GURMUKHI', 'RIGHT', 'APOSTROPHE', 'ETHIOPIC', 'LATIN', 'ARABIC', 'LESS-THAN', 'GREEK', 'ASTERISK', 'QUOTATION', 'LEFT', 'ARMENIAN', 'BENGALI', 'KATAKANA', 'DEVANAGARI'}\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "alphabet = []\n",
    "for i in df['name']:\n",
    "    alphabet.append(langname(i))\n",
    "\n",
    "print(set(alphabet))\n",
    "print(len(set(alphabet)))\n",
    "\n",
    "df['alphabet'] = alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a count of names that use each alphabet in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 EQUALS\n",
      "14 DIGIT\n",
      "3 HANGUL\n",
      "1 SINHALA\n",
      "10 HEBREW\n",
      "43 CYRILLIC\n",
      "146 CJK\n",
      "1 SYRIAC\n",
      "3 HYPHEN-MINUS\n",
      "2 KANNADA\n",
      "1 THAI\n",
      "1 TELUGU\n",
      "2 TAMIL\n",
      "1 MYANMAR\n",
      "1 GURMUKHI\n",
      "1 RIGHT\n",
      "2 APOSTROPHE\n",
      "1 ETHIOPIC\n",
      "47317 LATIN\n",
      "55 ARABIC\n",
      "1 LESS-THAN\n",
      "10 GREEK\n",
      "1 ASTERISK\n",
      "8 QUOTATION\n",
      "109 LEFT\n",
      "3 ARMENIAN\n",
      "5 BENGALI\n",
      "1 KATAKANA\n",
      "15 DEVANAGARI\n"
     ]
    }
   ],
   "source": [
    "for i in set(alphabet):\n",
    "    count = 0\n",
    "    for x,y in enumerate(df['alphabet']):\n",
    "        if str(i) in y:\n",
    "            count += 1\n",
    "            #print(df['name'][x])\n",
    "    print(count, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding names that have special characters and preparing to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leena Peltonen-Palotie', 'R. M. Dharmadasa Banda', 'Vicente de Valverde y Alvarez de Toledo, O.P.', 'Ute Kircheis-Wessel', 'David John (Dave) Shannon', 'Dr. Joan W. Miller', 'Donald M. Davis', 'Akseli Gallen-Kallela', 'Gerald S. McGowan', 'Jung Chul-Woon']\n",
      "4841\n",
      "{'GREEK', 'HEBREW', 'CYRILLIC', 'HANGUL', 'CJK', 'SYRIAC', 'ARMENIAN', 'LATIN', 'KATAKANA', 'ARABIC'}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "alphabet1 = []\n",
    "notalpha = []\n",
    "for i in df['name']:\n",
    "    tempword = i.split()\n",
    "    if (all(word.isalpha() == True for word in tempword)):\n",
    "        alphabet1.append(langname(i))\n",
    "    else: \n",
    "        notalpha.append(i)\n",
    "    \n",
    "print(notalpha[0:10])\n",
    "print(len(notalpha))\n",
    "print(set(alphabet1))\n",
    "print(len(set(alphabet1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a new dataframe 'df2' with dropped names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "droprows = []\n",
    "for i, name in enumerate(df['name']):\n",
    "    if name in notalpha:\n",
    "        droprows.append(i)\n",
    "#df2 = df.drop(droprows) df2 is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset df2 index starting from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name  class lang alphabet\n",
      "0                 Raha Etemadi      1   et    LATIN\n",
      "1                  Luma Grothe      1   en    LATIN\n",
      "2                Takuya Kakine      1   ja    LATIN\n",
      "3               Ōuyáng Zhènhuá      1   mi    LATIN\n",
      "4         Jordan Gideon Archer      1   en    LATIN\n",
      "...                        ...    ...  ...      ...\n",
      "42913          Clyde Donaldson      1   en    LATIN\n",
      "42914          Terry Alexander      1   en    LATIN\n",
      "42915             Neil Roebuck      1   en    LATIN\n",
      "42916             Lyle Stewart      1   en    LATIN\n",
      "42917  Thomas Colclough Watson      1   en    LATIN\n",
      "\n",
      "[42918 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df2.reset_index(drop=True, inplace=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of names that use each alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GREEK', 'HEBREW', 'CYRILLIC', 'HANGUL', 'CJK', 'SYRIAC', 'ARMENIAN', 'LATIN', 'KATAKANA', 'ARABIC'}\n",
      "10\n",
      "9 GREEK\n",
      "8 HEBREW\n",
      "42 CYRILLIC\n",
      "3 HANGUL\n",
      "144 CJK\n",
      "1 SYRIAC\n",
      "2 ARMENIAN\n",
      "42655 LATIN\n",
      "1 KATAKANA\n",
      "53 ARABIC\n"
     ]
    }
   ],
   "source": [
    "alphabet2 = []\n",
    "for i in df2['name']:\n",
    "    alphabet2.append(langname(i))\n",
    "\n",
    "print(set(alphabet2))\n",
    "print(len(set(alphabet2)))\n",
    "\n",
    "df2['alphabet'] = alphabet2\n",
    "\n",
    "for i in set(alphabet2):\n",
    "    count = 0\n",
    "    for x,y in enumerate(df2['alphabet']):\n",
    "        if str(i) in y:\n",
    "            count += 1\n",
    "    print(count, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking original names in DEVANAGARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['alphabet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "राणा उदय सिहं\n",
      "False\n",
      "करतार सिंह भड़ाना\n",
      "False\n",
      "शंखलाल माझी\n",
      "False\n",
      "सुर्नेद्र झा 'सुमन '\n",
      "False\n",
      "आचार्य सारंगधर\n",
      "False\n",
      "पवन कुमार शर्मा\n",
      "False\n",
      "अटल बिहारी वाजपेयी\n",
      "False\n",
      "गेंदा लाल  चौधरी\n",
      "False\n",
      "विजय सिंह\n",
      "False\n",
      "परेश रावल\n",
      "False\n",
      "पुरुशोत्तम काशीनाथ केळकर\n",
      "False\n",
      "फ़ौज़िया  तहसीन ख़ान\n",
      "False\n",
      "रवीन्द्र प्रभात\n",
      "False\n",
      "नाहिद हसन\n",
      "False\n",
      "ओम प्रकाश वर्मा\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(df['name']):\n",
    "    if df['alphabet'][i] == 'DEVANAGARI':\n",
    "        print(df['name'][i])\n",
    "        print(df['name'][i].isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accents (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leters with accents\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "import unicodedata\n",
    "\n",
    "text_with_accents = \"Létérs wïth âccénts\"\n",
    "normalized_text = unidecode(text_with_accents)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "langname = lambda x : unicodedata.name(x[0]).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'춘', '수', 'ć', 'ế', 'ೇ', '신', 'Ș', 'ķ', 'ṣ', 'ো', 'ô', 'ừ', 'ọ', 'ì', 'ă', 'ń', 'ò', '동', '일', 'ί', 'ώ', 'Ü', '태', 'أ', 'å', 'č', 'ț', 'ű', 'ễ', 'Ž', 'ņ', 'ż', 'ặ', 'ё', '랑', 'ū', '정', 'ļ', 'Ż', 'Ö', 'ú', '헌', 'ą', 'ǔ', 'Ä', 'Å', 'ž', 'ạ', '현', 'ň', 'Â', 'ṭ', '김', 'ũ', 'ÿ', '겸', 'ù', 'ố', 'ţ', 'Ľ', '보', 'ǎ', 'ģ', 'š', 'ǫ', 'ό', 'ê', '민', 'ź', 'Ş', 'ά', 'ụ', 'ؤ', 'í', '규', 'Ō', 'Í', 'ầ', 'ǒ', 'ů', 'ē', 'ś', 'ơ', 'ῑ', '순', 'İ', 'й', 'ắ', 'ǚ', '송', 'Ḥ', '건', 'έ', '원', 'ę', 'ě', 'Ī', 'Ț', 'ứ', '허', '기', 'ç', 'ý', 'î', 'â', '식', 'è', '권', 'ৌ', 'ã', '진', 'إ', 'Ř', 'õ', 'ĩ', 'ớ', 'Š', 'ő', 'ằ', '윤', 'ペ', '섭', 'ữ', '녕', 'ờ', 'ồ', 'ï', 'Ś', 'ệ', 'ī', '환', '상', 'ó', 'Ó', 'Ć', 'É', 'ä', 'ủ', '조', '이', '철', '박', 'à', 'Ú', 'ೀ', '최', 'ύ', 'û', 'ḫ', 'ė', '재', '명', 'ǐ', 'Ṭ', '대', 'ř', 'ỹ', 'é', 'ş', 'Ç', 'Ѓ', '연', 'ë', 'ợ', 'Ḫ', '홍', '긍', 'ō', 'á', '형', 'ș', 'ị', '광', 'ề', '강', 'ď', '석', '하', 'ド', 'ü', 'Č', 'ľ', 'ї', 'ả', '노', 'ö', 'Á', 'ā', 'ấ', 'ñ', 'ῖ', '영', 'ư', 'ŭ', 'ğ'}\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "def identify_accents(text):\n",
    "    accents = []\n",
    "    for char in text:\n",
    "        if unicodedata.normalize('NFD', char) != char:\n",
    "            accents.append(char)\n",
    "    return accents\n",
    "allaccents= set()\n",
    "for i in df['name']:\n",
    "    allaccents.update(identify_accents(i))\n",
    "print(allaccents)\n",
    "print(len(allaccents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ć', 'ế', 'ೇ', 'Ș', 'ķ', 'ṣ', 'ো', 'ô', 'ừ', 'ọ', 'ì', 'ă', 'ń', 'ò', 'ί', 'ώ', 'Ü', 'أ', 'å', 'č', 'ț', 'ű', 'ễ', 'Ž', 'ņ', 'ż', 'ặ', 'ё', 'ū', 'ļ', 'Ż', 'Ö', 'ú', 'ą', 'ǔ', 'Ä', 'Å', 'ž', 'ạ', 'ň', 'Â', 'ṭ', 'ũ', 'ÿ', 'ù', 'ố', 'ţ', 'Ľ', 'ǎ', 'ģ', 'š', 'ǫ', 'ό', 'ê', 'ź', 'Ş', 'ά', 'ụ', 'ؤ', 'í', 'Ō', 'Í', 'ầ', 'ǒ', 'ů', 'ē', 'ś', 'ơ', 'ῑ', 'İ', 'й', 'ắ', 'ǚ', 'Ḥ', 'έ', 'ę', 'ě', 'Ī', 'Ț', 'ứ', 'ç', 'ý', 'î', 'â', 'è', 'ৌ', 'ã', 'إ', 'Ř', 'õ', 'ĩ', 'ớ', 'Š', 'ő', 'ằ', 'ペ', 'ữ', 'ờ', 'ồ', 'ï', 'Ś', 'ệ', 'ī', 'ó', 'Ó', 'Ć', 'É', 'ä', 'ủ', 'à', 'Ú', 'ೀ', 'ύ', 'û', 'ḫ', 'ė', 'ǐ', 'Ṭ', 'ř', 'ỹ', 'é', 'ş', 'Ç', 'Ѓ', 'ë', 'ợ', 'Ḫ', 'ō', 'á', 'ș', 'ị', 'ề', 'ď', 'ド', 'ü', 'Č', 'ľ', 'ї', 'ả', 'ö', 'Á', 'ā', 'ấ', 'ñ', 'ῖ', 'ư', 'ŭ', 'ğ']\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "allaccents1 = []\n",
    "for i in allaccents:\n",
    "    if langname(str(i)) != 'HANGUL':\n",
    "        allaccents1.append(i)\n",
    "print(allaccents1)\n",
    "print(len(allaccents1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize('NFD', '안녕하세요') == '안녕하세요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'안녕하세요' == '안녕하세요'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating langname2 as another option to find the alphabet name for each character in a name instead of just the first letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LATIN', 'CAPITAL', 'LETTER', 'R'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'A'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'H'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'A'],\n",
       " ['SPACE'],\n",
       " ['LATIN', 'CAPITAL', 'LETTER', 'E'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'T'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'E'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'M'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'A'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'D'],\n",
       " ['LATIN', 'SMALL', 'LETTER', 'I']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langname2 = lambda x: [unicodedata.name(char).split(' ') for char in x]\n",
    "langname2('Raha Etemadi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for non alphabet characters in each names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leena Peltonen-Palotie', 'R. M. Dharmadasa Banda', 'Vicente de Valverde y Alvarez de Toledo, O.P.', 'Ute Kircheis-Wessel', 'David John (Dave) Shannon', 'Dr. Joan W. Miller', 'Donald M. Davis', 'Akseli Gallen-Kallela', 'Gerald S. McGowan', 'Jung Chul-Woon']\n",
      "4841\n",
      "{'GREEK', 'HEBREW', 'CYRILLIC', 'HANGUL', 'CJK', 'SYRIAC', 'ARMENIAN', 'LATIN', 'KATAKANA', 'ARABIC'}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "alphabet1 = []\n",
    "notalpha = []\n",
    "for i in df['name']:\n",
    "    tempword = i.split()\n",
    "    if (all(word.isalpha() == True for word in tempword)):\n",
    "        alphabet1.append(langname(i))\n",
    "    else: \n",
    "        notalpha.append(i)\n",
    "print(notalpha[0:10])\n",
    "print(len(notalpha))\n",
    "print(set(alphabet1))\n",
    "print(len(set(alphabet1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg_token_length (complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raha Etemadi\n"
     ]
    }
   ],
   "source": [
    "print(df2['name'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_token_length(name):\n",
    "    total_length = 0\n",
    "    total_tokens = 0\n",
    "    # Tokenize the name (split by spaces)\n",
    "    tokens = name.split()\n",
    "\n",
    "    # Calculate the total length of tokens in the name\n",
    "    token_length = sum(len(token) for token in tokens)\n",
    "\n",
    "    # Total length (characters in each word) and total number of tokens (words in name)\n",
    "    total_length += token_length\n",
    "    total_tokens += len(tokens)\n",
    "    # Calculate the average token length\n",
    "    if total_tokens > 0:\n",
    "        average_length = total_length / total_tokens\n",
    "        return average_length\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "avg_token_length = []\n",
    "for i in df2['name']:\n",
    "    avg_token_length.append(average_token_length(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['avg_token_length'] = avg_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raha Etemadi</td>\n",
       "      <td>1</td>\n",
       "      <td>et</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luma Grothe</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Takuya Kakine</td>\n",
       "      <td>1</td>\n",
       "      <td>ja</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ōuyáng Zhènhuá</td>\n",
       "      <td>1</td>\n",
       "      <td>mi</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Gideon Archer</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42913</th>\n",
       "      <td>Clyde Donaldson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42914</th>\n",
       "      <td>Terry Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42915</th>\n",
       "      <td>Neil Roebuck</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42916</th>\n",
       "      <td>Lyle Stewart</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42917</th>\n",
       "      <td>Thomas Colclough Watson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42918 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  class lang alphabet  avg_token_length  \\\n",
       "0                 Raha Etemadi      1   et    LATIN               5.5   \n",
       "1                  Luma Grothe      1   en    LATIN               5.0   \n",
       "2                Takuya Kakine      1   ja    LATIN               6.0   \n",
       "3               Ōuyáng Zhènhuá      1   mi    LATIN               6.5   \n",
       "4         Jordan Gideon Archer      1   en    LATIN               6.0   \n",
       "...                        ...    ...  ...      ...               ...   \n",
       "42913          Clyde Donaldson      1   en    LATIN               7.0   \n",
       "42914          Terry Alexander      1   en    LATIN               7.0   \n",
       "42915             Neil Roebuck      1   en    LATIN               5.5   \n",
       "42916             Lyle Stewart      1   en    LATIN               5.5   \n",
       "42917  Thomas Colclough Watson      1   en    LATIN               7.0   \n",
       "\n",
       "       num_tokens  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               3  \n",
       "...           ...  \n",
       "42913           2  \n",
       "42914           2  \n",
       "42915           2  \n",
       "42916           2  \n",
       "42917           3  \n",
       "\n",
       "[42918 rows x 6 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_len(name):\n",
    "    total_tokens = 0\n",
    "    tokens = name.split()\n",
    "    # Total number of tokens (words in name)\n",
    "    total_tokens += len(tokens)\n",
    "    return total_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = []\n",
    "for i in df2['name']:\n",
    "    token_length.append(token_len(i))\n",
    "df2['num_tokens'] = token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raha Etemadi</td>\n",
       "      <td>1</td>\n",
       "      <td>et</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luma Grothe</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Takuya Kakine</td>\n",
       "      <td>1</td>\n",
       "      <td>ja</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ōuyáng Zhènhuá</td>\n",
       "      <td>1</td>\n",
       "      <td>mi</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jordan Gideon Archer</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42913</th>\n",
       "      <td>Clyde Donaldson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42914</th>\n",
       "      <td>Terry Alexander</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42915</th>\n",
       "      <td>Neil Roebuck</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42916</th>\n",
       "      <td>Lyle Stewart</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42917</th>\n",
       "      <td>Thomas Colclough Watson</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>LATIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42918 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  class lang alphabet  avg_token_length  \\\n",
       "0                 Raha Etemadi      1   et    LATIN               5.5   \n",
       "1                  Luma Grothe      1   en    LATIN               5.0   \n",
       "2                Takuya Kakine      1   ja    LATIN               6.0   \n",
       "3               Ōuyáng Zhènhuá      1   mi    LATIN               6.5   \n",
       "4         Jordan Gideon Archer      1   en    LATIN               6.0   \n",
       "...                        ...    ...  ...      ...               ...   \n",
       "42913          Clyde Donaldson      1   en    LATIN               7.0   \n",
       "42914          Terry Alexander      1   en    LATIN               7.0   \n",
       "42915             Neil Roebuck      1   en    LATIN               5.5   \n",
       "42916             Lyle Stewart      1   en    LATIN               5.5   \n",
       "42917  Thomas Colclough Watson      1   en    LATIN               7.0   \n",
       "\n",
       "       num_tokens  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               3  \n",
       "...           ...  \n",
       "42913           2  \n",
       "42914           2  \n",
       "42915           2  \n",
       "42916           2  \n",
       "42917           3  \n",
       "\n",
       "[42918 rows x 6 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### space_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
