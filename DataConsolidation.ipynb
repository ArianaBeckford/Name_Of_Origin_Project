{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Model training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was originally for frequency distributions for Latin names!\n",
    "but we can also concat the other dfs / do model training after in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo = pd.read_pickle('df_indo.pkl.gz', compression = 'gzip')\n",
    "df_malay = pd.read_pickle('df_malay.pkl.gz', compression = 'gzip')\n",
    "df_viet = pd.read_pickle('viet_df.pkl.gz', compression = 'gzip')\n",
    "df_cnrom = pd.read_pickle('cnrom_df.pkl.gz', compression = 'gzip')\n",
    "df_cnchar = pd.read_pickle('cnchar_df.pkl.gz', compression = 'gzip')\n",
    "df_turk = pd.read_pickle('turkish_df.pkl.gz', compression = 'gzip')\n",
    "df_korean = pd.read_pickle('korean_df.pkl.gz', compression ='gzip') \n",
    "# import company csv\n",
    "\n",
    "all_dfs = [df_indo, df_malay, df_viet, df_cnrom, df_cnchar, df_turk, df_korean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indonesian : 11246\n",
      "Malay : 2908\n",
      "Vietnamese : 2290\n",
      "Chinese (Romanized) : 10478\n",
      "Chinese (Characters) : 11055\n",
      "Turkish : 18037\n",
      "Korean (Romanized & Characters) : 19118\n"
     ]
    }
   ],
   "source": [
    "# finding percentages\n",
    "df_names = ['Indonesian', 'Malay', 'Vietnamese', 'Chinese (Romanized)', 'Chinese (Characters)', 'Turkish', 'Korean (Romanized & Characters)']\n",
    "total_size = 0\n",
    "\n",
    "for i, df in enumerate(all_dfs):\n",
    "    total_size += df.shape[0]\n",
    "    print(df_names[i], ':', df.shape[0])\n",
    "    \n",
    "# for i, df in enumerate(all_dfs):\n",
    "#     print(df_names[i], ':', df.shape[0] / total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names to KEEP: (10 so far)\n",
    "\n",
    "* name_length\n",
    "* avg_token_length\n",
    "* num_tokens\n",
    "* period_freq\n",
    "* dash_freq\n",
    "* apostrophe_freq\n",
    "* space_freq\n",
    "* unigrams_cosine_sim\n",
    "* bigrams_cosine_sim\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>từ hoàng thông</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(T,), (ừ,), ( ,), (H,), (o,), (à,), (n,), (g,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tu hoang thong</td>\n",
       "      <td>[t, ừ,  , h, o, à, n, g,  , t, h, ô, n, g]</td>\n",
       "      <td>[(t, ừ), (ừ,  ), ( , h), (h, o), (o, à), (à, n...</td>\n",
       "      <td>[(t, ừ,  ), (ừ,  , h), ( , h, o), (h, o, à), (...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07...</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.508198</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nguyễn thị phương thảo</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>[(N,), (g,), (u,), (y,), (ễ,), (n,), ( ,), (T,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>nguyen thi phuong thao</td>\n",
       "      <td>[n, g, u, y, ễ, n,  , t, h, ị,  , p, h, ư, ơ, ...</td>\n",
       "      <td>[(n, g), (g, u), (u, y), (y, ễ), (ễ, n), (n,  ...</td>\n",
       "      <td>[(n, g, u), (g, u, y), (u, y, ễ), (y, ễ, n), (...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>[[0.13636363636363635, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.884792</td>\n",
       "      <td>0.667716</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nick út</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[(N,), (i,), (c,), (k,), ( ,), (Ú,), (t,), (N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nick ut</td>\n",
       "      <td>[n, i, c, k,  , ú, t]</td>\n",
       "      <td>[(n, i), (i, c), (c, k), (k,  ), ( , ú), (ú, t)]</td>\n",
       "      <td>[(n, i, c), (i, c, k), (c, k,  ), (k,  , ú), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.14285714285...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.592690</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cao văn lầu</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(C,), (a,), (o,), ( ,), (V,), (ă,), (n,), ( ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>cao van lau</td>\n",
       "      <td>[c, a, o,  , v, ă, n,  , l, ầ, u]</td>\n",
       "      <td>[(c, a), (a, o), (o,  ), ( , v), (v, ă), (ă, n...</td>\n",
       "      <td>[(c, a, o), (a, o,  ), (o,  , v), ( , v, ă), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.18181818181818182, 0.09090909090909091, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665965</td>\n",
       "      <td>0.243176</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tạ thu thâu</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(T,), (ạ,), ( ,), (T,), (h,), (u,), ( ,), (T,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ta thu thau</td>\n",
       "      <td>[t, ạ,  , t, h, u,  , t, h, â, u]</td>\n",
       "      <td>[(t, ạ), (ạ,  ), ( , t), (t, h), (h, u), (u,  ...</td>\n",
       "      <td>[(t, ạ,  ), (ạ,  , t), ( , t, h), (t, h, u), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.596114</td>\n",
       "      <td>0.288942</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fullname                                           alphabet  \\\n",
       "0          từ hoàng thông  [LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...   \n",
       "1  nguyễn thị phương thảo  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "2                 nick út  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]   \n",
       "3             cao văn lầu  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   \n",
       "4             tạ thu thâu  [LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, SPA...   \n",
       "\n",
       "   name_length  num_tokens                                        char_ngrams  \\\n",
       "0           14           3  [(T,), (ừ,), ( ,), (H,), (o,), (à,), (n,), (g,...   \n",
       "1           22           4  [(N,), (g,), (u,), (y,), (ễ,), (n,), ( ,), (T,...   \n",
       "2            7           2  [(N,), (i,), (c,), (k,), ( ,), (Ú,), (t,), (N,...   \n",
       "3           11           3  [(C,), (a,), (o,), ( ,), (V,), (ă,), (n,), ( ,...   \n",
       "4           11           3  [(T,), (ạ,), ( ,), (T,), (h,), (u,), ( ,), (T,...   \n",
       "\n",
       "   period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "0            0          0           2                0   \n",
       "1            0          0           3                0   \n",
       "2            0          0           1                0   \n",
       "3            0          0           2                0   \n",
       "4            0          0           2                0   \n",
       "\n",
       "          transliteration                                           unigrams  \\\n",
       "0          tu hoang thong         [t, ừ,  , h, o, à, n, g,  , t, h, ô, n, g]   \n",
       "1  nguyen thi phuong thao  [n, g, u, y, ễ, n,  , t, h, ị,  , p, h, ư, ơ, ...   \n",
       "2                 nick ut                              [n, i, c, k,  , ú, t]   \n",
       "3             cao van lau                  [c, a, o,  , v, ă, n,  , l, ầ, u]   \n",
       "4             ta thu thau                  [t, ạ,  , t, h, u,  , t, h, â, u]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(t, ừ), (ừ,  ), ( , h), (h, o), (o, à), (à, n...   \n",
       "1  [(n, g), (g, u), (u, y), (y, ễ), (ễ, n), (n,  ...   \n",
       "2   [(n, i), (i, c), (c, k), (k,  ), ( , ú), (ú, t)]   \n",
       "3  [(c, a), (a, o), (o,  ), ( , v), (v, ă), (ă, n...   \n",
       "4  [(t, ạ), (ạ,  ), ( , t), (t, h), (h, u), (u,  ...   \n",
       "\n",
       "                                            trigrams  avg_token_length  \\\n",
       "0  [(t, ừ,  ), (ừ,  , h), ( , h, o), (h, o, à), (...              4.00   \n",
       "1  [(n, g, u), (g, u, y), (u, y, ễ), (y, ễ, n), (...              4.75   \n",
       "2  [(n, i, c), (i, c, k), (c, k,  ), (k,  , ú), (...              3.00   \n",
       "3  [(c, a, o), (a, o,  ), (o,  , v), ( , v, ă), (...              3.00   \n",
       "4  [(t, ạ,  ), (ạ,  , t), ( , t, h), (t, h, u), (...              3.00   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  [[0.13636363636363635, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[0.14285714285714285, 0.0, 0.0, 0.14285714285...   \n",
       "3  [[0.18181818181818182, 0.09090909090909091, 0....   \n",
       "4  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07...             0.805625   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.884792   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.592690   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665965   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.596114   \n",
       "\n",
       "   bigrams_cosine_sim    language  \n",
       "0            0.508198  Vietnamese  \n",
       "1            0.667716  Vietnamese  \n",
       "2            0.005600  Vietnamese  \n",
       "3            0.243176  Vietnamese  \n",
       "4            0.288942  Vietnamese  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is where you rename columns to all match\n",
    "df_viet.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnrom.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnchar.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_viet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Redoing frequency distributions across all Latin names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Frequency Distribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from IndoMalay.ipynb\n",
    "\n",
    "def create_lang_char_distribution(df, col_name):\n",
    "    char_freqs = {}\n",
    "    total_num_chars = 0  # across the entire language/dataset\n",
    "\n",
    "    for name in df[col_name]:\n",
    "        for char in name:\n",
    "            if char not in char_freqs.keys():\n",
    "                char_freqs[char] = 1\n",
    "            else:\n",
    "                char_freqs[char] += 1\n",
    "            total_num_chars += 1\n",
    "\n",
    "    char_freqs_relative = dict(sorted({char: count / total_num_chars for char, count in char_freqs.items()}.items()))\n",
    "    return char_freqs_relative\n",
    "\n",
    "def initialize_all_possible_bigrams(all_possible_chars):\n",
    "    all_possible_bigrams = {}\n",
    "    for first_char in all_possible_chars:  # first character of the current bigram\n",
    "        for second_char in all_possible_chars:  # second character of the current bigram\n",
    "            all_possible_bigrams[(first_char, second_char)] = 0\n",
    "    return all_possible_bigrams\n",
    "\n",
    "def create_lang_gram_distribution(initialized_grams, df, col_name):\n",
    "    gram_freqs = initialized_grams.copy()  # need a copy otherwise initiailized_grams is changed\n",
    "    total_num_grams = 0  # across the entire language/dataset\n",
    "    \n",
    "    for grams_list in df[col_name]:\n",
    "        for gram in grams_list:\n",
    "            gram_freqs[gram] += 1\n",
    "            total_num_grams += 1\n",
    "    \n",
    "    gram_freqs_relative = {gram: count / total_num_grams for gram, count in gram_freqs.items()}\n",
    "    return gram_freqs_relative\n",
    "\n",
    "def initialize_all_possible_trigrams(all_possible_chars):\n",
    "    all_possible_trigrams = {}\n",
    "    for first_char in all_possible_chars:  # first character of the current trigram\n",
    "        for second_char in all_possible_chars:  # second character of the current trigram\n",
    "            for third_char in all_possible_chars:  # third character of the current trigram\n",
    "                all_possible_trigrams[(first_char, second_char, third_char)] = 0\n",
    "    return all_possible_trigrams\n",
    "\n",
    "def create_indiv_gram_distribution(grams_list, initialized_grams):\n",
    "    gram_freqs_relative = initialized_grams.copy()  \n",
    "    num_grams = len(grams_list)  # for this current example\n",
    "    \n",
    "    for gram in grams_list:\n",
    "        gram_freqs_relative[gram] += 1 / num_grams\n",
    "\n",
    "    return gram_freqs_relative\n",
    "\n",
    "def set_indiv_trigram_dist(trigrams_list, init_trigrams):\n",
    "    trigrams_fdist_relative = init_trigrams\n",
    "    num_grams = len(trigrams_list)\n",
    "\n",
    "    for gram in trigrams_list:\n",
    "        trigrams_fdist_relative[gram] += 1 / num_grams\n",
    "\n",
    "    return trigrams_fdist_relative\n",
    "\n",
    "# TRIGRAMS individual frequency distributions\n",
    "#df_indo['indiv_trigrams_fdist'] = df_indo.apply(lambda row: set_indiv_trigram_dist(row['trigrams'], row['indiv_trigrams_fdist']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Determining which languages use Latin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these lines of code to work, the datasets must have been pickled to preserve data types! `pd.csv` turns everything into strings; for example, a list of `[LATIN, LATIN, LATIN, ...]` becomes `'[LATIN, LATIN, LATIN, ...]'` (i.e., `'['` becomes a character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589739940220817"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indo_latin_percent = create_lang_char_distribution(df_indo, 'alphabet')['LATIN']\n",
    "malay_latin_percent = create_lang_char_distribution(df_malay, 'alphabet')['LATIN']\n",
    "viet_latin_percent = create_lang_char_distribution(df_viet, 'alphabet')['LATIN']\n",
    "cnrom_latin_percent = create_lang_char_distribution(df_cnrom, 'alphabet')['LATIN']\n",
    "# cnchar_latin_percent = create_lang_char_distribution(df_cnchar, 'alphabet')['LATIN'] error -> no latin\n",
    "turk_latin_percent = create_lang_char_distribution(df_turk, 'alphabet')['LATIN']\n",
    "korean_latin_percent = create_lang_char_distribution(df_korean, 'alphabet')['LATIN']\n",
    "korean_latin_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁一平</td>\n",
       "      <td>ding yi ping</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , p, i, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.774279</td>\n",
       "      <td>0.548928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁世雄</td>\n",
       "      <td>ding shi xiong</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , s, h, i,  , x, i, o, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.811762</td>\n",
       "      <td>0.560151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丁亦昕</td>\n",
       "      <td>ding yi xin</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , x, i, n]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.510394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>丁仲礼</td>\n",
       "      <td>ding zhong li</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...</td>\n",
       "      <td>[d, i, n, g,  , z, h, o, n, g,  , l, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.605839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>丁伟</td>\n",
       "      <td>ding wei</td>\n",
       "      <td>[CJK, CJK]</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , w, e, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>[[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.440812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_fullname transliteration         alphabet  name_length  num_tokens  \\\n",
       "0               丁一平    ding yi ping  [CJK, CJK, CJK]           12           3   \n",
       "1               丁世雄  ding shi xiong  [CJK, CJK, CJK]           14           3   \n",
       "2               丁亦昕     ding yi xin  [CJK, CJK, CJK]           11           3   \n",
       "3               丁仲礼   ding zhong li  [CJK, CJK, CJK]           13           3   \n",
       "4                丁伟        ding wei       [CJK, CJK]            8           2   \n",
       "\n",
       "                                         char_ngrams  \\\n",
       "0  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "1  [(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...   \n",
       "2  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "3  [(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...   \n",
       "4  [(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...   \n",
       "\n",
       "                                     unigrams  \\\n",
       "0        [d, i, n, g,  , y, i,  , p, i, n, g]   \n",
       "1  [d, i, n, g,  , s, h, i,  , x, i, o, n, g]   \n",
       "2           [d, i, n, g,  , y, i,  , x, i, n]   \n",
       "3     [d, i, n, g,  , z, h, o, n, g,  , l, i]   \n",
       "4                    [d, i, n, g,  , w, e, i]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "1  [(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...   \n",
       "2  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "3  [(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...   \n",
       "4  [(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...   \n",
       "\n",
       "                                            trigrams  period_freq  dash_freq  \\\n",
       "0  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "1  [(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...            0          0   \n",
       "2  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "3  [(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...            0          0   \n",
       "4  [(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...            0          0   \n",
       "\n",
       "   space_freq  apostrophe_freq  avg_token_length  \\\n",
       "0           2                0          3.333333   \n",
       "1           2                0          4.000000   \n",
       "2           2                0          3.000000   \n",
       "3           2                0          3.666667   \n",
       "4           1                0          3.500000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...   \n",
       "1  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...   \n",
       "2  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...   \n",
       "3  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...   \n",
       "4  [[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.774279   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.811762   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.776390   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.841584   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.710349   \n",
       "\n",
       "   bigrams_cosine_sim  \n",
       "0            0.548928  \n",
       "1            0.560151  \n",
       "2            0.510394  \n",
       "3            0.605839  \n",
       "4            0.440812  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnchar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>Park Joo-bong</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...</td>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g]</td>\n",
       "      <td>[(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...</td>\n",
       "      <td>[(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>[[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.377660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>KIM Jong hoon</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n]</td>\n",
       "      <td>[(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...</td>\n",
       "      <td>[(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.552090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이민혁</td>\n",
       "      <td>이민혁</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>iminhyeog</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g]</td>\n",
       "      <td>[(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...</td>\n",
       "      <td>[(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.757701</td>\n",
       "      <td>0.344410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lee ho</td>\n",
       "      <td>Lee Ho</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]</td>\n",
       "      <td>lee ho</td>\n",
       "      <td>[l, e, e,  , h, o]</td>\n",
       "      <td>[(l, e), (e, e), (e,  ), ( , h), (h, o)]</td>\n",
       "      <td>[(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]</td>\n",
       "      <td>[l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.537098</td>\n",
       "      <td>0.143205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최민호</td>\n",
       "      <td>최민호</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>choeminho</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o]</td>\n",
       "      <td>[(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...</td>\n",
       "      <td>[(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665396</td>\n",
       "      <td>0.171394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fullname original_fullname  \\\n",
       "0  park joo-bong     Park Joo-bong   \n",
       "1  kim jong hoon     KIM Jong hoon   \n",
       "2            이민혁               이민혁   \n",
       "3         lee ho            Lee Ho   \n",
       "4            최민호               최민호   \n",
       "\n",
       "                                            alphabet transliteration  \\\n",
       "0  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...   park joo-bong   \n",
       "1  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   kim jong hoon   \n",
       "2                           [HANGUL, HANGUL, HANGUL]       iminhyeog   \n",
       "3         [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]          lee ho   \n",
       "4                           [HANGUL, HANGUL, HANGUL]       choeminho   \n",
       "\n",
       "                                  unigrams  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g]   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n]   \n",
       "2              [i, m, i, n, h, y, e, o, g]   \n",
       "3                       [l, e, e,  , h, o]   \n",
       "4              [c, h, o, e, m, i, n, h, o]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...   \n",
       "1  [(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...   \n",
       "2  [(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...   \n",
       "3           [(l, e), (e, e), (e,  ), ( , h), (h, o)]   \n",
       "4  [(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...   \n",
       "1  [(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...   \n",
       "2  [(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...   \n",
       "3       [(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]   \n",
       "4  [(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...   \n",
       "\n",
       "                                         char_ngrams  num_tokens  period_freq  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...           2            0   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...           3            0   \n",
       "2  [i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...           1            0   \n",
       "3  [l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...           2            0   \n",
       "4  [c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...           1            0   \n",
       "\n",
       "   dash_freq  space_freq  name_length  avg_token_length  \\\n",
       "0          1           1           13          6.000000   \n",
       "1          0           2           13          3.666667   \n",
       "2          0           0            9          9.000000   \n",
       "3          0           1            6          2.500000   \n",
       "4          0           0            9          9.000000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.680590   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.762211   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.757701   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.537098   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665396   \n",
       "\n",
       "   bigrams_cosine_sim  \n",
       "0            0.377660  \n",
       "1            0.552090  \n",
       "2            0.344410  \n",
       "3            0.143205  \n",
       "4            0.171394  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. Remaking Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add a_hat_freq and turn categorical columns into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD after Maker Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see 10/16 anna meeting notes for ideas on more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cleaning up other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullname', 'original_fullname', 'alphabet', 'transliteration',\n",
       "       'unigrams', 'bigrams', 'trigrams', 'char_ngrams', 'num_tokens',\n",
       "       'period_freq', 'dash_freq', 'space_freq', 'name_length',\n",
       "       'avg_token_length', 'indiv_unigrams_fdist', 'indiv_bigrams_fdist',\n",
       "       'unigrams_cosine_sim', 'bigrams_cosine_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label_tr', 'original_fullname', 'fullname', 'alphabet',\n",
       "       'unigrams', 'bigrams', 'trigrams', 'char_ngrams', 'name_length',\n",
       "       'num_tokens', 'avg_token_length', 'period_freq', 'dash_freq',\n",
       "       'space_freq', 'transliteration', 'indiv_unigrams_fdist',\n",
       "       'indiv_bigrams_fdist', 'indiv_trigrams_fdist', 'unigrams_cosine_sim',\n",
       "       'bigrams_cosine_sim', 'trigrams_cosine_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turk['apostrophe_freq'] = df_turk['fullname'].apply(lambda name: name.count('\\''))\n",
    "df_korean['apostrophe_freq'] = df_korean['fullname'].apply(lambda name: name.count('\\''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adding the language (label) to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indo['language'] = 'Indonesian'\n",
    "df_malay['language'] = 'Malay'\n",
    "df_viet['language'] = 'Vietnamese'\n",
    "df_cnrom['language'] = 'Chinese (Romanized)'\n",
    "df_cnchar['language'] = 'Chinese (Characters)'\n",
    "df_turk['language'] = 'Turkish'\n",
    "df_korean['language'] = 'Korean' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining all names to make one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>indiv_trigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>label_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supriyadi</td>\n",
       "      <td>Supriyadi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, u, p, r, i, y, a, d, i]</td>\n",
       "      <td>[(s, u), (u, p), (p, r), (r, i), (i, y), (y, a...</td>\n",
       "      <td>[(s, u, p), (u, p, r), (p, r, i), (r, i, y), (...</td>\n",
       "      <td>[s, u, p, r, i, y, a, d, i, (s, u), (u, p), (p...</td>\n",
       "      <td>[supriyadi]</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triyaningsih</td>\n",
       "      <td>Triyaningsih</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[t, r, i, y, a, n, i, n, g, s, i, h]</td>\n",
       "      <td>[(t, r), (r, i), (i, y), (y, a), (a, n), (n, i...</td>\n",
       "      <td>[(t, r, i), (r, i, y), (i, y, a), (y, a, n), (...</td>\n",
       "      <td>[t, r, i, y, a, n, i, n, g, s, i, h, (t, r), (...</td>\n",
       "      <td>[triyaningsih]</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soerjadi</td>\n",
       "      <td>Soerjadi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, o, e, r, j, a, d, i]</td>\n",
       "      <td>[(s, o), (o, e), (e, r), (r, j), (j, a), (a, d...</td>\n",
       "      <td>[(s, o, e), (o, e, r), (e, r, j), (r, j, a), (...</td>\n",
       "      <td>[s, o, e, r, j, a, d, i, (s, o), (o, e), (e, r...</td>\n",
       "      <td>[soerjadi]</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0.090295</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undunsyah</td>\n",
       "      <td>Undunsyah</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[u, n, d, u, n, s, y, a, h]</td>\n",
       "      <td>[(u, n), (n, d), (d, u), (u, n), (n, s), (s, y...</td>\n",
       "      <td>[(u, n, d), (n, d, u), (d, u, n), (u, n, s), (...</td>\n",
       "      <td>[u, n, d, u, n, s, y, a, h, (u, n), (n, d), (d...</td>\n",
       "      <td>[undunsyah]</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.060083</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soeripto</td>\n",
       "      <td>Soeripto</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, o, e, r, i, p, t, o]</td>\n",
       "      <td>[(s, o), (o, e), (e, r), (r, i), (i, p), (p, t...</td>\n",
       "      <td>[(s, o, e), (o, e, r), (e, r, i), (r, i, p), (...</td>\n",
       "      <td>[s, o, e, r, i, p, t, o, (s, o), (o, e), (e, r...</td>\n",
       "      <td>[soeripto]</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75127</th>\n",
       "      <td>lee han-wi</td>\n",
       "      <td>Lee Han-wi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>[l, e, e,  , h, a, n, -, w, i]</td>\n",
       "      <td>[(l, e), (e, e), (e,  ), ( , h), (h, a), (a, n...</td>\n",
       "      <td>[(l, e, e), (e, e,  ), (e,  , h), ( , h, a), (...</td>\n",
       "      <td>[l, e, e,  , h, a, n, -, w, i, (l, e), (e, e),...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675313</td>\n",
       "      <td>0.212623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75128</th>\n",
       "      <td>gil jung-woo</td>\n",
       "      <td>Gil Jung-woo</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>[g, i, l,  , j, u, n, g, -, w, o, o]</td>\n",
       "      <td>[(g, i), (i, l), (l,  ), ( , j), (j, u), (u, n...</td>\n",
       "      <td>[(g, i, l), (i, l,  ), (l,  , j), ( , j, u), (...</td>\n",
       "      <td>[g, i, l,  , j, u, n, g, -, w, o, o, (g, i), (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769942</td>\n",
       "      <td>0.394563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75129</th>\n",
       "      <td>이정희</td>\n",
       "      <td>이정희</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>[i, j, e, o, n, g, h, u, i]</td>\n",
       "      <td>[(i, j), (j, e), (e, o), (o, n), (n, g), (g, h...</td>\n",
       "      <td>[(i, j, e), (j, e, o), (e, o, n), (o, n, g), (...</td>\n",
       "      <td>[i, j, e, o, n, g, h, u, i, (i, j), (j, e), (e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777239</td>\n",
       "      <td>0.508705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75130</th>\n",
       "      <td>금태섭</td>\n",
       "      <td>금태섭</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>[g, e, u, m, t, a, e, s, e, o, b]</td>\n",
       "      <td>[(g, e), (e, u), (u, m), (m, t), (t, a), (a, e...</td>\n",
       "      <td>[(g, e, u), (e, u, m), (u, m, t), (m, t, a), (...</td>\n",
       "      <td>[g, e, u, m, t, a, e, s, e, o, b, (g, e), (e, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614584</td>\n",
       "      <td>0.229460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75131</th>\n",
       "      <td>oh ui-sik</td>\n",
       "      <td>Oh Ui-sik</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, HYPHEN-MIN...</td>\n",
       "      <td>[o, h,  , u, i, -, s, i, k]</td>\n",
       "      <td>[(o, h), (h,  ), ( , u), (u, i), (i, -), (-, s...</td>\n",
       "      <td>[(o, h,  ), (h,  , u), ( , u, i), (u, i, -), (...</td>\n",
       "      <td>[o, h,  , u, i, -, s, i, k, (o, h), (h,  ), ( ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592052</td>\n",
       "      <td>0.067721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75132 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fullname original_fullname  \\\n",
       "0         supriyadi         Supriyadi   \n",
       "1      triyaningsih      Triyaningsih   \n",
       "2          soerjadi          Soerjadi   \n",
       "3         undunsyah         Undunsyah   \n",
       "4          soeripto          Soeripto   \n",
       "...             ...               ...   \n",
       "75127    lee han-wi        Lee Han-wi   \n",
       "75128  gil jung-woo      Gil Jung-woo   \n",
       "75129           이정희               이정희   \n",
       "75130           금태섭               금태섭   \n",
       "75131     oh ui-sik         Oh Ui-sik   \n",
       "\n",
       "                                                alphabet  \\\n",
       "0      [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "1      [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "2      [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "3      [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "4      [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "...                                                  ...   \n",
       "75127  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   \n",
       "75128  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   \n",
       "75129                           [HANGUL, HANGUL, HANGUL]   \n",
       "75130                           [HANGUL, HANGUL, HANGUL]   \n",
       "75131  [LATIN, LATIN, SPACE, LATIN, LATIN, HYPHEN-MIN...   \n",
       "\n",
       "                                   unigrams  \\\n",
       "0               [s, u, p, r, i, y, a, d, i]   \n",
       "1      [t, r, i, y, a, n, i, n, g, s, i, h]   \n",
       "2                  [s, o, e, r, j, a, d, i]   \n",
       "3               [u, n, d, u, n, s, y, a, h]   \n",
       "4                  [s, o, e, r, i, p, t, o]   \n",
       "...                                     ...   \n",
       "75127        [l, e, e,  , h, a, n, -, w, i]   \n",
       "75128  [g, i, l,  , j, u, n, g, -, w, o, o]   \n",
       "75129           [i, j, e, o, n, g, h, u, i]   \n",
       "75130     [g, e, u, m, t, a, e, s, e, o, b]   \n",
       "75131           [o, h,  , u, i, -, s, i, k]   \n",
       "\n",
       "                                                 bigrams  \\\n",
       "0      [(s, u), (u, p), (p, r), (r, i), (i, y), (y, a...   \n",
       "1      [(t, r), (r, i), (i, y), (y, a), (a, n), (n, i...   \n",
       "2      [(s, o), (o, e), (e, r), (r, j), (j, a), (a, d...   \n",
       "3      [(u, n), (n, d), (d, u), (u, n), (n, s), (s, y...   \n",
       "4      [(s, o), (o, e), (e, r), (r, i), (i, p), (p, t...   \n",
       "...                                                  ...   \n",
       "75127  [(l, e), (e, e), (e,  ), ( , h), (h, a), (a, n...   \n",
       "75128  [(g, i), (i, l), (l,  ), ( , j), (j, u), (u, n...   \n",
       "75129  [(i, j), (j, e), (e, o), (o, n), (n, g), (g, h...   \n",
       "75130  [(g, e), (e, u), (u, m), (m, t), (t, a), (a, e...   \n",
       "75131  [(o, h), (h,  ), ( , u), (u, i), (i, -), (-, s...   \n",
       "\n",
       "                                                trigrams  \\\n",
       "0      [(s, u, p), (u, p, r), (p, r, i), (r, i, y), (...   \n",
       "1      [(t, r, i), (r, i, y), (i, y, a), (y, a, n), (...   \n",
       "2      [(s, o, e), (o, e, r), (e, r, j), (r, j, a), (...   \n",
       "3      [(u, n, d), (n, d, u), (d, u, n), (u, n, s), (...   \n",
       "4      [(s, o, e), (o, e, r), (e, r, i), (r, i, p), (...   \n",
       "...                                                  ...   \n",
       "75127  [(l, e, e), (e, e,  ), (e,  , h), ( , h, a), (...   \n",
       "75128  [(g, i, l), (i, l,  ), (l,  , j), ( , j, u), (...   \n",
       "75129  [(i, j, e), (j, e, o), (e, o, n), (o, n, g), (...   \n",
       "75130  [(g, e, u), (e, u, m), (u, m, t), (m, t, a), (...   \n",
       "75131  [(o, h,  ), (h,  , u), ( , u, i), (u, i, -), (...   \n",
       "\n",
       "                                             char_ngrams     word_ngrams  \\\n",
       "0      [s, u, p, r, i, y, a, d, i, (s, u), (u, p), (p...     [supriyadi]   \n",
       "1      [t, r, i, y, a, n, i, n, g, s, i, h, (t, r), (...  [triyaningsih]   \n",
       "2      [s, o, e, r, j, a, d, i, (s, o), (o, e), (e, r...      [soerjadi]   \n",
       "3      [u, n, d, u, n, s, y, a, h, (u, n), (n, d), (d...     [undunsyah]   \n",
       "4      [s, o, e, r, i, p, t, o, (s, o), (o, e), (e, r...      [soeripto]   \n",
       "...                                                  ...             ...   \n",
       "75127  [l, e, e,  , h, a, n, -, w, i, (l, e), (e, e),...             NaN   \n",
       "75128  [g, i, l,  , j, u, n, g, -, w, o, o, (g, i), (...             NaN   \n",
       "75129  [i, j, e, o, n, g, h, u, i, (i, j), (j, e), (e...             NaN   \n",
       "75130  [g, e, u, m, t, a, e, s, e, o, b, (g, e), (e, ...             NaN   \n",
       "75131  [o, h,  , u, i, -, s, i, k, (o, h), (h,  ), ( ...             NaN   \n",
       "\n",
       "       name_length  avg_token_length  ...  space_freq  \\\n",
       "0                9               9.0  ...           0   \n",
       "1               12              12.0  ...           0   \n",
       "2                8               8.0  ...           0   \n",
       "3                9               9.0  ...           0   \n",
       "4                8               8.0  ...           0   \n",
       "...            ...               ...  ...         ...   \n",
       "75127           10               4.5  ...           1   \n",
       "75128           12               5.5  ...           1   \n",
       "75129            9               9.0  ...           0   \n",
       "75130           11              11.0  ...           0   \n",
       "75131            9               4.0  ...           1   \n",
       "\n",
       "                                    indiv_unigrams_fdist  \\\n",
       "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111,...   \n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333...   \n",
       "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0....   \n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111,...   \n",
       "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                  ...   \n",
       "75127  [[0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0,...   \n",
       "75128  [[0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "75129  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75130  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75131  [[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...   \n",
       "\n",
       "                                     indiv_bigrams_fdist  \\\n",
       "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                  ...   \n",
       "75127  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75128  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75129  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75130  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "75131  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                    indiv_trigrams_fdist  unigrams_cosine_sim  \\\n",
       "0      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.664809   \n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.686625   \n",
       "2      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.688312   \n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.581396   \n",
       "4      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.463215   \n",
       "...                                                  ...                  ...   \n",
       "75127                                                NaN             0.675313   \n",
       "75128                                                NaN             0.769942   \n",
       "75129                                                NaN             0.777239   \n",
       "75130                                                NaN             0.614584   \n",
       "75131                                                NaN             0.592052   \n",
       "\n",
       "       bigrams_cosine_sim trigrams_cosine_sim    language   id  label_tr  \n",
       "0                0.250640            0.085949  Indonesian  NaN       NaN  \n",
       "1                0.353292            0.117226  Indonesian  NaN       NaN  \n",
       "2                0.197139            0.090295  Indonesian  NaN       NaN  \n",
       "3                0.155386            0.060083  Indonesian  NaN       NaN  \n",
       "4                0.176917            0.052811  Indonesian  NaN       NaN  \n",
       "...                   ...                 ...         ...  ...       ...  \n",
       "75127            0.212623                 NaN      Korean  NaN       NaN  \n",
       "75128            0.394563                 NaN      Korean  NaN       NaN  \n",
       "75129            0.508705                 NaN      Korean  NaN       NaN  \n",
       "75130            0.229460                 NaN      Korean  NaN       NaN  \n",
       "75131            0.067721                 NaN      Korean  NaN       NaN  \n",
       "\n",
       "[75132 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see from output, we need the columns in the concatenated df (in this case, viet) to match\n",
    "# it's okay if some values are NaN bc we'll drop all non-numerical columns anyway\n",
    "merged_df = pd.concat(all_dfs, ignore_index = True, join = 'outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many unique characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullname', 'original_fullname', 'alphabet', 'unigrams', 'bigrams',\n",
       "       'trigrams', 'char_ngrams', 'word_ngrams', 'name_length',\n",
       "       'avg_token_length', 'num_tokens', 'transliteration', 'period_freq',\n",
       "       'dash_freq', 'apostrophe_freq', 'space_freq', 'indiv_unigrams_fdist',\n",
       "       'indiv_bigrams_fdist', 'indiv_trigrams_fdist', 'unigrams_cosine_sim',\n",
       "       'bigrams_cosine_sim', 'trigrams_cosine_sim', 'language', 'id',\n",
       "       'label_tr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indonesian' 'Malay' 'Vietnamese' 'Chinese (Romanized)'\n",
      " 'Chinese (Characters)' 'Turkish' 'Korean']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many total unique chars based on our unigrams?\n",
    "print(merged_df['language'].unique())\n",
    "unigrams_fdist = create_lang_char_distribution(merged_df, 'unigrams')\n",
    "len(unigrams_fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([' ', '\"', \"'\", '(', ')', ',', '-', '.', '/', '7', ':', '@', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'à', 'á', 'â', 'ã', 'ä', 'å', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ā', 'ă', 'ą', 'ć', 'č', 'đ', 'ē', 'ğ', 'ĩ', 'ī', 'ı', 'ō', 'ŏ', 'ś', 'ş', 'š', 'ũ', 'ū', 'ŭ', 'ű', 'ž', 'ơ', 'ư', 'ǎ', 'ǧ', 'ǹ', 'ș', 'ț', 'ʻ', '̇', 'ạ', 'ả', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ắ', 'ằ', 'ặ', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ỉ', 'ị', 'ọ', 'ỏ', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ớ', 'ờ', 'ở', 'ợ', 'ụ', 'ủ', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'ỳ', 'ỵ', 'ỷ', 'ỹ', '\\u200b', '\\u200e', '\\u200f', '‑', '’', '人', '卓', '政', '治', '燮', '物', '賢', '趙', '郑', '镇', '高'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_fdist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0.09234122115983197,\n",
       " '\"': 2.1503457218334276e-06,\n",
       " \"'\": 9.354003889975411e-05,\n",
       " '(': 0.0006343519879408612,\n",
       " ')': 0.0006343519879408612,\n",
       " ',': 1.612759291375071e-05,\n",
       " '-': 0.012799932909213479,\n",
       " '.': 0.0007622975583899502,\n",
       " '/': 2.1503457218334276e-05,\n",
       " '7': 1.0751728609167138e-06,\n",
       " ':': 1.0751728609167138e-06,\n",
       " '@': 7.5262100264169975e-06,\n",
       " 'a': 0.10832689125594168,\n",
       " 'b': 0.013768663656899438,\n",
       " 'c': 0.014053584465042367,\n",
       " 'd': 0.02025948221825364,\n",
       " 'e': 0.06334488427376911,\n",
       " 'f': 0.007453098271874661,\n",
       " 'g': 0.05017401672753937,\n",
       " 'h': 0.04609158537463861,\n",
       " 'i': 0.07519328920107131,\n",
       " 'j': 0.015486789888644346,\n",
       " 'k': 0.023249537944463022,\n",
       " 'l': 0.03357334775498531,\n",
       " 'm': 0.03245301763391009,\n",
       " 'n': 0.09933414544723428,\n",
       " 'o': 0.050080476688639616,\n",
       " 'p': 0.007413316876020743,\n",
       " 'q': 0.002555685890399029,\n",
       " 'r': 0.033337884898444546,\n",
       " 's': 0.03247667143685026,\n",
       " 't': 0.024273102508055734,\n",
       " 'u': 0.050744933516686144,\n",
       " 'v': 0.004068454105708845,\n",
       " 'w': 0.010253923574562701,\n",
       " 'x': 0.004508199805823781,\n",
       " 'y': 0.02986185103910081,\n",
       " 'z': 0.012914976405331567,\n",
       " '|': 1.0751728609167138e-06,\n",
       " 'à': 0.0002558911408981779,\n",
       " 'á': 0.0001397724719191728,\n",
       " 'â': 0.00026556769664642834,\n",
       " 'ã': 1.935311149650085e-05,\n",
       " 'ä': 4.300691443666855e-06,\n",
       " 'å': 1.0751728609167138e-06,\n",
       " 'ç': 0.0028158777227408737,\n",
       " 'è': 1.0751728609167138e-06,\n",
       " 'é': 4.300691443666855e-05,\n",
       " 'ê': 0.0002773945981165122,\n",
       " 'ë': 1.0751728609167138e-06,\n",
       " 'ì': 6.666071737683625e-05,\n",
       " 'í': 7.096140882050311e-05,\n",
       " 'î': 3.010484010566799e-05,\n",
       " 'ï': 1.0751728609167138e-06,\n",
       " 'ð': 5.375864304583569e-06,\n",
       " 'ñ': 4.300691443666855e-06,\n",
       " 'ò': 1.720276577466742e-05,\n",
       " 'ó': 7.5262100264169975e-06,\n",
       " 'ô': 0.00018062904063400793,\n",
       " 'õ': 2.3653802940167705e-05,\n",
       " 'ö': 0.002619121089193115,\n",
       " 'ø': 2.1503457218334276e-06,\n",
       " 'ù': 8.171313742967026e-05,\n",
       " 'ú': 8.386348315150369e-05,\n",
       " 'û': 5.375864304583569e-06,\n",
       " 'ü': 0.00500600484042822,\n",
       " 'ý': 4.730760588033541e-05,\n",
       " 'ā': 1.0751728609167138e-06,\n",
       " 'ă': 0.00023546285654076033,\n",
       " 'ą': 2.1503457218334276e-06,\n",
       " 'ć': 3.440553154933484e-05,\n",
       " 'č': 9.676555748250425e-06,\n",
       " 'đ': 0.0002806201166992623,\n",
       " 'ē': 2.1503457218334276e-06,\n",
       " 'ğ': 0.002818028068462707,\n",
       " 'ĩ': 2.5804148662001135e-05,\n",
       " 'ī': 3.225518582750142e-06,\n",
       " 'ı': 0.004973749654600719,\n",
       " 'ō': 5.375864304583569e-06,\n",
       " 'ŏ': 9.676555748250425e-06,\n",
       " 'ś': 2.1503457218334276e-06,\n",
       " 'ş': 0.0030986481851619694,\n",
       " 'š': 9.676555748250425e-06,\n",
       " 'ũ': 6.773589023775297e-05,\n",
       " 'ū': 5.375864304583569e-06,\n",
       " 'ŭ': 5.375864304583569e-06,\n",
       " 'ű': 1.0751728609167138e-06,\n",
       " 'ž': 6.451037165500284e-06,\n",
       " 'ơ': 0.00019783180640867536,\n",
       " 'ư': 0.00027631942525559546,\n",
       " 'ǎ': 1.0751728609167138e-06,\n",
       " 'ǧ': 6.451037165500284e-06,\n",
       " 'ǹ': 1.0751728609167138e-06,\n",
       " 'ș': 2.1503457218334276e-06,\n",
       " 'ț': 1.0751728609167138e-06,\n",
       " 'ʻ': 2.1503457218334276e-06,\n",
       " '̇': 0.001228922580027804,\n",
       " 'ạ': 0.0001709524848857575,\n",
       " 'ả': 8.278831029058697e-05,\n",
       " 'ấ': 6.236002593316941e-05,\n",
       " 'ầ': 0.00017525317632942437,\n",
       " 'ẩ': 1.0751728609167138e-05,\n",
       " 'ẫ': 2.1503457218334276e-06,\n",
       " 'ậ': 4.6232433019418696e-05,\n",
       " 'ắ': 3.010484010566799e-05,\n",
       " 'ằ': 1.612759291375071e-05,\n",
       " 'ặ': 3.1180012966584705e-05,\n",
       " 'ế': 0.00010644211323075467,\n",
       " 'ề': 3.9781395853918415e-05,\n",
       " 'ể': 1.2902074331000567e-05,\n",
       " 'ễ': 0.00041394155145293483,\n",
       " 'ệ': 9.354003889975411e-05,\n",
       " 'ỉ': 3.225518582750142e-06,\n",
       " 'ị': 0.00014837385480650651,\n",
       " 'ọ': 9.031452031700396e-05,\n",
       " 'ỏ': 1.0751728609167138e-06,\n",
       " 'ố': 4.1931741575751844e-05,\n",
       " 'ồ': 6.343519879408612e-05,\n",
       " 'ổ': 6.451037165500284e-06,\n",
       " 'ỗ': 2.6879321522917846e-05,\n",
       " 'ộ': 2.0428284357417565e-05,\n",
       " 'ớ': 1.2902074331000567e-05,\n",
       " 'ờ': 3.7631050132084986e-05,\n",
       " 'ở': 3.225518582750142e-06,\n",
       " 'ợ': 2.1503457218334276e-05,\n",
       " 'ụ': 2.9029667244751275e-05,\n",
       " 'ủ': 5.375864304583569e-06,\n",
       " 'ứ': 6.020968021133598e-05,\n",
       " 'ừ': 1.5052420052833995e-05,\n",
       " 'ử': 1.720276577466742e-05,\n",
       " 'ữ': 3.655587727116827e-05,\n",
       " 'ự': 9.676555748250425e-06,\n",
       " 'ỳ': 4.085656871483513e-05,\n",
       " 'ỵ': 3.225518582750142e-06,\n",
       " 'ỷ': 3.225518582750142e-06,\n",
       " 'ỹ': 1.8277938635584136e-05,\n",
       " '\\u200b': 3.225518582750142e-06,\n",
       " '\\u200e': 2.1503457218334276e-06,\n",
       " '\\u200f': 1.0751728609167138e-06,\n",
       " '‑': 1.0751728609167138e-06,\n",
       " '’': 9.676555748250425e-06,\n",
       " '人': 1.0751728609167138e-06,\n",
       " '卓': 1.0751728609167138e-06,\n",
       " '政': 1.0751728609167138e-06,\n",
       " '治': 1.0751728609167138e-06,\n",
       " '燮': 1.0751728609167138e-06,\n",
       " '物': 1.0751728609167138e-06,\n",
       " '賢': 1.0751728609167138e-06,\n",
       " '趙': 1.0751728609167138e-06,\n",
       " '郑': 1.0751728609167138e-06,\n",
       " '镇': 1.0751728609167138e-06,\n",
       " '高': 1.0751728609167138e-06}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75132, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Keeping numerical columns only for each dataset (Same process as step 4, except we don't have to repeat lines of code...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75127</th>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675313</td>\n",
       "      <td>0.212623</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75128</th>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769942</td>\n",
       "      <td>0.394563</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75129</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777239</td>\n",
       "      <td>0.508705</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75130</th>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614584</td>\n",
       "      <td>0.229460</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75131</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592052</td>\n",
       "      <td>0.067721</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75132 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0                9               9.0           1            0          0   \n",
       "1               12              12.0           1            0          0   \n",
       "2                8               8.0           1            0          0   \n",
       "3                9               9.0           1            0          0   \n",
       "4                8               8.0           1            0          0   \n",
       "...            ...               ...         ...          ...        ...   \n",
       "75127           10               4.5           2            0          1   \n",
       "75128           12               5.5           2            0          1   \n",
       "75129            9               9.0           1            0          0   \n",
       "75130           11              11.0           1            0          0   \n",
       "75131            9               4.0           2            0          1   \n",
       "\n",
       "       apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                    0           0             0.664809            0.250640   \n",
       "1                    0           0             0.686625            0.353292   \n",
       "2                    0           0             0.688312            0.197139   \n",
       "3                    0           0             0.581396            0.155386   \n",
       "4                    0           0             0.463215            0.176917   \n",
       "...                ...         ...                  ...                 ...   \n",
       "75127                0           1             0.675313            0.212623   \n",
       "75128                0           1             0.769942            0.394563   \n",
       "75129                0           0             0.777239            0.508705   \n",
       "75130                0           0             0.614584            0.229460   \n",
       "75131                0           1             0.592052            0.067721   \n",
       "\n",
       "         language  \n",
       "0      Indonesian  \n",
       "1      Indonesian  \n",
       "2      Indonesian  \n",
       "3      Indonesian  \n",
       "4      Indonesian  \n",
       "...           ...  \n",
       "75127      Korean  \n",
       "75128      Korean  \n",
       "75129      Korean  \n",
       "75130      Korean  \n",
       "75131      Korean  \n",
       "\n",
       "[75132 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col = merged_df['language']\n",
    "merged_df = merged_df.select_dtypes(exclude = 'object')\n",
    "merged_df.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "merged_df['language'] = label_col\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that there are no null values\n",
    "np.any(pd.isnull(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_pickle('merged_df.pkl.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE everything after this: we will be training in individual files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Clean up columns so we can combine dataframes into one (focus on making an all-Latin dataset first)\n",
    "    - do not combine in this step\n",
    "2. Frequency distributions for Latin names -> redo\n",
    "3. Add a_hat_freq\n",
    "4. Only keep numerical columns\n",
    "    - turn some categorical features -> numerical so we have more things to feed into model\n",
    "5. Add in label (language) for each dataset\n",
    "6. Combine Latin and non-Latin names to make one big dataset\n",
    "    - may need to repeat some of the above steps for non-Latin names\n",
    "7. Train test split\n",
    "8. MODEL TRAINING!\n",
    "9. Model evaluation\n",
    "\n",
    "Reminder:\n",
    "- We decided to keep period_freq, dash_freq, apostrophe_freq for now. After our first run of model training, we can remove them to see if it improves the performance\n",
    "\n",
    "**You can work on these steps out of order** (act as if the previous steps r there), but in the end we ideally want all of these steps implemented in this order.\n",
    "\n",
    "For example, you could write the code for model training and train the model on one or a few datasets. Later on, we'll just replace the variables you used with the ones containing all the languages/names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    name  class lang\n",
      "0                The Canal of the Angels      0   en\n",
      "1                      Rescue Renovation      0   en\n",
      "2       Agatha Christie: The ABC Murders      0   en\n",
      "3                            Siti Akbari      0   ar\n",
      "4                                  Stany      0   pl\n",
      "...                                  ...    ...  ...\n",
      "199995                   Robber's Bridge      0   en\n",
      "199996                       Johan Renck      0   en\n",
      "199997                      Lyle Stewart      1   en\n",
      "199998           Thomas Colclough Watson      1   en\n",
      "199999                              Gavà      0   ca\n",
      "\n",
      "[200000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#can replace file names later\n",
    "filename = os.path.join(os.getcwd(), \"company_person_name_dataset.csv\")\n",
    "#filename = os.path.join(os.getcwd(), \"Name_Of_Origin_Project-\", \"company_person_name_dataset.csv\")\n",
    "df = pd.read_csv(filename, header=0)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name_length', 'avg_token_length', 'num_tokens', 'period_freq',\n",
      "       'dash_freq', 'apostrophe_freq', 'space_freq', 'unigrams_cosine_sim',\n",
      "       'bigrams_cosine_sim', 'language'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0            9               9.0           1            0          0   \n",
       "1           12              12.0           1            0          0   \n",
       "2            8               8.0           1            0          0   \n",
       "3            9               9.0           1            0          0   \n",
       "4            8               8.0           1            0          0   \n",
       "\n",
       "   apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \n",
       "0                0           0             0.664809            0.250640  \n",
       "1                0           0             0.686625            0.353292  \n",
       "2                0           0             0.688312            0.197139  \n",
       "3                0           0             0.581396            0.155386  \n",
       "4                0           0             0.463215            0.176917  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = merged_df['language']\n",
    "print(merged_df.columns)\n",
    "\n",
    "X = merged_df.drop(columns = 'language', axis = 1) # oops this code is a bit redundant with before but its ok\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training - Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb Cell 47\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid_search_rf \u001b[39m=\u001b[39m GridSearchCV(rf_classifier, param_grid\u001b[39m=\u001b[39mparam_grid_rf, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid_search_rf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(rf_classifier, param_grid=param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_rf_model = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest model on the test set\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8428922708845618\n",
      "Random Forest Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Chinese (Characters)       0.79      0.88      0.83      2211\n",
      " Chinese (Romanized)       0.68      0.75      0.72      2096\n",
      "          Indonesian       0.73      0.80      0.76      2249\n",
      "              Korean       0.94      0.91      0.93      3844\n",
      "               Malay       0.55      0.23      0.33       582\n",
      "             Turkish       1.00      0.99      1.00      3607\n",
      "          Vietnamese       0.56      0.33      0.42       458\n",
      "\n",
      "            accuracy                           0.84     15047\n",
      "           macro avg       0.75      0.70      0.71     15047\n",
      "        weighted avg       0.84      0.84      0.84     15047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training - SVM\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid=param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_svm_model = grid_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the SVM model on the test set\n",
    "svm_predictions = best_svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will leave this commented for now\n",
    "# randomizing data - idk if this is correct or necessary?\n",
    "# X, y = shuffle(X, y)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change test data size\n",
    "# changed: 0.10 -> 0.30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234) \n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline with a TfidfVectorizer and Multinomial Naive Bayes classifier\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()) # we want this probably\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_nb = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__alpha': (1e-2, 1e-3, 1e-4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_nb = GridSearchCV(pipeline_nb, param_grid_nb, cv = 5, n_jobs = -1)\n",
    "grid_search_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_nb_model = grid_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score\n",
    "# not in the other code parts but its ok\n",
    "print(\"Best Parameters: \", grid_search_nb.best_params_)\n",
    "print(\"Best Score: \", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = grid_search_nb.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "\n",
    "print(\"NB Accuracy:\", svm_accuracy)\n",
    "print(\"NB Classification Report:\")\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, SVM, RNNs, Naive Bayes\n",
    "\n",
    "use gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 20)\n",
    "# rf.fit(X_train, y_train)\n",
    "# rf_predictions = list(rf_20_model.predict_proba(X_test)[:,1])\n",
    "# in ML foundations we used ROC and AUC to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there r multiple types of support vector machines\n",
    "# not sure if this is correct\n",
    "# svc = svm.SVC()\n",
    "# svc.fit(X_train, y_train)\n",
    "# svc_predictions = svc.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNs - not sure if this is correct\n",
    "# mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, ... hidden_layer_sizes=(5, 2), random_state=1)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# mlp_predictions = mlp.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes - there r diff types\n",
    "# this is multinomialNB, is said to be used for text classification\n",
    "# mn_nb = MultinomialNB(force_alpha=True) # idk\n",
    "# mn_nb.fit(X_train, y_train)\n",
    "# mn_nb_predictions = mn_nb.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation: precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score\n",
    "# need multiple cells, one for each evaluation\n",
    "# rf_f1 = f1_score(y_test, rf_predictions, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
