{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import unicodedata\n",
    "from nltk import edit_distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Model training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was originally for frequency distributions for Latin names!\n",
    "but we can also concat the other dfs / do model training after in the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiger datasets\n",
    "df_indo = pd.read_pickle('df_indo.pkl.gz', compression = 'gzip')\n",
    "df_malay = pd.read_pickle('df_malay.pkl.gz', compression = 'gzip')\n",
    "df_viet = pd.read_pickle('viet_df.pkl.gz', compression = 'gzip')\n",
    "df_cnrom = pd.read_pickle('cnrom_df.pkl.gz', compression = 'gzip')\n",
    "df_cnchar = pd.read_pickle('cnchar_df.pkl.gz', compression = 'gzip')\n",
    "df_turk = pd.read_pickle('turkish_df.pkl.gz', compression = 'gzip')\n",
    "df_korean = pd.read_pickle('korean_df.pkl.gz', compression ='gzip') \n",
    "df_japan = pd.read_pickle('japanese_df.pkl.gz', compression ='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_csv                                                                     number of samples\n",
    "# df_arabic = pd.read_pickle('arabic_df.pkl.gz', compression = 'gzip')                  # 40\n",
    "df_arabic_latin = pd.read_pickle('arabicLatin_df.pkl.gz', compression = 'gzip')         # 1046\n",
    "# df_bulgar = pd.read_pickle('bulgarian_df.pkl.gz', compression = 'gzip')               # 2\n",
    "# df_bulgar_latin = pd.read_pickle('bulgarianLatin_df.pkl.gz', compression = 'gzip')    # 474\n",
    "df_croatian = pd.read_pickle('croatian_df.pkl.gz', compression = 'gzip')                # 582\n",
    "# df_danish = pd.read_pickle('danish_df.pkl.gz', compression = 'gzip')                  # 408\n",
    "df_dutch = pd.read_pickle('dutch_df.pkl.gz', compression = 'gzip')                      # 695\n",
    "df_english = pd.read_pickle('english_df.pkl.gz', compression = 'gzip')                  # 22779\n",
    "# df_finnish = pd.read_pickle('finnish_df.pkl.gz', compression = 'gzip')                # 451\n",
    "df_french = pd.read_pickle('french_df.pkl.gz', compression = 'gzip')                    # 1164\n",
    "df_german = pd.read_pickle('german_df.pkl.gz', compression = 'gzip')                    # 1064\n",
    "# df_hindi = pd.read_pickle('hindi_df.pkl.gz', compression = 'gzip')                    # 12\n",
    "df_hindi_latin = pd.read_pickle('hindiLatin_df.pkl.gz', compression = 'gzip')           # 781\n",
    "# df_hungar = pd.read_pickle('hungarian_df.pkl.gz', compression = 'gzip')               # 434\n",
    "df_italian = pd.read_pickle('italian_df.pkl.gz', compression = 'gzip')                  # 1207\n",
    "# df_norwegian = pd.read_pickle('norwegian_df.pkl.gz', compression = 'gzip')            # 403\n",
    "df_polish = pd.read_pickle('polish_df.pkl.gz', compression = 'gzip')                    # 561\n",
    "df_portug = pd.read_pickle('portuguese_df.pkl.gz', compression = 'gzip')                # 1068\n",
    "# df_russian = pd.read_pickle('russian_df.pkl.gz', compression = 'gzip')                # 15\n",
    "df_russian_latin = pd.read_pickle('russianLatin_df.pkl.gz', compression = 'gzip')       # 968\n",
    "df_spanish = pd.read_pickle('spanish_df.pkl.gz', compression = 'gzip')                  # 2502\n",
    "\n",
    "company_csv_dfs = [df_arabic_latin, df_croatian, df_dutch, df_english, df_french, df_german, df_hindi_latin, df_italian, df_polish,\n",
    "                   df_portug, df_russian_latin, df_spanish]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>name_lower</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>...</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>detected_accents</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Al Dokali Al Seyed</td>\n",
       "      <td>1</td>\n",
       "      <td>ar</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4</td>\n",
       "      <td>al dokali al seyed</td>\n",
       "      <td>al dokali al seyed</td>\n",
       "      <td>[(a,), (l,), ( ,), (d,), (o,), (k,), (a,), (l,...</td>\n",
       "      <td>[a, l,  , d, o, k, a, l, i,  , a, l,  , s, e, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Al, Dokali, Al, Seyed]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058823529411...</td>\n",
       "      <td>0.789154</td>\n",
       "      <td>0.374614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Afzal Ansari</td>\n",
       "      <td>1</td>\n",
       "      <td>ar</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>2</td>\n",
       "      <td>afzal ansari</td>\n",
       "      <td>afzal ansari</td>\n",
       "      <td>[(a,), (f,), (z,), (a,), (l,), ( ,), (a,), (n,...</td>\n",
       "      <td>[a, f, z, a, l,  , a, n, s, a, r, i]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Afzal, Ansari]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.090909090909...</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.397864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Naguib Mahfouz</td>\n",
       "      <td>1</td>\n",
       "      <td>ar</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2</td>\n",
       "      <td>naguib mahfouz</td>\n",
       "      <td>naguib mahfouz</td>\n",
       "      <td>[(n,), (a,), (g,), (u,), (i,), (b,), ( ,), (m,...</td>\n",
       "      <td>[n, a, g, u, i, b,  , m, a, h, f, o, u, z]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Naguib, Mahfouz]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.750020</td>\n",
       "      <td>0.229505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Fahad Barakah Al-Marwani Al-Johani</td>\n",
       "      <td>1</td>\n",
       "      <td>ar</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4</td>\n",
       "      <td>fahad barakah al-marwani al-johani</td>\n",
       "      <td>fahad barakah al-marwani al-johani</td>\n",
       "      <td>[(f,), (a,), (h,), (a,), (d,), ( ,), (b,), (a,...</td>\n",
       "      <td>[f, a, h, a, d,  , b, a, r, a, k, a, h,  , a, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Fahad, Barakah, Al-Marwani, Al-Johani]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[0.08823529411764705, 0.0, 0.0588235294117647...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060606060606...</td>\n",
       "      <td>0.909744</td>\n",
       "      <td>0.636527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Zulfiqar Ahmed</td>\n",
       "      <td>1</td>\n",
       "      <td>ar</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2</td>\n",
       "      <td>zulfiqar ahmed</td>\n",
       "      <td>zulfiqar ahmed</td>\n",
       "      <td>[(z,), (u,), (l,), (f,), (i,), (q,), (a,), (r,...</td>\n",
       "      <td>[z, u, l, f, i, q, a, r,  , a, h, m, e, d]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Zulfiqar, Ahmed]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076923076923...</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>0.307370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  class lang  \\\n",
       "15                   Al Dokali Al Seyed      1   ar   \n",
       "116                        Afzal Ansari      1   ar   \n",
       "165                      Naguib Mahfouz      1   ar   \n",
       "316  Fahad Barakah Al-Marwani Al-Johani      1   ar   \n",
       "320                      Zulfiqar Ahmed      1   ar   \n",
       "\n",
       "                                              alphabet  avg_token_length  \\\n",
       "15   [LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...              3.75   \n",
       "116  [LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...              5.50   \n",
       "165  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...              6.50   \n",
       "316  [LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...              7.75   \n",
       "320  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...              6.50   \n",
       "\n",
       "     num_tokens                          name_lower  \\\n",
       "15            4                  al dokali al seyed   \n",
       "116           2                        afzal ansari   \n",
       "165           2                      naguib mahfouz   \n",
       "316           4  fahad barakah al-marwani al-johani   \n",
       "320           2                      zulfiqar ahmed   \n",
       "\n",
       "                        transliteration  \\\n",
       "15                   al dokali al seyed   \n",
       "116                        afzal ansari   \n",
       "165                      naguib mahfouz   \n",
       "316  fahad barakah al-marwani al-johani   \n",
       "320                      zulfiqar ahmed   \n",
       "\n",
       "                                           char_ngrams  \\\n",
       "15   [(a,), (l,), ( ,), (d,), (o,), (k,), (a,), (l,...   \n",
       "116  [(a,), (f,), (z,), (a,), (l,), ( ,), (a,), (n,...   \n",
       "165  [(n,), (a,), (g,), (u,), (i,), (b,), ( ,), (m,...   \n",
       "316  [(f,), (a,), (h,), (a,), (d,), ( ,), (b,), (a,...   \n",
       "320  [(z,), (u,), (l,), (f,), (i,), (q,), (a,), (r,...   \n",
       "\n",
       "                                              unigrams  ... dash_freq  \\\n",
       "15   [a, l,  , d, o, k, a, l, i,  , a, l,  , s, e, ...  ...         0   \n",
       "116               [a, f, z, a, l,  , a, n, s, a, r, i]  ...         0   \n",
       "165         [n, a, g, u, i, b,  , m, a, h, f, o, u, z]  ...         0   \n",
       "316  [f, a, h, a, d,  , b, a, r, a, k, a, h,  , a, ...  ...         2   \n",
       "320         [z, u, l, f, i, q, a, r,  , a, h, m, e, d]  ...         0   \n",
       "\n",
       "    apostrophe_freq  space_freq                              word_ngrams  \\\n",
       "15                0           3                  [Al, Dokali, Al, Seyed]   \n",
       "116               0           1                          [Afzal, Ansari]   \n",
       "165               0           1                        [Naguib, Mahfouz]   \n",
       "316               0           3  [Fahad, Barakah, Al-Marwani, Al-Johani]   \n",
       "320               0           1                        [Zulfiqar, Ahmed]   \n",
       "\n",
       "     accent_count  detected_accents  \\\n",
       "15              0                     \n",
       "116             0                     \n",
       "165             0                     \n",
       "316             0                     \n",
       "320             0                     \n",
       "\n",
       "                                  indiv_unigrams_fdist  \\\n",
       "15   [[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "116  [[0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "165  [[0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "316  [[0.08823529411764705, 0.0, 0.0588235294117647...   \n",
       "320  [[0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                   indiv_bigrams_fdist unigrams_cosine_sim  \\\n",
       "15   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058823529411...            0.789154   \n",
       "116  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.090909090909...            0.831071   \n",
       "165  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.750020   \n",
       "316  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060606060606...            0.909744   \n",
       "320  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076923076923...            0.843715   \n",
       "\n",
       "    bigrams_cosine_sim  \n",
       "15            0.374614  \n",
       "116           0.397864  \n",
       "165           0.229505  \n",
       "316           0.636527  \n",
       "320           0.307370  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arabic_latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in company_csv_dfs:\n",
    "    df['name_length'] = df['name'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [df_indo, df_malay, df_viet, df_cnrom, df_cnchar, df_turk, df_korean, df_japan]\n",
    "for df in company_csv_dfs:\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding counts\n",
    "# df_names = ['Indonesian', 'Malay', 'Vietnamese', 'Chinese (Romanized)', 'Chinese (Characters)', 'Turkish', 'Korean (Romanized & Characters)']\n",
    "# total_size = 0\n",
    "\n",
    "# for i, df in enumerate(all_dfs):\n",
    "#     total_size += df.shape[0]\n",
    "#     print(df_names[i], ':', df.shape[0])\n",
    "    \n",
    "# for i, df in enumerate(all_dfs):\n",
    "#     print(df_names[i], ':', df.shape[0] / total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cleaning up column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names to KEEP: (10 so far)\n",
    "\n",
    "* name_length\n",
    "* avg_token_length\n",
    "* num_tokens\n",
    "* period_freq\n",
    "* dash_freq\n",
    "* apostrophe_freq\n",
    "* space_freq\n",
    "* unigrams_cosine_sim\n",
    "* bigrams_cosine_sim\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>từ hoàng thông</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(T,), (ừ,), ( ,), (H,), (o,), (à,), (n,), (g,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>tu hoang thong</td>\n",
       "      <td>[t, ừ,  , h, o, à, n, g,  , t, h, ô, n, g]</td>\n",
       "      <td>[(t, ừ), (ừ,  ), ( , h), (h, o), (o, à), (à, n...</td>\n",
       "      <td>[(t, ừ,  ), (ừ,  , h), ( , h, o), (h, o, à), (...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07...</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.508198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nguyễn thị phương thảo</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>[(N,), (g,), (u,), (y,), (ễ,), (n,), ( ,), (T,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>nguyen thi phuong thao</td>\n",
       "      <td>[n, g, u, y, ễ, n,  , t, h, ị,  , p, h, ư, ơ, ...</td>\n",
       "      <td>[(n, g), (g, u), (u, y), (y, ễ), (ễ, n), (n,  ...</td>\n",
       "      <td>[(n, g, u), (g, u, y), (u, y, ễ), (y, ễ, n), (...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>[[0.13636363636363635, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.884792</td>\n",
       "      <td>0.667716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nick út</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[(N,), (i,), (c,), (k,), ( ,), (Ú,), (t,), (N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nick ut</td>\n",
       "      <td>[n, i, c, k,  , ú, t]</td>\n",
       "      <td>[(n, i), (i, c), (c, k), (k,  ), ( , ú), (ú, t)]</td>\n",
       "      <td>[(n, i, c), (i, c, k), (c, k,  ), (k,  , ú), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.14285714285...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.592690</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cao văn lầu</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(C,), (a,), (o,), ( ,), (V,), (ă,), (n,), ( ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>cao van lau</td>\n",
       "      <td>[c, a, o,  , v, ă, n,  , l, ầ, u]</td>\n",
       "      <td>[(c, a), (a, o), (o,  ), ( , v), (v, ă), (ă, n...</td>\n",
       "      <td>[(c, a, o), (a, o,  ), (o,  , v), ( , v, ă), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.18181818181818182, 0.09090909090909091, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665965</td>\n",
       "      <td>0.243176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tạ thu thâu</td>\n",
       "      <td>[LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(T,), (ạ,), ( ,), (T,), (h,), (u,), ( ,), (T,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ta thu thau</td>\n",
       "      <td>[t, ạ,  , t, h, u,  , t, h, â, u]</td>\n",
       "      <td>[(t, ạ), (ạ,  ), ( , t), (t, h), (h, u), (u,  ...</td>\n",
       "      <td>[(t, ạ,  ), (ạ,  , t), ( , t, h), (t, h, u), (...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.596114</td>\n",
       "      <td>0.288942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fullname                                           alphabet  \\\n",
       "0          từ hoàng thông  [LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, LAT...   \n",
       "1  nguyễn thị phương thảo  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "2                 nick út  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]   \n",
       "3             cao văn lầu  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   \n",
       "4             tạ thu thâu  [LATIN, LATIN, SPACE, LATIN, LATIN, LATIN, SPA...   \n",
       "\n",
       "   name_length  num_tokens                                        char_ngrams  \\\n",
       "0           14           3  [(T,), (ừ,), ( ,), (H,), (o,), (à,), (n,), (g,...   \n",
       "1           22           4  [(N,), (g,), (u,), (y,), (ễ,), (n,), ( ,), (T,...   \n",
       "2            7           2  [(N,), (i,), (c,), (k,), ( ,), (Ú,), (t,), (N,...   \n",
       "3           11           3  [(C,), (a,), (o,), ( ,), (V,), (ă,), (n,), ( ,...   \n",
       "4           11           3  [(T,), (ạ,), ( ,), (T,), (h,), (u,), ( ,), (T,...   \n",
       "\n",
       "   period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "0            0          0           2                0   \n",
       "1            0          0           3                0   \n",
       "2            0          0           1                0   \n",
       "3            0          0           2                0   \n",
       "4            0          0           2                0   \n",
       "\n",
       "          transliteration                                           unigrams  \\\n",
       "0          tu hoang thong         [t, ừ,  , h, o, à, n, g,  , t, h, ô, n, g]   \n",
       "1  nguyen thi phuong thao  [n, g, u, y, ễ, n,  , t, h, ị,  , p, h, ư, ơ, ...   \n",
       "2                 nick ut                              [n, i, c, k,  , ú, t]   \n",
       "3             cao van lau                  [c, a, o,  , v, ă, n,  , l, ầ, u]   \n",
       "4             ta thu thau                  [t, ạ,  , t, h, u,  , t, h, â, u]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(t, ừ), (ừ,  ), ( , h), (h, o), (o, à), (à, n...   \n",
       "1  [(n, g), (g, u), (u, y), (y, ễ), (ễ, n), (n,  ...   \n",
       "2   [(n, i), (i, c), (c, k), (k,  ), ( , ú), (ú, t)]   \n",
       "3  [(c, a), (a, o), (o,  ), ( , v), (v, ă), (ă, n...   \n",
       "4  [(t, ạ), (ạ,  ), ( , t), (t, h), (h, u), (u,  ...   \n",
       "\n",
       "                                            trigrams  avg_token_length  \\\n",
       "0  [(t, ừ,  ), (ừ,  , h), ( , h, o), (h, o, à), (...              4.00   \n",
       "1  [(n, g, u), (g, u, y), (u, y, ễ), (y, ễ, n), (...              4.75   \n",
       "2  [(n, i, c), (i, c, k), (c, k,  ), (k,  , ú), (...              3.00   \n",
       "3  [(c, a, o), (a, o,  ), (o,  , v), ( , v, ă), (...              3.00   \n",
       "4  [(t, ạ,  ), (ạ,  , t), ( , t, h), (t, h, u), (...              3.00   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  [[0.13636363636363635, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[0.14285714285714285, 0.0, 0.0, 0.14285714285...   \n",
       "3  [[0.18181818181818182, 0.09090909090909091, 0....   \n",
       "4  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07...             0.805625   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.884792   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.592690   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665965   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.596114   \n",
       "\n",
       "   bigrams_cosine_sim  \n",
       "0            0.508198  \n",
       "1            0.667716  \n",
       "2            0.005600  \n",
       "3            0.243176  \n",
       "4            0.288942  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is where you rename columns to all match\n",
    "df_viet.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnrom.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_cnchar.rename(columns = {'word_length': 'name_length'}, inplace = True)\n",
    "df_viet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Redoing frequency distributions across all Latin names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Frequency Distribution Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from IndoMalay.ipynb\n",
    "\n",
    "def create_lang_char_distribution(df, col_name):\n",
    "    char_freqs = {}\n",
    "    total_num_chars = 0  # across the entire language/dataset\n",
    "\n",
    "    for name in df[col_name]:\n",
    "        for char in name:\n",
    "            if char not in char_freqs.keys():\n",
    "                char_freqs[char] = 1\n",
    "            else:\n",
    "                char_freqs[char] += 1\n",
    "            total_num_chars += 1\n",
    "\n",
    "    char_freqs_relative = dict(sorted({char: count / total_num_chars for char, count in char_freqs.items()}.items()))\n",
    "    return char_freqs_relative\n",
    "\n",
    "def initialize_all_possible_bigrams(all_possible_chars):\n",
    "    all_possible_bigrams = {}\n",
    "    for first_char in all_possible_chars:  # first character of the current bigram\n",
    "        for second_char in all_possible_chars:  # second character of the current bigram\n",
    "            all_possible_bigrams[(first_char, second_char)] = 0\n",
    "    return all_possible_bigrams\n",
    "\n",
    "def create_lang_gram_distribution(initialized_grams, df, col_name):\n",
    "    gram_freqs = initialized_grams.copy()  # need a copy otherwise initiailized_grams is changed\n",
    "    total_num_grams = 0  # across the entire language/dataset\n",
    "    \n",
    "    for grams_list in df[col_name]:\n",
    "        for gram in grams_list:\n",
    "            gram_freqs[gram] += 1\n",
    "            total_num_grams += 1\n",
    "    \n",
    "    gram_freqs_relative = {gram: count / total_num_grams for gram, count in gram_freqs.items()}\n",
    "    return gram_freqs_relative\n",
    "\n",
    "def initialize_all_possible_trigrams(all_possible_chars):\n",
    "    all_possible_trigrams = {}\n",
    "    for first_char in all_possible_chars:  # first character of the current trigram\n",
    "        for second_char in all_possible_chars:  # second character of the current trigram\n",
    "            for third_char in all_possible_chars:  # third character of the current trigram\n",
    "                all_possible_trigrams[(first_char, second_char, third_char)] = 0\n",
    "    return all_possible_trigrams\n",
    "\n",
    "def create_indiv_gram_distribution(grams_list, initialized_grams):\n",
    "    gram_freqs_relative = initialized_grams.copy()  \n",
    "    num_grams = len(grams_list)  # for this current example\n",
    "    \n",
    "    for gram in grams_list:\n",
    "        gram_freqs_relative[gram] += 1 / num_grams\n",
    "\n",
    "    return gram_freqs_relative\n",
    "\n",
    "def set_indiv_trigram_dist(trigrams_list, init_trigrams):\n",
    "    trigrams_fdist_relative = init_trigrams\n",
    "    num_grams = len(trigrams_list)\n",
    "\n",
    "    for gram in trigrams_list:\n",
    "        trigrams_fdist_relative[gram] += 1 / num_grams\n",
    "\n",
    "    return trigrams_fdist_relative\n",
    "\n",
    "# TRIGRAMS individual frequency distributions\n",
    "#df_indo['indiv_trigrams_fdist'] = df_indo.apply(lambda row: set_indiv_trigram_dist(row['trigrams'], row['indiv_trigrams_fdist']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Determining which languages use Latin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these lines of code to work, the datasets must have been pickled to preserve data types! `pd.csv` turns everything into strings; for example, a list of `[LATIN, LATIN, LATIN, ...]` becomes `'[LATIN, LATIN, LATIN, ...]'` (i.e., `'['` becomes a character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589739940220817"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indo_latin_percent = create_lang_char_distribution(df_indo, 'alphabet')['LATIN']\n",
    "malay_latin_percent = create_lang_char_distribution(df_malay, 'alphabet')['LATIN']\n",
    "viet_latin_percent = create_lang_char_distribution(df_viet, 'alphabet')['LATIN']\n",
    "cnrom_latin_percent = create_lang_char_distribution(df_cnrom, 'alphabet')['LATIN']\n",
    "# cnchar_latin_percent = create_lang_char_distribution(df_cnchar, 'alphabet')['LATIN'] error -> no latin\n",
    "turk_latin_percent = create_lang_char_distribution(df_turk, 'alphabet')['LATIN']\n",
    "korean_latin_percent = create_lang_char_distribution(df_korean, 'alphabet')['LATIN']\n",
    "korean_latin_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁一平</td>\n",
       "      <td>ding yi ping</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , p, i, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.774279</td>\n",
       "      <td>0.548928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁世雄</td>\n",
       "      <td>ding shi xiong</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , s, h, i,  , x, i, o, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.811762</td>\n",
       "      <td>0.560151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丁亦昕</td>\n",
       "      <td>ding yi xin</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , x, i, n]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.510394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>丁仲礼</td>\n",
       "      <td>ding zhong li</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...</td>\n",
       "      <td>[d, i, n, g,  , z, h, o, n, g,  , l, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.605839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>丁伟</td>\n",
       "      <td>ding wei</td>\n",
       "      <td>[CJK, CJK]</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , w, e, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>[[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.440812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_fullname transliteration         alphabet  name_length  num_tokens  \\\n",
       "0               丁一平    ding yi ping  [CJK, CJK, CJK]           12           3   \n",
       "1               丁世雄  ding shi xiong  [CJK, CJK, CJK]           14           3   \n",
       "2               丁亦昕     ding yi xin  [CJK, CJK, CJK]           11           3   \n",
       "3               丁仲礼   ding zhong li  [CJK, CJK, CJK]           13           3   \n",
       "4                丁伟        ding wei       [CJK, CJK]            8           2   \n",
       "\n",
       "                                         char_ngrams  \\\n",
       "0  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "1  [(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...   \n",
       "2  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "3  [(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...   \n",
       "4  [(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...   \n",
       "\n",
       "                                     unigrams  \\\n",
       "0        [d, i, n, g,  , y, i,  , p, i, n, g]   \n",
       "1  [d, i, n, g,  , s, h, i,  , x, i, o, n, g]   \n",
       "2           [d, i, n, g,  , y, i,  , x, i, n]   \n",
       "3     [d, i, n, g,  , z, h, o, n, g,  , l, i]   \n",
       "4                    [d, i, n, g,  , w, e, i]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "1  [(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...   \n",
       "2  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "3  [(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...   \n",
       "4  [(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...   \n",
       "\n",
       "                                            trigrams  period_freq  dash_freq  \\\n",
       "0  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "1  [(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...            0          0   \n",
       "2  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "3  [(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...            0          0   \n",
       "4  [(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...            0          0   \n",
       "\n",
       "   space_freq  apostrophe_freq  avg_token_length  \\\n",
       "0           2                0          3.333333   \n",
       "1           2                0          4.000000   \n",
       "2           2                0          3.000000   \n",
       "3           2                0          3.666667   \n",
       "4           1                0          3.500000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...   \n",
       "1  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...   \n",
       "2  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...   \n",
       "3  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...   \n",
       "4  [[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.774279   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.811762   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.776390   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.841584   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.710349   \n",
       "\n",
       "   bigrams_cosine_sim  \n",
       "0            0.548928  \n",
       "1            0.560151  \n",
       "2            0.510394  \n",
       "3            0.605839  \n",
       "4            0.440812  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnchar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>Park Joo-bong</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...</td>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g]</td>\n",
       "      <td>[(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...</td>\n",
       "      <td>[(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>[[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.377660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>KIM Jong hoon</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n]</td>\n",
       "      <td>[(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...</td>\n",
       "      <td>[(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.552090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이민혁</td>\n",
       "      <td>이민혁</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>iminhyeog</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g]</td>\n",
       "      <td>[(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...</td>\n",
       "      <td>[(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.757701</td>\n",
       "      <td>0.344410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lee ho</td>\n",
       "      <td>Lee Ho</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]</td>\n",
       "      <td>lee ho</td>\n",
       "      <td>[l, e, e,  , h, o]</td>\n",
       "      <td>[(l, e), (e, e), (e,  ), ( , h), (h, o)]</td>\n",
       "      <td>[(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]</td>\n",
       "      <td>[l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.537098</td>\n",
       "      <td>0.143205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최민호</td>\n",
       "      <td>최민호</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>choeminho</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o]</td>\n",
       "      <td>[(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...</td>\n",
       "      <td>[(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665396</td>\n",
       "      <td>0.171394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fullname original_fullname  \\\n",
       "0  park joo-bong     Park Joo-bong   \n",
       "1  kim jong hoon     KIM Jong hoon   \n",
       "2            이민혁               이민혁   \n",
       "3         lee ho            Lee Ho   \n",
       "4            최민호               최민호   \n",
       "\n",
       "                                            alphabet transliteration  \\\n",
       "0  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...   park joo-bong   \n",
       "1  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   kim jong hoon   \n",
       "2                           [HANGUL, HANGUL, HANGUL]       iminhyeog   \n",
       "3         [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]          lee ho   \n",
       "4                           [HANGUL, HANGUL, HANGUL]       choeminho   \n",
       "\n",
       "                                  unigrams  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g]   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n]   \n",
       "2              [i, m, i, n, h, y, e, o, g]   \n",
       "3                       [l, e, e,  , h, o]   \n",
       "4              [c, h, o, e, m, i, n, h, o]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...   \n",
       "1  [(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...   \n",
       "2  [(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...   \n",
       "3           [(l, e), (e, e), (e,  ), ( , h), (h, o)]   \n",
       "4  [(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...   \n",
       "1  [(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...   \n",
       "2  [(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...   \n",
       "3       [(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]   \n",
       "4  [(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...   \n",
       "\n",
       "                                         char_ngrams  num_tokens  period_freq  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...           2            0   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...           3            0   \n",
       "2  [i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...           1            0   \n",
       "3  [l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...           2            0   \n",
       "4  [c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...           1            0   \n",
       "\n",
       "   dash_freq  space_freq  name_length  avg_token_length  \\\n",
       "0          1           1           13          6.000000   \n",
       "1          0           2           13          3.666667   \n",
       "2          0           0            9          9.000000   \n",
       "3          0           1            6          2.500000   \n",
       "4          0           0            9          9.000000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.680590   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.762211   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.757701   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.537098   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665396   \n",
       "\n",
       "   bigrams_cosine_sim  \n",
       "0            0.377660  \n",
       "1            0.552090  \n",
       "2            0.344410  \n",
       "3            0.143205  \n",
       "4            0.171394  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. Remaking Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add a_hat_freq and turn categorical columns into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD after Maker Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see 10/16 anna meeting notes for ideas on more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cleaning up other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullname', 'original_fullname', 'alphabet', 'transliteration',\n",
       "       'unigrams', 'bigrams', 'trigrams', 'char_ngrams', 'num_tokens',\n",
       "       'period_freq', 'dash_freq', 'space_freq', 'name_length',\n",
       "       'avg_token_length', 'indiv_unigrams_fdist', 'indiv_bigrams_fdist',\n",
       "       'unigrams_cosine_sim', 'bigrams_cosine_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'original_fullname', 'fullname', 'transliteration', 'alphabet',\n",
       "       'unigrams', 'bigrams', 'trigrams', 'char_ngrams', 'name_length',\n",
       "       'num_tokens', 'avg_token_length', 'period_freq', 'dash_freq',\n",
       "       'space_freq', 'indiv_unigrams_fdist', 'indiv_bigrams_fdist',\n",
       "       'indiv_trigrams_fdist', 'unigrams_cosine_sim', 'bigrams_cosine_sim',\n",
       "       'trigrams_cosine_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turk['apostrophe_freq'] = df_turk['fullname'].apply(lambda name: name.count('\\''))\n",
    "df_korean['apostrophe_freq'] = df_korean['fullname'].apply(lambda name: name.count('\\''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More consolidation, separating characters from romanized, accent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding avg_token_length column to dfs missing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_csv_dfs = [df_arabic_latin, df_croatian, df_dutch, df_english, df_french, df_german, df_hindi_latin, df_italian, df_polish,\n",
    "#                    df_portug, df_russian_latin, df_spanish]\n",
    "# all_dfs = [df_indo, df_malay, df_viet, df_cnrom, df_cnchar, df_turk, df_korean, df_japan]\n",
    "# df_korean_latin, df_korean_non_latin, df_japan_latin, df_japan_non_latin\n",
    "\n",
    "# NEED:\n",
    "# name_length\tavg_token_length\tnum_tokens\tperiod_freq\tdash_freq\tapostrophe_freq\tspace_freq\tunigrams_cosine_sim\tbigrams_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'original_fullname', 'fullname', 'transliteration', 'alphabet',\n",
       "       'unigrams', 'bigrams', 'trigrams', 'char_ngrams', 'name_length',\n",
       "       'num_tokens', 'avg_token_length', 'period_freq', 'dash_freq',\n",
       "       'space_freq', 'indiv_unigrams_fdist', 'indiv_bigrams_fdist',\n",
       "       'indiv_trigrams_fdist', 'unigrams_cosine_sim', 'bigrams_cosine_sim',\n",
       "       'trigrams_cosine_sim', 'apostrophe_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df_korean['fullname'].apply(lambda name: name.split(' '))\n",
    "token_lengths = tokens.apply(lambda token_list: [len(token) for token in token_list])\n",
    "df_korean['avg_token_length'] = token_lengths.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df_japan['fullname'].apply(lambda name: name.split(' '))\n",
    "token_lengths = tokens.apply(lambda token_list: [len(token) for token in token_list])\n",
    "df_japan['avg_token_length'] = token_lengths.apply(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating Korean and Japanese characters from romanized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>avg_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hirotoshi nakamura</td>\n",
       "      <td>Hirotoshi Nakamura</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>hirotoshi nakamura</td>\n",
       "      <td>[h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...</td>\n",
       "      <td>[(h, i), (i, r), (r, o), (o, t), (t, o), (o, s...</td>\n",
       "      <td>[(h, i, r), (i, r, o), (r, o, t), (o, t, o), (...</td>\n",
       "      <td>[h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05555555555555555, 0.0, 0.0, 0.16666666666...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sachio hosokawa</td>\n",
       "      <td>Sachio Hosokawa</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>sachio hosokawa</td>\n",
       "      <td>[s, a, c, h, i, o,  , h, o, s, o, k, a, w, a]</td>\n",
       "      <td>[(s, a), (a, c), (c, h), (h, i), (i, o), (o,  ...</td>\n",
       "      <td>[(s, a, c), (a, c, h), (c, h, i), (h, i, o), (...</td>\n",
       "      <td>[s, a, c, h, i, o,  , h, o, s, o, k, a, w, a, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.06666666666666667, 0.0, 0.0, 0.2, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.805768</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oza</td>\n",
       "      <td>OZA</td>\n",
       "      <td>[LATIN, LATIN, LATIN]</td>\n",
       "      <td>oza</td>\n",
       "      <td>[o, z, a]</td>\n",
       "      <td>[(o, z), (z, a)]</td>\n",
       "      <td>[(o, z, a)]</td>\n",
       "      <td>[o, z, a, (o, z), (z, a), (o, z, a)]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>平塚利男</td>\n",
       "      <td>平塚利男</td>\n",
       "      <td>[CJK, CJK, CJK, CJK]</td>\n",
       "      <td>hiratsuka toshio</td>\n",
       "      <td>[h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, o]</td>\n",
       "      <td>[(h, i), (i, r), (r, a), (a, t), (t, s), (s, u...</td>\n",
       "      <td>[(h, i, r), (i, r, a), (r, a, t), (a, t, s), (...</td>\n",
       "      <td>[h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.883438</td>\n",
       "      <td>0.600381</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jun kochi</td>\n",
       "      <td>Jun Kochi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>jun kochi</td>\n",
       "      <td>[j, u, n,  , k, o, c, h, i]</td>\n",
       "      <td>[(j, u), (u, n), (n,  ), ( , k), (k, o), (o, c...</td>\n",
       "      <td>[(j, u, n), (u, n,  ), (n,  , k), ( , k, o), (...</td>\n",
       "      <td>[j, u, n,  , k, o, c, h, i, (j, u), (u, n), (n...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.646229</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname   original_fullname  \\\n",
       "0  hirotoshi nakamura  Hirotoshi Nakamura   \n",
       "1     sachio hosokawa     Sachio Hosokawa   \n",
       "2                 oza                 OZA   \n",
       "3                平塚利男                平塚利男   \n",
       "4           jun kochi           Jun Kochi   \n",
       "\n",
       "                                            alphabet     transliteration  \\\n",
       "0  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...  hirotoshi nakamura   \n",
       "1  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...     sachio hosokawa   \n",
       "2                              [LATIN, LATIN, LATIN]                 oza   \n",
       "3                               [CJK, CJK, CJK, CJK]    hiratsuka toshio   \n",
       "4  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...           jun kochi   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0  [h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...   \n",
       "1      [s, a, c, h, i, o,  , h, o, s, o, k, a, w, a]   \n",
       "2                                          [o, z, a]   \n",
       "3   [h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, o]   \n",
       "4                        [j, u, n,  , k, o, c, h, i]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(h, i), (i, r), (r, o), (o, t), (t, o), (o, s...   \n",
       "1  [(s, a), (a, c), (c, h), (h, i), (i, o), (o,  ...   \n",
       "2                                   [(o, z), (z, a)]   \n",
       "3  [(h, i), (i, r), (r, a), (a, t), (t, s), (s, u...   \n",
       "4  [(j, u), (u, n), (n,  ), ( , k), (k, o), (o, c...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(h, i, r), (i, r, o), (r, o, t), (o, t, o), (...   \n",
       "1  [(s, a, c), (a, c, h), (c, h, i), (h, i, o), (...   \n",
       "2                                        [(o, z, a)]   \n",
       "3  [(h, i, r), (i, r, a), (r, a, t), (a, t, s), (...   \n",
       "4  [(j, u, n), (u, n,  ), (n,  , k), ( , k, o), (...   \n",
       "\n",
       "                                         char_ngrams  name_length  num_tokens  \\\n",
       "0  [h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...           17           2   \n",
       "1  [s, a, c, h, i, o,  , h, o, s, o, k, a, w, a, ...           14           2   \n",
       "2               [o, z, a, (o, z), (z, a), (o, z, a)]            3           1   \n",
       "3  [h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, ...           15           2   \n",
       "4  [j, u, n,  , k, o, c, h, i, (j, u), (u, n), (n...            8           2   \n",
       "\n",
       "   period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "0            0          0           1                0   \n",
       "1            0          0           1                0   \n",
       "2            0          0           0                0   \n",
       "3            0          0           1                0   \n",
       "4            0          0           1                0   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.05555555555555555, 0.0, 0.0, 0.16666666666...   \n",
       "1  [[0.06666666666666667, 0.0, 0.0, 0.2, 0.0, 0.0...   \n",
       "2  [[0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0,...   \n",
       "3  [[0.0625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.930607   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.805768   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.523246   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.883438   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.646229   \n",
       "\n",
       "   bigrams_cosine_sim  avg_token_length  \n",
       "0            0.612908               8.5  \n",
       "1            0.394186               7.0  \n",
       "2            0.020991               3.0  \n",
       "3            0.600381               4.0  \n",
       "4            0.287507               4.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_japan.rename(columns = {'determine_alphabet': 'alphabet'}, inplace = True)\n",
    "df_japan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...\n",
       "1        [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...\n",
       "2                                 [HANGUL, HANGUL, HANGUL]\n",
       "3               [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]\n",
       "4                                 [HANGUL, HANGUL, HANGUL]\n",
       "                               ...                        \n",
       "21197    [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...\n",
       "21198    [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...\n",
       "21199                             [HANGUL, HANGUL, HANGUL]\n",
       "21200                             [HANGUL, HANGUL, HANGUL]\n",
       "21201    [LATIN, LATIN, SPACE, LATIN, LATIN, HYPHEN-MIN...\n",
       "Name: alphabet, Length: 19118, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean['alphabet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>Park Joo-bong</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...</td>\n",
       "      <td>park joo-bong</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g]</td>\n",
       "      <td>[(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...</td>\n",
       "      <td>[(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...</td>\n",
       "      <td>[p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>[[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>KIM Jong hoon</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>kim jong hoon</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n]</td>\n",
       "      <td>[(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...</td>\n",
       "      <td>[(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...</td>\n",
       "      <td>[k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.552090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이민혁</td>\n",
       "      <td>이민혁</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>iminhyeog</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g]</td>\n",
       "      <td>[(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...</td>\n",
       "      <td>[(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.757701</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lee ho</td>\n",
       "      <td>Lee Ho</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]</td>\n",
       "      <td>lee ho</td>\n",
       "      <td>[l, e, e,  , h, o]</td>\n",
       "      <td>[(l, e), (e, e), (e,  ), ( , h), (h, o)]</td>\n",
       "      <td>[(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]</td>\n",
       "      <td>[l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.537098</td>\n",
       "      <td>0.143205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최민호</td>\n",
       "      <td>최민호</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>choeminho</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o]</td>\n",
       "      <td>[(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...</td>\n",
       "      <td>[(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665396</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fullname original_fullname  \\\n",
       "0  park joo-bong     Park Joo-bong   \n",
       "1  kim jong hoon     KIM Jong hoon   \n",
       "2            이민혁               이민혁   \n",
       "3         lee ho            Lee Ho   \n",
       "4            최민호               최민호   \n",
       "\n",
       "                                            alphabet transliteration  \\\n",
       "0  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...   park joo-bong   \n",
       "1  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...   kim jong hoon   \n",
       "2                           [HANGUL, HANGUL, HANGUL]       iminhyeog   \n",
       "3         [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN]          lee ho   \n",
       "4                           [HANGUL, HANGUL, HANGUL]       choeminho   \n",
       "\n",
       "                                  unigrams  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g]   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n]   \n",
       "2              [i, m, i, n, h, y, e, o, g]   \n",
       "3                       [l, e, e,  , h, o]   \n",
       "4              [c, h, o, e, m, i, n, h, o]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(p, a), (a, r), (r, k), (k,  ), ( , j), (j, o...   \n",
       "1  [(k, i), (i, m), (m,  ), ( , j), (j, o), (o, n...   \n",
       "2  [(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...   \n",
       "3           [(l, e), (e, e), (e,  ), ( , h), (h, o)]   \n",
       "4  [(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(p, a, r), (a, r, k), (r, k,  ), (k,  , j), (...   \n",
       "1  [(k, i, m), (i, m,  ), (m,  , j), ( , j, o), (...   \n",
       "2  [(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...   \n",
       "3       [(l, e, e), (e, e,  ), (e,  , h), ( , h, o)]   \n",
       "4  [(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...   \n",
       "\n",
       "                                         char_ngrams  num_tokens  period_freq  \\\n",
       "0  [p, a, r, k,  , j, o, o, -, b, o, n, g, (p, a)...           2            0   \n",
       "1  [k, i, m,  , j, o, n, g,  , h, o, o, n, (k, i)...           3            0   \n",
       "2  [i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...           1            0   \n",
       "3  [l, e, e,  , h, o, (l, e), (e, e), (e,  ), ( ,...           2            0   \n",
       "4  [c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...           1            0   \n",
       "\n",
       "   dash_freq  space_freq  name_length  avg_token_length  \\\n",
       "0          1           1           13          6.000000   \n",
       "1          0           2           13          3.666667   \n",
       "2          0           0            9          3.000000   \n",
       "3          0           1            6          2.500000   \n",
       "4          0           0            9          3.000000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "1  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.680590   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.762211   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.757701   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.537098   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665396   \n",
       "\n",
       "   bigrams_cosine_sim  apostrophe_freq  \n",
       "0            0.377660                0  \n",
       "1            0.552090                0  \n",
       "2            0.344410                0  \n",
       "3            0.143205                0  \n",
       "4            0.171394                0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_korean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이민혁</td>\n",
       "      <td>이민혁</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>iminhyeog</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g]</td>\n",
       "      <td>[(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...</td>\n",
       "      <td>[(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...</td>\n",
       "      <td>[i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.757701</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>최민호</td>\n",
       "      <td>최민호</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>choeminho</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o]</td>\n",
       "      <td>[(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...</td>\n",
       "      <td>[(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...</td>\n",
       "      <td>[c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.665396</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>이수경</td>\n",
       "      <td>이수경</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>isugyeong</td>\n",
       "      <td>[i, s, u, g, y, e, o, n, g]</td>\n",
       "      <td>[(i, s), (s, u), (u, g), (g, y), (y, e), (e, o...</td>\n",
       "      <td>[(i, s, u), (s, u, g), (u, g, y), (g, y, e), (...</td>\n",
       "      <td>[i, s, u, g, y, e, o, n, g, (i, s), (s, u), (u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.803067</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>서하준</td>\n",
       "      <td>서하준</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>seohajun</td>\n",
       "      <td>[s, e, o, h, a, j, u, n]</td>\n",
       "      <td>[(s, e), (e, o), (o, h), (h, a), (a, j), (j, u...</td>\n",
       "      <td>[(s, e, o), (e, o, h), (o, h, a), (h, a, j), (...</td>\n",
       "      <td>[s, e, o, h, a, j, u, n, (s, e), (e, o), (o, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.330478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>윤종규</td>\n",
       "      <td>윤종규</td>\n",
       "      <td>[HANGUL, HANGUL, HANGUL]</td>\n",
       "      <td>yunjonggyu</td>\n",
       "      <td>[y, u, n, j, o, n, g, g, y, u]</td>\n",
       "      <td>[(y, u), (u, n), (n, j), (j, o), (o, n), (n, g...</td>\n",
       "      <td>[(y, u, n), (u, n, j), (n, j, o), (j, o, n), (...</td>\n",
       "      <td>[y, u, n, j, o, n, g, g, y, u, (y, u), (u, n),...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.692096</td>\n",
       "      <td>0.458872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fullname original_fullname                  alphabet transliteration  \\\n",
       "2      이민혁               이민혁  [HANGUL, HANGUL, HANGUL]       iminhyeog   \n",
       "4      최민호               최민호  [HANGUL, HANGUL, HANGUL]       choeminho   \n",
       "6      이수경               이수경  [HANGUL, HANGUL, HANGUL]       isugyeong   \n",
       "7      서하준               서하준  [HANGUL, HANGUL, HANGUL]        seohajun   \n",
       "9      윤종규               윤종규  [HANGUL, HANGUL, HANGUL]      yunjonggyu   \n",
       "\n",
       "                         unigrams  \\\n",
       "2     [i, m, i, n, h, y, e, o, g]   \n",
       "4     [c, h, o, e, m, i, n, h, o]   \n",
       "6     [i, s, u, g, y, e, o, n, g]   \n",
       "7        [s, e, o, h, a, j, u, n]   \n",
       "9  [y, u, n, j, o, n, g, g, y, u]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "2  [(i, m), (m, i), (i, n), (n, h), (h, y), (y, e...   \n",
       "4  [(c, h), (h, o), (o, e), (e, m), (m, i), (i, n...   \n",
       "6  [(i, s), (s, u), (u, g), (g, y), (y, e), (e, o...   \n",
       "7  [(s, e), (e, o), (o, h), (h, a), (a, j), (j, u...   \n",
       "9  [(y, u), (u, n), (n, j), (j, o), (o, n), (n, g...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "2  [(i, m, i), (m, i, n), (i, n, h), (n, h, y), (...   \n",
       "4  [(c, h, o), (h, o, e), (o, e, m), (e, m, i), (...   \n",
       "6  [(i, s, u), (s, u, g), (u, g, y), (g, y, e), (...   \n",
       "7  [(s, e, o), (e, o, h), (o, h, a), (h, a, j), (...   \n",
       "9  [(y, u, n), (u, n, j), (n, j, o), (j, o, n), (...   \n",
       "\n",
       "                                         char_ngrams  num_tokens  period_freq  \\\n",
       "2  [i, m, i, n, h, y, e, o, g, (i, m), (m, i), (i...           1            0   \n",
       "4  [c, h, o, e, m, i, n, h, o, (c, h), (h, o), (o...           1            0   \n",
       "6  [i, s, u, g, y, e, o, n, g, (i, s), (s, u), (u...           1            0   \n",
       "7  [s, e, o, h, a, j, u, n, (s, e), (e, o), (o, h...           1            0   \n",
       "9  [y, u, n, j, o, n, g, g, y, u, (y, u), (u, n),...           1            0   \n",
       "\n",
       "   dash_freq  space_freq  name_length  avg_token_length  \\\n",
       "2          0           0            9               3.0   \n",
       "4          0           0            9               3.0   \n",
       "6          0           0            9               3.0   \n",
       "7          0           0            8               3.0   \n",
       "9          0           0           10               3.0   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "9  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.757701   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.665396   \n",
       "6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.803067   \n",
       "7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.753968   \n",
       "9  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.692096   \n",
       "\n",
       "   bigrams_cosine_sim  apostrophe_freq  \n",
       "2            0.344410                0  \n",
       "4            0.171394                0  \n",
       "6            0.547257                0  \n",
       "7            0.330478                0  \n",
       "9            0.458872                0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_mask = df_korean['fullname'].str.contains(r'[a-zA-Z]')\n",
    "df_korean_latin = df_korean[latin_mask]\n",
    "df_korean_non_latin = df_korean[~latin_mask]\n",
    "df_korean_non_latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>avg_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hirotoshi nakamura</td>\n",
       "      <td>Hirotoshi Nakamura</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>hirotoshi nakamura</td>\n",
       "      <td>[h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...</td>\n",
       "      <td>[(h, i), (i, r), (r, o), (o, t), (t, o), (o, s...</td>\n",
       "      <td>[(h, i, r), (i, r, o), (r, o, t), (o, t, o), (...</td>\n",
       "      <td>[h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05555555555555555, 0.0, 0.0, 0.16666666666...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sachio hosokawa</td>\n",
       "      <td>Sachio Hosokawa</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>sachio hosokawa</td>\n",
       "      <td>[s, a, c, h, i, o,  , h, o, s, o, k, a, w, a]</td>\n",
       "      <td>[(s, a), (a, c), (c, h), (h, i), (i, o), (o,  ...</td>\n",
       "      <td>[(s, a, c), (a, c, h), (c, h, i), (h, i, o), (...</td>\n",
       "      <td>[s, a, c, h, i, o,  , h, o, s, o, k, a, w, a, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.06666666666666667, 0.0, 0.0, 0.2, 0.0, 0.0...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.805768</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oza</td>\n",
       "      <td>OZA</td>\n",
       "      <td>[LATIN, LATIN, LATIN]</td>\n",
       "      <td>oza</td>\n",
       "      <td>[o, z, a]</td>\n",
       "      <td>[(o, z), (z, a)]</td>\n",
       "      <td>[(o, z, a)]</td>\n",
       "      <td>[o, z, a, (o, z), (z, a), (o, z, a)]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jun kochi</td>\n",
       "      <td>Jun Kochi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...</td>\n",
       "      <td>jun kochi</td>\n",
       "      <td>[j, u, n,  , k, o, c, h, i]</td>\n",
       "      <td>[(j, u), (u, n), (n,  ), ( , k), (k, o), (o, c...</td>\n",
       "      <td>[(j, u, n), (u, n,  ), (n,  , k), ( , k, o), (...</td>\n",
       "      <td>[j, u, n,  , k, o, c, h, i, (j, u), (u, n), (n...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.646229</td>\n",
       "      <td>0.287507</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>suguru kubota</td>\n",
       "      <td>Suguru Kubota</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>suguru kubota</td>\n",
       "      <td>[s, u, g, u, r, u,  , k, u, b, o, t, a]</td>\n",
       "      <td>[(s, u), (u, g), (g, u), (u, r), (r, u), (u,  ...</td>\n",
       "      <td>[(s, u, g), (u, g, u), (g, u, r), (u, r, u), (...</td>\n",
       "      <td>[s, u, g, u, r, u,  , k, u, b, o, t, a, (s, u)...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.07692307692307693, 0.0, 0.0, 0.07692307692...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.604463</td>\n",
       "      <td>0.239627</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fullname   original_fullname  \\\n",
       "0  hirotoshi nakamura  Hirotoshi Nakamura   \n",
       "1     sachio hosokawa     Sachio Hosokawa   \n",
       "2                 oza                 OZA   \n",
       "4           jun kochi           Jun Kochi   \n",
       "5       suguru kubota       Suguru Kubota   \n",
       "\n",
       "                                            alphabet     transliteration  \\\n",
       "0  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...  hirotoshi nakamura   \n",
       "1  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...     sachio hosokawa   \n",
       "2                              [LATIN, LATIN, LATIN]                 oza   \n",
       "4  [LATIN, LATIN, LATIN, SPACE, LATIN, LATIN, LAT...           jun kochi   \n",
       "5  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...       suguru kubota   \n",
       "\n",
       "                                            unigrams  \\\n",
       "0  [h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...   \n",
       "1      [s, a, c, h, i, o,  , h, o, s, o, k, a, w, a]   \n",
       "2                                          [o, z, a]   \n",
       "4                        [j, u, n,  , k, o, c, h, i]   \n",
       "5            [s, u, g, u, r, u,  , k, u, b, o, t, a]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(h, i), (i, r), (r, o), (o, t), (t, o), (o, s...   \n",
       "1  [(s, a), (a, c), (c, h), (h, i), (i, o), (o,  ...   \n",
       "2                                   [(o, z), (z, a)]   \n",
       "4  [(j, u), (u, n), (n,  ), ( , k), (k, o), (o, c...   \n",
       "5  [(s, u), (u, g), (g, u), (u, r), (r, u), (u,  ...   \n",
       "\n",
       "                                            trigrams  \\\n",
       "0  [(h, i, r), (i, r, o), (r, o, t), (o, t, o), (...   \n",
       "1  [(s, a, c), (a, c, h), (c, h, i), (h, i, o), (...   \n",
       "2                                        [(o, z, a)]   \n",
       "4  [(j, u, n), (u, n,  ), (n,  , k), ( , k, o), (...   \n",
       "5  [(s, u, g), (u, g, u), (g, u, r), (u, r, u), (...   \n",
       "\n",
       "                                         char_ngrams  name_length  num_tokens  \\\n",
       "0  [h, i, r, o, t, o, s, h, i,  , n, a, k, a, m, ...           17           2   \n",
       "1  [s, a, c, h, i, o,  , h, o, s, o, k, a, w, a, ...           14           2   \n",
       "2               [o, z, a, (o, z), (z, a), (o, z, a)]            3           1   \n",
       "4  [j, u, n,  , k, o, c, h, i, (j, u), (u, n), (n...            8           2   \n",
       "5  [s, u, g, u, r, u,  , k, u, b, o, t, a, (s, u)...           12           2   \n",
       "\n",
       "   period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "0            0          0           1                0   \n",
       "1            0          0           1                0   \n",
       "2            0          0           0                0   \n",
       "4            0          0           1                0   \n",
       "5            0          0           1                0   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.05555555555555555, 0.0, 0.0, 0.16666666666...   \n",
       "1  [[0.06666666666666667, 0.0, 0.0, 0.2, 0.0, 0.0...   \n",
       "2  [[0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0,...   \n",
       "4  [[0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.11...   \n",
       "5  [[0.07692307692307693, 0.0, 0.0, 0.07692307692...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.930607   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.805768   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.523246   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.646229   \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.604463   \n",
       "\n",
       "   bigrams_cosine_sim  avg_token_length  \n",
       "0            0.612908               8.5  \n",
       "1            0.394186               7.0  \n",
       "2            0.020991               3.0  \n",
       "4            0.287507               4.0  \n",
       "5            0.239627               6.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latin_mask = df_japan['fullname'].str.contains(r'[a-zA-Z]')\n",
    "df_japan_latin = df_japan[latin_mask]\n",
    "df_japan_non_latin = df_japan[~latin_mask]\n",
    "df_japan_latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>avg_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>平塚利男</td>\n",
       "      <td>平塚利男</td>\n",
       "      <td>[CJK, CJK, CJK, CJK]</td>\n",
       "      <td>hiratsuka toshio</td>\n",
       "      <td>[h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, o]</td>\n",
       "      <td>[(h, i), (i, r), (r, a), (a, t), (t, s), (s, u...</td>\n",
       "      <td>[(h, i, r), (i, r, a), (r, a, t), (a, t, s), (...</td>\n",
       "      <td>[h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.883438</td>\n",
       "      <td>0.600381</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中野正俊</td>\n",
       "      <td>中野正俊</td>\n",
       "      <td>[CJK, CJK, CJK, CJK]</td>\n",
       "      <td>nakano masatoshi</td>\n",
       "      <td>[n, a, k, a, n, o,  , m, a, s, a, t, o, s, h, i]</td>\n",
       "      <td>[(n, a), (a, k), (k, a), (a, n), (n, o), (o,  ...</td>\n",
       "      <td>[(n, a, k), (a, k, a), (k, a, n), (a, n, o), (...</td>\n",
       "      <td>[n, a, k, a, n, o,  , m, a, s, a, t, o, s, h, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0625, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.865120</td>\n",
       "      <td>0.623953</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>尺振八</td>\n",
       "      <td>尺振八</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>shaku shinpachi</td>\n",
       "      <td>[s, h, a, k, u,  , s, h, i, n, p, a, c, h, i]</td>\n",
       "      <td>[(s, h), (h, a), (a, k), (k, u), (u,  ), ( , s...</td>\n",
       "      <td>[(s, h, a), (h, a, k), (a, k, u), (k, u,  ), (...</td>\n",
       "      <td>[s, h, a, k, u,  , s, h, i, n, p, a, c, h, i, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.06666666666666667, 0.0, 0.0, 0.13333333333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.758203</td>\n",
       "      <td>0.466828</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>吉永みち子</td>\n",
       "      <td>吉永みち子</td>\n",
       "      <td>[CJK, CJK, HIRAGANA, HIRAGANA, CJK]</td>\n",
       "      <td>yoshinaga michi ko</td>\n",
       "      <td>[y, o, s, h, i, n, a, g, a,  , m, i, c, h, i, ...</td>\n",
       "      <td>[(y, o), (o, s), (s, h), (h, i), (i, n), (n, a...</td>\n",
       "      <td>[(y, o, s), (o, s, h), (s, h, i), (h, i, n), (...</td>\n",
       "      <td>[y, o, s, h, i, n, a, g, a,  , m, i, c, h, i, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.1111111111111111, 0.0, 0.0, 0.111111111111...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.869671</td>\n",
       "      <td>0.576394</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>かかし朝浩</td>\n",
       "      <td>かかし朝浩</td>\n",
       "      <td>[HIRAGANA, HIRAGANA, HIRAGANA, CJK, CJK]</td>\n",
       "      <td>kakashi asa hiroshi</td>\n",
       "      <td>[k, a, k, a, s, h, i,  , a, s, a,  , h, i, r, ...</td>\n",
       "      <td>[(k, a), (a, k), (k, a), (a, s), (s, h), (h, i...</td>\n",
       "      <td>[(k, a, k), (a, k, a), (k, a, s), (a, s, h), (...</td>\n",
       "      <td>[k, a, k, a, s, h, i,  , a, s, a,  , h, i, r, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.10526315789473684, 0.0, 0.0, 0.21052631578...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0...</td>\n",
       "      <td>0.857157</td>\n",
       "      <td>0.650052</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fullname original_fullname                                  alphabet  \\\n",
       "3      平塚利男              平塚利男                      [CJK, CJK, CJK, CJK]   \n",
       "7      中野正俊              中野正俊                      [CJK, CJK, CJK, CJK]   \n",
       "10      尺振八               尺振八                           [CJK, CJK, CJK]   \n",
       "11    吉永みち子             吉永みち子       [CJK, CJK, HIRAGANA, HIRAGANA, CJK]   \n",
       "13    かかし朝浩             かかし朝浩  [HIRAGANA, HIRAGANA, HIRAGANA, CJK, CJK]   \n",
       "\n",
       "        transliteration                                           unigrams  \\\n",
       "3      hiratsuka toshio   [h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, o]   \n",
       "7      nakano masatoshi   [n, a, k, a, n, o,  , m, a, s, a, t, o, s, h, i]   \n",
       "10      shaku shinpachi      [s, h, a, k, u,  , s, h, i, n, p, a, c, h, i]   \n",
       "11   yoshinaga michi ko  [y, o, s, h, i, n, a, g, a,  , m, i, c, h, i, ...   \n",
       "13  kakashi asa hiroshi  [k, a, k, a, s, h, i,  , a, s, a,  , h, i, r, ...   \n",
       "\n",
       "                                              bigrams  \\\n",
       "3   [(h, i), (i, r), (r, a), (a, t), (t, s), (s, u...   \n",
       "7   [(n, a), (a, k), (k, a), (a, n), (n, o), (o,  ...   \n",
       "10  [(s, h), (h, a), (a, k), (k, u), (u,  ), ( , s...   \n",
       "11  [(y, o), (o, s), (s, h), (h, i), (i, n), (n, a...   \n",
       "13  [(k, a), (a, k), (k, a), (a, s), (s, h), (h, i...   \n",
       "\n",
       "                                             trigrams  \\\n",
       "3   [(h, i, r), (i, r, a), (r, a, t), (a, t, s), (...   \n",
       "7   [(n, a, k), (a, k, a), (k, a, n), (a, n, o), (...   \n",
       "10  [(s, h, a), (h, a, k), (a, k, u), (k, u,  ), (...   \n",
       "11  [(y, o, s), (o, s, h), (s, h, i), (h, i, n), (...   \n",
       "13  [(k, a, k), (a, k, a), (k, a, s), (a, s, h), (...   \n",
       "\n",
       "                                          char_ngrams  name_length  \\\n",
       "3   [h, i, r, a, t, s, u, k, a,  , t, o, s, h, i, ...           15   \n",
       "7   [n, a, k, a, n, o,  , m, a, s, a, t, o, s, h, ...           15   \n",
       "10  [s, h, a, k, u,  , s, h, i, n, p, a, c, h, i, ...           14   \n",
       "11  [y, o, s, h, i, n, a, g, a,  , m, i, c, h, i, ...           16   \n",
       "13  [k, a, k, a, s, h, i,  , a, s, a,  , h, i, r, ...           17   \n",
       "\n",
       "    num_tokens  period_freq  dash_freq  space_freq  apostrophe_freq  \\\n",
       "3            2            0          0           1                0   \n",
       "7            2            0          0           1                0   \n",
       "10           2            0          0           1                0   \n",
       "11           3            0          0           2                0   \n",
       "13           3            0          0           2                0   \n",
       "\n",
       "                                 indiv_unigrams_fdist  \\\n",
       "3   [[0.0625, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7   [[0.0625, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "10  [[0.06666666666666667, 0.0, 0.0, 0.13333333333...   \n",
       "11  [[0.1111111111111111, 0.0, 0.0, 0.111111111111...   \n",
       "13  [[0.10526315789473684, 0.0, 0.0, 0.21052631578...   \n",
       "\n",
       "                                  indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "3   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.883438   \n",
       "7   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.865120   \n",
       "10  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.758203   \n",
       "11  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.869671   \n",
       "13  [[0.0, 0.0, 0.0, 0.05555555555555555, 0.0, 0.0...             0.857157   \n",
       "\n",
       "    bigrams_cosine_sim  avg_token_length  \n",
       "3             0.600381               4.0  \n",
       "7             0.623953               4.0  \n",
       "10            0.466828               3.0  \n",
       "11            0.576394               5.0  \n",
       "13            0.650052               5.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_japan_non_latin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to separate CJK and create a list of Latin dataframes only because otherwise, CJK characters would get counted as accents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't include CJK or HANGUL\n",
    "# company_csv_dfs = [df_arabic_latin, df_croatian, df_dutch, df_english, df_french, df_german, df_hindi_latin, df_italian, df_polish,\n",
    "#                    df_portug, df_russian_latin, df_spanish]\n",
    "# all_dfs = [df_indo, df_malay, df_viet, df_cnrom, df_cnchar, df_turk, df_korean, df_japan]\n",
    "df_latin = company_csv_dfs\n",
    "df_latin.extend([df_indo, df_malay, df_viet, df_cnrom, df_turk, df_korean_latin, df_japan_latin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnrom.rename(columns = {'original_fullname': 'fullname'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/295077215.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns = {'name_lower': 'fullname'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "for df in company_csv_dfs:\n",
    "    df.rename(columns = {'name_lower': 'fullname'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying accent counts\n",
    "def count_accents(name):\n",
    "    num_accents = 0\n",
    "    for char in name:\n",
    "        if unicodedata.normalize('NFD', char) != char:\n",
    "            num_accents += 1\n",
    "    return num_accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/1256525415.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['accent_count'] = df['fullname'].apply(count_accents)\n",
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/1256525415.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['accent_count'] = df['fullname'].apply(count_accents)\n"
     ]
    }
   ],
   "source": [
    "for df in df_latin:\n",
    "    df['accent_count'] = df['fullname'].apply(count_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/3079166869.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['accent_count'] = 0\n",
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/3079166869.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['accent_count'] = 0\n"
     ]
    }
   ],
   "source": [
    "# set other accents to 0\n",
    "df_non_latin = [df_cnchar, df_japan_non_latin, df_korean_non_latin]\n",
    "for df in df_non_latin:\n",
    "    df['accent_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_accents(df, col_name, all_accents):\n",
    "    for name in df[col_name]:\n",
    "        for char in name:\n",
    "            if unicodedata.normalize('NFD', char) != char:\n",
    "                all_accents.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ë',\n",
       " 'ì',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ñ',\n",
       " 'ò',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'õ',\n",
       " 'ö',\n",
       " 'ù',\n",
       " 'ú',\n",
       " 'û',\n",
       " 'ü',\n",
       " 'ý',\n",
       " 'ÿ',\n",
       " 'ā',\n",
       " 'ă',\n",
       " 'ą',\n",
       " 'ć',\n",
       " 'č',\n",
       " 'ē',\n",
       " 'ę',\n",
       " 'ğ',\n",
       " 'ĩ',\n",
       " 'ī',\n",
       " 'ń',\n",
       " 'ō',\n",
       " 'ŏ',\n",
       " 'ś',\n",
       " 'ş',\n",
       " 'š',\n",
       " 'ţ',\n",
       " 'ũ',\n",
       " 'ū',\n",
       " 'ŭ',\n",
       " 'ű',\n",
       " 'ź',\n",
       " 'ż',\n",
       " 'ž',\n",
       " 'ơ',\n",
       " 'ư',\n",
       " 'ǎ',\n",
       " 'ǧ',\n",
       " 'ǹ',\n",
       " 'ș',\n",
       " 'ț',\n",
       " 'ḫ',\n",
       " 'ạ',\n",
       " 'ả',\n",
       " 'ấ',\n",
       " 'ầ',\n",
       " 'ẩ',\n",
       " 'ẫ',\n",
       " 'ậ',\n",
       " 'ắ',\n",
       " 'ằ',\n",
       " 'ặ',\n",
       " 'ế',\n",
       " 'ề',\n",
       " 'ể',\n",
       " 'ễ',\n",
       " 'ệ',\n",
       " 'ỉ',\n",
       " 'ị',\n",
       " 'ọ',\n",
       " 'ỏ',\n",
       " 'ố',\n",
       " 'ồ',\n",
       " 'ổ',\n",
       " 'ỗ',\n",
       " 'ộ',\n",
       " 'ớ',\n",
       " 'ờ',\n",
       " 'ở',\n",
       " 'ợ',\n",
       " 'ụ',\n",
       " 'ủ',\n",
       " 'ứ',\n",
       " 'ừ',\n",
       " 'ử',\n",
       " 'ữ',\n",
       " 'ự',\n",
       " 'ỳ',\n",
       " 'ỵ',\n",
       " 'ỷ',\n",
       " 'ỹ',\n",
       " 'が',\n",
       " 'ご',\n",
       " 'ざ',\n",
       " 'じ',\n",
       " 'ず',\n",
       " 'で',\n",
       " 'ゴ',\n",
       " 'ザ',\n",
       " 'ジ',\n",
       " 'ズ',\n",
       " 'ダ',\n",
       " 'デ',\n",
       " 'ド',\n",
       " 'パ',\n",
       " 'ビ',\n",
       " 'ブ',\n",
       " 'ペ',\n",
       " 'ボ',\n",
       " 'ポ',\n",
       " 'ヴ',\n",
       " '거',\n",
       " '고',\n",
       " '김',\n",
       " '나',\n",
       " '동',\n",
       " '딩',\n",
       " '라',\n",
       " '래',\n",
       " '릴',\n",
       " '몽',\n",
       " '성',\n",
       " '스',\n",
       " '욱',\n",
       " '유',\n",
       " '윤',\n",
       " '이',\n",
       " '조',\n",
       " '지',\n",
       " '진',\n",
       " '컷',\n",
       " '클',\n",
       " '타',\n",
       " '투',\n",
       " '퍼',\n",
       " '현'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accents = set()\n",
    "for df in df_latin:\n",
    "    find_all_accents(df, 'fullname', all_accents)\n",
    "print(len(all_accents))\n",
    "all_accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [df_indo, df_malay, df_viet, df_cnrom, df_cnchar, df_turk, df_korean_latin, df_korean_non_latin, df_japan_latin, df_japan_non_latin,\n",
    "           df_arabic_latin, df_croatian, df_dutch, df_english, df_french, df_german, df_hindi_latin, df_italian, df_polish,df_portug, df_russian_latin, df_spanish]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adding the language (label) to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/4039237494.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_korean_latin['language'] = 'Korean (Romanized)'\n",
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/4039237494.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_korean_non_latin['language'] = 'Korean (Characters)'\n",
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/4039237494.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_japan_latin['language'] = 'Japanese (Romanized)'\n",
      "/var/folders/gl/9r15n5c95wb28j_6336yjr180000gn/T/ipykernel_83661/4039237494.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_japan_non_latin['language'] = 'Japanese (Characters)'\n"
     ]
    }
   ],
   "source": [
    "df_indo['language'] = 'Indonesian'\n",
    "df_malay['language'] = 'Malay'\n",
    "df_viet['language'] = 'Vietnamese'\n",
    "df_cnrom['language'] = 'Chinese (Romanized)'\n",
    "df_cnchar['language'] = 'Chinese (Characters)'\n",
    "df_turk['language'] = 'Turkish'\n",
    "df_korean_latin['language'] = 'Korean (Romanized)'\n",
    "df_korean_non_latin['language'] = 'Korean (Characters)'\n",
    "df_japan_latin['language'] = 'Japanese (Romanized)'\n",
    "df_japan_non_latin['language'] = 'Japanese (Characters)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_csv_dfs: df_arabic_latin, df_croatian, df_dutch, df_english, df_french, df_german, df_hindi_latin, df_italian, df_polish,\n",
    "#                  df_portug, df_russian_latin, df_spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arabic_latin['language'] = 'Arabic (Romanized)'\n",
    "df_croatian['language'] = 'Croatian'\n",
    "df_dutch['language'] = 'Dutch'\n",
    "df_english['language'] = 'English'\n",
    "df_french['language'] = 'French'\n",
    "df_german['language'] = 'German'\n",
    "df_hindi_latin['language'] = 'Hindi (Romanized)'\n",
    "df_italian['language'] = 'Italian'\n",
    "df_polish['language'] = 'Polish'\n",
    "df_portug['language'] = 'Portuguese'\n",
    "df_russian_latin['language'] = 'Russian (Romanized)'\n",
    "df_spanish['language'] = 'Spanish'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding which datasets have null fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese (Characters)\n"
     ]
    }
   ],
   "source": [
    "for df in all_dfs:\n",
    "    if 'fullname' not in df.columns:\n",
    "        print(df['language'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁一平</td>\n",
       "      <td>ding yi ping</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , p, i, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.774279</td>\n",
       "      <td>0.548928</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁世雄</td>\n",
       "      <td>ding shi xiong</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , s, h, i,  , x, i, o, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.811762</td>\n",
       "      <td>0.560151</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丁亦昕</td>\n",
       "      <td>ding yi xin</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , x, i, n]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.510394</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>丁仲礼</td>\n",
       "      <td>ding zhong li</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...</td>\n",
       "      <td>[d, i, n, g,  , z, h, o, n, g,  , l, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.605839</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>丁伟</td>\n",
       "      <td>ding wei</td>\n",
       "      <td>[CJK, CJK]</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , w, e, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>[[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.440812</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_fullname transliteration         alphabet  name_length  num_tokens  \\\n",
       "0               丁一平    ding yi ping  [CJK, CJK, CJK]           12           3   \n",
       "1               丁世雄  ding shi xiong  [CJK, CJK, CJK]           14           3   \n",
       "2               丁亦昕     ding yi xin  [CJK, CJK, CJK]           11           3   \n",
       "3               丁仲礼   ding zhong li  [CJK, CJK, CJK]           13           3   \n",
       "4                丁伟        ding wei       [CJK, CJK]            8           2   \n",
       "\n",
       "                                         char_ngrams  \\\n",
       "0  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "1  [(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...   \n",
       "2  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "3  [(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...   \n",
       "4  [(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...   \n",
       "\n",
       "                                     unigrams  \\\n",
       "0        [d, i, n, g,  , y, i,  , p, i, n, g]   \n",
       "1  [d, i, n, g,  , s, h, i,  , x, i, o, n, g]   \n",
       "2           [d, i, n, g,  , y, i,  , x, i, n]   \n",
       "3     [d, i, n, g,  , z, h, o, n, g,  , l, i]   \n",
       "4                    [d, i, n, g,  , w, e, i]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "1  [(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...   \n",
       "2  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "3  [(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...   \n",
       "4  [(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...   \n",
       "\n",
       "                                            trigrams  period_freq  dash_freq  \\\n",
       "0  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "1  [(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...            0          0   \n",
       "2  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0          0   \n",
       "3  [(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...            0          0   \n",
       "4  [(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...            0          0   \n",
       "\n",
       "   space_freq  apostrophe_freq  avg_token_length  \\\n",
       "0           2                0          3.333333   \n",
       "1           2                0          4.000000   \n",
       "2           2                0          3.000000   \n",
       "3           2                0          3.666667   \n",
       "4           1                0          3.500000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...   \n",
       "1  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...   \n",
       "2  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...   \n",
       "3  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...   \n",
       "4  [[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...   \n",
       "\n",
       "                                 indiv_bigrams_fdist  unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.774279   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.811762   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.776390   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.841584   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...             0.710349   \n",
       "\n",
       "   bigrams_cosine_sim  accent_count              language  \n",
       "0            0.548928             0  Chinese (Characters)  \n",
       "1            0.560151             0  Chinese (Characters)  \n",
       "2            0.510394             0  Chinese (Characters)  \n",
       "3            0.605839             0  Chinese (Characters)  \n",
       "4            0.440812             0  Chinese (Characters)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnchar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>indiv_unigrams_fdist</th>\n",
       "      <th>indiv_bigrams_fdist</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>language</th>\n",
       "      <th>fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁一平</td>\n",
       "      <td>ding yi ping</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , p, i, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>[[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.774279</td>\n",
       "      <td>0.548928</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>丁一平</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁世雄</td>\n",
       "      <td>ding shi xiong</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , s, h, i,  , x, i, o, n, g]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.811762</td>\n",
       "      <td>0.560151</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>丁世雄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>丁亦昕</td>\n",
       "      <td>ding yi xin</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...</td>\n",
       "      <td>[d, i, n, g,  , y, i,  , x, i, n]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.510394</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>丁亦昕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>丁仲礼</td>\n",
       "      <td>ding zhong li</td>\n",
       "      <td>[CJK, CJK, CJK]</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...</td>\n",
       "      <td>[d, i, n, g,  , z, h, o, n, g,  , l, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>[[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.605839</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>丁仲礼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>丁伟</td>\n",
       "      <td>ding wei</td>\n",
       "      <td>[CJK, CJK]</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...</td>\n",
       "      <td>[d, i, n, g,  , w, e, i]</td>\n",
       "      <td>[(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...</td>\n",
       "      <td>[(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>[[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.440812</td>\n",
       "      <td>0</td>\n",
       "      <td>Chinese (Characters)</td>\n",
       "      <td>丁伟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_fullname transliteration         alphabet  name_length  num_tokens  \\\n",
       "0               丁一平    ding yi ping  [CJK, CJK, CJK]           12           3   \n",
       "1               丁世雄  ding shi xiong  [CJK, CJK, CJK]           14           3   \n",
       "2               丁亦昕     ding yi xin  [CJK, CJK, CJK]           11           3   \n",
       "3               丁仲礼   ding zhong li  [CJK, CJK, CJK]           13           3   \n",
       "4                丁伟        ding wei       [CJK, CJK]            8           2   \n",
       "\n",
       "                                         char_ngrams  \\\n",
       "0  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "1  [(d,), (i,), (n,), (g,), ( ,), (s,), (h,), (i,...   \n",
       "2  [(d,), (i,), (n,), (g,), ( ,), (y,), (i,), ( ,...   \n",
       "3  [(d,), (i,), (n,), (g,), ( ,), (z,), (h,), (o,...   \n",
       "4  [(d,), (i,), (n,), (g,), ( ,), (w,), (e,), (i,...   \n",
       "\n",
       "                                     unigrams  \\\n",
       "0        [d, i, n, g,  , y, i,  , p, i, n, g]   \n",
       "1  [d, i, n, g,  , s, h, i,  , x, i, o, n, g]   \n",
       "2           [d, i, n, g,  , y, i,  , x, i, n]   \n",
       "3     [d, i, n, g,  , z, h, o, n, g,  , l, i]   \n",
       "4                    [d, i, n, g,  , w, e, i]   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "1  [(d, i), (i, n), (n, g), (g,  ), ( , s), (s, h...   \n",
       "2  [(d, i), (i, n), (n, g), (g,  ), ( , y), (y, i...   \n",
       "3  [(d, i), (i, n), (n, g), (g,  ), ( , z), (z, h...   \n",
       "4  [(d, i), (i, n), (n, g), (g,  ), ( , w), (w, e...   \n",
       "\n",
       "                                            trigrams  period_freq  ...  \\\n",
       "0  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0  ...   \n",
       "1  [(d, i, n), (i, n, g), (n, g,  ), (g,  , s), (...            0  ...   \n",
       "2  [(d, i, n), (i, n, g), (n, g,  ), (g,  , y), (...            0  ...   \n",
       "3  [(d, i, n), (i, n, g), (n, g,  ), (g,  , z), (...            0  ...   \n",
       "4  [(d, i, n), (i, n, g), (n, g,  ), (g,  , w), (...            0  ...   \n",
       "\n",
       "   space_freq  apostrophe_freq  avg_token_length  \\\n",
       "0           2                0          3.333333   \n",
       "1           2                0          4.000000   \n",
       "2           2                0          3.000000   \n",
       "3           2                0          3.666667   \n",
       "4           1                0          3.500000   \n",
       "\n",
       "                                indiv_unigrams_fdist  \\\n",
       "0  [[0.16666666666666666, 0.0, 0.0, 0.0, 0.083333...   \n",
       "1  [[0.14285714285714285, 0.0, 0.0, 0.0, 0.071428...   \n",
       "2  [[0.18181818181818182, 0.0, 0.0, 0.0, 0.090909...   \n",
       "3  [[0.15384615384615385, 0.0, 0.0, 0.0, 0.076923...   \n",
       "4  [[0.125, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.1...   \n",
       "\n",
       "                                 indiv_bigrams_fdist unigrams_cosine_sim  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.774279   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.811762   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.776390   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.841584   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            0.710349   \n",
       "\n",
       "   bigrams_cosine_sim  accent_count              language fullname  \n",
       "0            0.548928             0  Chinese (Characters)      丁一平  \n",
       "1            0.560151             0  Chinese (Characters)      丁世雄  \n",
       "2            0.510394             0  Chinese (Characters)      丁亦昕  \n",
       "3            0.605839             0  Chinese (Characters)      丁仲礼  \n",
       "4            0.440812             0  Chinese (Characters)       丁伟  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnchar['fullname'] = df_cnchar['original_fullname']\n",
    "df_cnchar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Combining all names to make one big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "      <th>detected_accents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supriyadi</td>\n",
       "      <td>Supriyadi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, u, p, r, i, y, a, d, i]</td>\n",
       "      <td>[(s, u), (u, p), (p, r), (r, i), (i, y), (y, a...</td>\n",
       "      <td>[(s, u, p), (u, p, r), (p, r, i), (r, i, y), (...</td>\n",
       "      <td>[s, u, p, r, i, y, a, d, i, (s, u), (u, p), (p...</td>\n",
       "      <td>[supriyadi]</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triyaningsih</td>\n",
       "      <td>Triyaningsih</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[t, r, i, y, a, n, i, n, g, s, i, h]</td>\n",
       "      <td>[(t, r), (r, i), (i, y), (y, a), (a, n), (n, i...</td>\n",
       "      <td>[(t, r, i), (r, i, y), (i, y, a), (y, a, n), (...</td>\n",
       "      <td>[t, r, i, y, a, n, i, n, g, s, i, h, (t, r), (...</td>\n",
       "      <td>[triyaningsih]</td>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0.117226</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soerjadi</td>\n",
       "      <td>Soerjadi</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, o, e, r, j, a, d, i]</td>\n",
       "      <td>[(s, o), (o, e), (e, r), (r, j), (j, a), (a, d...</td>\n",
       "      <td>[(s, o, e), (o, e, r), (e, r, j), (r, j, a), (...</td>\n",
       "      <td>[s, o, e, r, j, a, d, i, (s, o), (o, e), (e, r...</td>\n",
       "      <td>[soerjadi]</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0.090295</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undunsyah</td>\n",
       "      <td>Undunsyah</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[u, n, d, u, n, s, y, a, h]</td>\n",
       "      <td>[(u, n), (n, d), (d, u), (u, n), (n, s), (s, y...</td>\n",
       "      <td>[(u, n, d), (n, d, u), (d, u, n), (u, n, s), (...</td>\n",
       "      <td>[u, n, d, u, n, s, y, a, h, (u, n), (n, d), (d...</td>\n",
       "      <td>[undunsyah]</td>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0.060083</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soeripto</td>\n",
       "      <td>Soeripto</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[s, o, e, r, i, p, t, o]</td>\n",
       "      <td>[(s, o), (o, e), (e, r), (r, i), (i, p), (p, t...</td>\n",
       "      <td>[(s, o, e), (o, e, r), (e, r, i), (r, i, p), (...</td>\n",
       "      <td>[s, o, e, r, i, p, t, o, (s, o), (o, e), (e, r...</td>\n",
       "      <td>[soeripto]</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297478</th>\n",
       "      <td>josé vizcaíno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...</td>\n",
       "      <td>[j, o, s, e,  , v, i, z, c, a, i, n, o]</td>\n",
       "      <td>[(j, o), (o, s), (s, e), (e,  ), ( , v), (v, i...</td>\n",
       "      <td>[(j, o, s), (o, s, e), (s, e,  ), (e,  , v), (...</td>\n",
       "      <td>[(j,), (o,), (s,), (e,), ( ,), (v,), (i,), (z,...</td>\n",
       "      <td>[José, Vizcaíno]</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>José Vizcaíno</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>é, í</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297479</th>\n",
       "      <td>felipe harboe bascuñán</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>[f, e, l, i, p, e,  , h, a, r, b, o, e,  , b, ...</td>\n",
       "      <td>[(f, e), (e, l), (l, i), (i, p), (p, e), (e,  ...</td>\n",
       "      <td>[(f, e, l), (e, l, i), (l, i, p), (i, p, e), (...</td>\n",
       "      <td>[(f,), (e,), (l,), (i,), (p,), (e,), ( ,), (h,...</td>\n",
       "      <td>[Felipe, Harboe, Bascuñán]</td>\n",
       "      <td>22</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873616</td>\n",
       "      <td>0.335940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Felipe Harboe Bascuñán</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>á, ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297480</th>\n",
       "      <td>guillermo lorenzo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[g, u, i, l, l, e, r, m, o,  , l, o, r, e, n, ...</td>\n",
       "      <td>[(g, u), (u, i), (i, l), (l, l), (l, e), (e, r...</td>\n",
       "      <td>[(g, u, i), (u, i, l), (i, l, l), (l, l, e), (...</td>\n",
       "      <td>[(g,), (u,), (i,), (l,), (l,), (e,), (r,), (m,...</td>\n",
       "      <td>[Guillermo, Lorenzo]</td>\n",
       "      <td>17</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726666</td>\n",
       "      <td>0.347654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guillermo Lorenzo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297481</th>\n",
       "      <td>elena ramos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...</td>\n",
       "      <td>[e, l, e, n, a,  , r, a, m, o, s]</td>\n",
       "      <td>[(e, l), (l, e), (e, n), (n, a), (a,  ), ( , r...</td>\n",
       "      <td>[(e, l, e), (l, e, n), (e, n, a), (n, a,  ), (...</td>\n",
       "      <td>[(e,), (l,), (e,), (n,), (a,), ( ,), (r,), (a,...</td>\n",
       "      <td>[Elena, Ramos]</td>\n",
       "      <td>11</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891172</td>\n",
       "      <td>0.318310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elena Ramos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297482</th>\n",
       "      <td>miguel bedoya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>[m, i, g, u, e, l,  , b, e, d, o, y, a]</td>\n",
       "      <td>[(m, i), (i, g), (g, u), (u, e), (e, l), (l,  ...</td>\n",
       "      <td>[(m, i, g), (i, g, u), (g, u, e), (u, e, l), (...</td>\n",
       "      <td>[(m,), (i,), (g,), (u,), (e,), (l,), ( ,), (b,...</td>\n",
       "      <td>[Miguel, Bedoya]</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735488</td>\n",
       "      <td>0.212596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miguel Bedoya</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297483 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fullname original_fullname  \\\n",
       "0                    supriyadi         Supriyadi   \n",
       "1                 triyaningsih      Triyaningsih   \n",
       "2                     soerjadi          Soerjadi   \n",
       "3                    undunsyah         Undunsyah   \n",
       "4                     soeripto          Soeripto   \n",
       "...                        ...               ...   \n",
       "297478           josé vizcaíno               NaN   \n",
       "297479  felipe harboe bascuñán               NaN   \n",
       "297480       guillermo lorenzo               NaN   \n",
       "297481             elena ramos               NaN   \n",
       "297482           miguel bedoya               NaN   \n",
       "\n",
       "                                                 alphabet  \\\n",
       "0       [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "1       [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "2       [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "3       [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "4       [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "...                                                   ...   \n",
       "297478  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...   \n",
       "297479  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "297480  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "297481  [LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...   \n",
       "297482  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "\n",
       "                                                 unigrams  \\\n",
       "0                             [s, u, p, r, i, y, a, d, i]   \n",
       "1                    [t, r, i, y, a, n, i, n, g, s, i, h]   \n",
       "2                                [s, o, e, r, j, a, d, i]   \n",
       "3                             [u, n, d, u, n, s, y, a, h]   \n",
       "4                                [s, o, e, r, i, p, t, o]   \n",
       "...                                                   ...   \n",
       "297478            [j, o, s, e,  , v, i, z, c, a, i, n, o]   \n",
       "297479  [f, e, l, i, p, e,  , h, a, r, b, o, e,  , b, ...   \n",
       "297480  [g, u, i, l, l, e, r, m, o,  , l, o, r, e, n, ...   \n",
       "297481                  [e, l, e, n, a,  , r, a, m, o, s]   \n",
       "297482            [m, i, g, u, e, l,  , b, e, d, o, y, a]   \n",
       "\n",
       "                                                  bigrams  \\\n",
       "0       [(s, u), (u, p), (p, r), (r, i), (i, y), (y, a...   \n",
       "1       [(t, r), (r, i), (i, y), (y, a), (a, n), (n, i...   \n",
       "2       [(s, o), (o, e), (e, r), (r, j), (j, a), (a, d...   \n",
       "3       [(u, n), (n, d), (d, u), (u, n), (n, s), (s, y...   \n",
       "4       [(s, o), (o, e), (e, r), (r, i), (i, p), (p, t...   \n",
       "...                                                   ...   \n",
       "297478  [(j, o), (o, s), (s, e), (e,  ), ( , v), (v, i...   \n",
       "297479  [(f, e), (e, l), (l, i), (i, p), (p, e), (e,  ...   \n",
       "297480  [(g, u), (u, i), (i, l), (l, l), (l, e), (e, r...   \n",
       "297481  [(e, l), (l, e), (e, n), (n, a), (a,  ), ( , r...   \n",
       "297482  [(m, i), (i, g), (g, u), (u, e), (e, l), (l,  ...   \n",
       "\n",
       "                                                 trigrams  \\\n",
       "0       [(s, u, p), (u, p, r), (p, r, i), (r, i, y), (...   \n",
       "1       [(t, r, i), (r, i, y), (i, y, a), (y, a, n), (...   \n",
       "2       [(s, o, e), (o, e, r), (e, r, j), (r, j, a), (...   \n",
       "3       [(u, n, d), (n, d, u), (d, u, n), (u, n, s), (...   \n",
       "4       [(s, o, e), (o, e, r), (e, r, i), (r, i, p), (...   \n",
       "...                                                   ...   \n",
       "297478  [(j, o, s), (o, s, e), (s, e,  ), (e,  , v), (...   \n",
       "297479  [(f, e, l), (e, l, i), (l, i, p), (i, p, e), (...   \n",
       "297480  [(g, u, i), (u, i, l), (i, l, l), (l, l, e), (...   \n",
       "297481  [(e, l, e), (l, e, n), (e, n, a), (n, a,  ), (...   \n",
       "297482  [(m, i, g), (i, g, u), (g, u, e), (u, e, l), (...   \n",
       "\n",
       "                                              char_ngrams  \\\n",
       "0       [s, u, p, r, i, y, a, d, i, (s, u), (u, p), (p...   \n",
       "1       [t, r, i, y, a, n, i, n, g, s, i, h, (t, r), (...   \n",
       "2       [s, o, e, r, j, a, d, i, (s, o), (o, e), (e, r...   \n",
       "3       [u, n, d, u, n, s, y, a, h, (u, n), (n, d), (d...   \n",
       "4       [s, o, e, r, i, p, t, o, (s, o), (o, e), (e, r...   \n",
       "...                                                   ...   \n",
       "297478  [(j,), (o,), (s,), (e,), ( ,), (v,), (i,), (z,...   \n",
       "297479  [(f,), (e,), (l,), (i,), (p,), (e,), ( ,), (h,...   \n",
       "297480  [(g,), (u,), (i,), (l,), (l,), (e,), (r,), (m,...   \n",
       "297481  [(e,), (l,), (e,), (n,), (a,), ( ,), (r,), (a,...   \n",
       "297482  [(m,), (i,), (g,), (u,), (e,), (l,), ( ,), (b,...   \n",
       "\n",
       "                       word_ngrams  name_length  avg_token_length  ...  \\\n",
       "0                      [supriyadi]            9          9.000000  ...   \n",
       "1                   [triyaningsih]           12         12.000000  ...   \n",
       "2                       [soerjadi]            8          8.000000  ...   \n",
       "3                      [undunsyah]            9          9.000000  ...   \n",
       "4                       [soeripto]            8          8.000000  ...   \n",
       "...                            ...          ...               ...  ...   \n",
       "297478            [José, Vizcaíno]           13          6.000000  ...   \n",
       "297479  [Felipe, Harboe, Bascuñán]           22          6.666667  ...   \n",
       "297480        [Guillermo, Lorenzo]           17          8.000000  ...   \n",
       "297481              [Elena, Ramos]           11          5.000000  ...   \n",
       "297482            [Miguel, Bedoya]           13          6.000000  ...   \n",
       "\n",
       "        unigrams_cosine_sim bigrams_cosine_sim  trigrams_cosine_sim  \\\n",
       "0                  0.664809           0.250640             0.085949   \n",
       "1                  0.686625           0.353292             0.117226   \n",
       "2                  0.688312           0.197139             0.090295   \n",
       "3                  0.581396           0.155386             0.060083   \n",
       "4                  0.463215           0.176917             0.052811   \n",
       "...                     ...                ...                  ...   \n",
       "297478             0.743017           0.238011                  NaN   \n",
       "297479             0.873616           0.335940                  NaN   \n",
       "297480             0.726666           0.347654                  NaN   \n",
       "297481             0.891172           0.318310                  NaN   \n",
       "297482             0.735488           0.212596                  NaN   \n",
       "\n",
       "        accent_count    language   id                    name class lang  \\\n",
       "0                  0  Indonesian  NaN                     NaN   NaN  NaN   \n",
       "1                  0  Indonesian  NaN                     NaN   NaN  NaN   \n",
       "2                  0  Indonesian  NaN                     NaN   NaN  NaN   \n",
       "3                  0  Indonesian  NaN                     NaN   NaN  NaN   \n",
       "4                  0  Indonesian  NaN                     NaN   NaN  NaN   \n",
       "...              ...         ...  ...                     ...   ...  ...   \n",
       "297478             2     Spanish  NaN           José Vizcaíno   1.0   es   \n",
       "297479             2     Spanish  NaN  Felipe Harboe Bascuñán   1.0   es   \n",
       "297480             0     Spanish  NaN       Guillermo Lorenzo   1.0   es   \n",
       "297481             0     Spanish  NaN             Elena Ramos   1.0   es   \n",
       "297482             0     Spanish  NaN           Miguel Bedoya   1.0   es   \n",
       "\n",
       "        detected_accents  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "297478              é, í  \n",
       "297479              á, ñ  \n",
       "297480                    \n",
       "297481                    \n",
       "297482                    \n",
       "\n",
       "[297483 rows x 29 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see from output, we need the columns in the concatenated df (in this case, viet) to match\n",
    "# it's okay if some values are NaN bc we'll drop all non-numerical columns anyway\n",
    "merged_df = pd.concat(all_dfs, ignore_index = True, join = 'outer')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding/editing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'APOSTROPHE': 0.00012045910959219644,\n",
       " 'ARABIC': 7.507366603479664e-06,\n",
       " 'BLACK': 2.7299514921744235e-06,\n",
       " 'BULLSEYE': 6.824878730436059e-07,\n",
       " 'CJK': 0.13094144083427317,\n",
       " 'COLON': 3.4124393652180294e-07,\n",
       " 'COMMA': 5.118659047827044e-06,\n",
       " 'COMMERCIAL': 2.3887075556526203e-06,\n",
       " 'CYRILLIC': 6.824878730436059e-07,\n",
       " 'DIGIT': 3.4124393652180294e-07,\n",
       " 'EIGHTH': 6.824878730436059e-07,\n",
       " 'FOR': 3.4124393652180294e-07,\n",
       " 'FULL': 0.0010585386910906328,\n",
       " 'FULLWIDTH': 3.4124393652180294e-06,\n",
       " 'GREEK': 1.0237318095654088e-06,\n",
       " 'HANGUL': 0.010368697011214982,\n",
       " 'HIRAGANA': 0.008231827480715452,\n",
       " 'HORIZONTAL': 3.4124393652180294e-07,\n",
       " 'HYPHEN': 3.4124393652180294e-07,\n",
       " 'HYPHEN-MINUS': 0.003179369756573638,\n",
       " 'IDEOGRAPHIC': 0.0001982627271191675,\n",
       " 'KATAKANA': 0.004038621988735538,\n",
       " 'KATAKANA-HIRAGANA': 0.00022692721778699894,\n",
       " 'LATIN': 0.771624201702466,\n",
       " 'LEFT': 0.00020133392254786372,\n",
       " 'LEFT-TO-RIGHT': 1.0237318095654088e-06,\n",
       " 'MALE': 3.4124393652180294e-07,\n",
       " 'MODIFIER': 2.7299514921744235e-06,\n",
       " 'MULTIPLICATION': 1.0237318095654088e-06,\n",
       " 'NON-BREAKING': 3.4124393652180294e-07,\n",
       " 'QUOTATION': 6.824878730436059e-07,\n",
       " 'RIGHT': 0.0002091825330878652,\n",
       " 'RIGHT-TO-LEFT': 1.7062196826090147e-06,\n",
       " 'SMALL': 3.4124393652180294e-07,\n",
       " 'SOFT': 3.4124393652180294e-07,\n",
       " 'SOLIDUS': 6.824878730436059e-06,\n",
       " 'SPACE': 0.06953527694504778,\n",
       " 'SYRIAC': 7.848610540001468e-06,\n",
       " 'TILDE': 3.4124393652180294e-07,\n",
       " 'VERTICAL': 3.4124393652180294e-07,\n",
       " 'WAVE': 3.753683301739832e-06,\n",
       " 'WHITE': 1.0919805968697694e-05,\n",
       " 'ZERO': 1.3649757460872117e-06}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_fdist = create_lang_char_distribution(merged_df, 'alphabet')\n",
    "print(len(alphabet_fdist))\n",
    "alphabet_fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LATIN': 0.771624201702466,\n",
       " 'CJK': 0.13094144083427317,\n",
       " 'SPACE': 0.06953527694504778,\n",
       " 'HANGUL': 0.010368697011214982,\n",
       " 'HIRAGANA': 0.008231827480715452,\n",
       " 'KATAKANA': 0.004038621988735538,\n",
       " 'HYPHEN-MINUS': 0.003179369756573638,\n",
       " 'FULL': 0.0010585386910906328,\n",
       " 'KATAKANA-HIRAGANA': 0.00022692721778699894,\n",
       " 'RIGHT': 0.0002091825330878652,\n",
       " 'LEFT': 0.00020133392254786372,\n",
       " 'IDEOGRAPHIC': 0.0001982627271191675,\n",
       " 'APOSTROPHE': 0.00012045910959219644,\n",
       " 'WHITE': 1.0919805968697694e-05,\n",
       " 'SYRIAC': 7.848610540001468e-06,\n",
       " 'ARABIC': 7.507366603479664e-06,\n",
       " 'SOLIDUS': 6.824878730436059e-06,\n",
       " 'COMMA': 5.118659047827044e-06,\n",
       " 'WAVE': 3.753683301739832e-06,\n",
       " 'FULLWIDTH': 3.4124393652180294e-06,\n",
       " 'BLACK': 2.7299514921744235e-06,\n",
       " 'MODIFIER': 2.7299514921744235e-06,\n",
       " 'COMMERCIAL': 2.3887075556526203e-06,\n",
       " 'RIGHT-TO-LEFT': 1.7062196826090147e-06,\n",
       " 'ZERO': 1.3649757460872117e-06,\n",
       " 'GREEK': 1.0237318095654088e-06,\n",
       " 'LEFT-TO-RIGHT': 1.0237318095654088e-06,\n",
       " 'MULTIPLICATION': 1.0237318095654088e-06,\n",
       " 'BULLSEYE': 6.824878730436059e-07,\n",
       " 'CYRILLIC': 6.824878730436059e-07,\n",
       " 'EIGHTH': 6.824878730436059e-07,\n",
       " 'QUOTATION': 6.824878730436059e-07,\n",
       " 'COLON': 3.4124393652180294e-07,\n",
       " 'DIGIT': 3.4124393652180294e-07,\n",
       " 'FOR': 3.4124393652180294e-07,\n",
       " 'HORIZONTAL': 3.4124393652180294e-07,\n",
       " 'HYPHEN': 3.4124393652180294e-07,\n",
       " 'MALE': 3.4124393652180294e-07,\n",
       " 'NON-BREAKING': 3.4124393652180294e-07,\n",
       " 'SMALL': 3.4124393652180294e-07,\n",
       " 'SOFT': 3.4124393652180294e-07,\n",
       " 'TILDE': 3.4124393652180294e-07,\n",
       " 'VERTICAL': 3.4124393652180294e-07}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by highest frequency\n",
    "sorted_alpha_fdist = dict(sorted(alphabet_fdist.items(), key = lambda item: item[1], reverse=True))\n",
    "sorted_alpha_fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding number of alphabets in single name\n",
    "def find_number_alphabets(alpha_list):\n",
    "    alpha_set = set()\n",
    "    for alpha_type in alpha_list:\n",
    "        alpha_set.add(alpha_type)\n",
    "    return len(alpha_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['num_alphabets'] = merged_df['alphabet'].apply(find_number_alphabets)\n",
    "merged_df['num_alphabets'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### edit_distance(fullname, transliterated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fullname', 'original_fullname', 'alphabet', 'unigrams', 'bigrams',\n",
       "       'trigrams', 'char_ngrams', 'word_ngrams', 'name_length',\n",
       "       'avg_token_length', 'num_tokens', 'transliteration', 'period_freq',\n",
       "       'dash_freq', 'apostrophe_freq', 'space_freq', 'indiv_unigrams_fdist',\n",
       "       'indiv_bigrams_fdist', 'indiv_trigrams_fdist', 'unigrams_cosine_sim',\n",
       "       'bigrams_cosine_sim', 'trigrams_cosine_sim', 'accent_count', 'language',\n",
       "       'id', 'name', 'class', 'lang', 'detected_accents', 'num_alphabets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(merged_df['fullname'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      supriyadi\n",
       "1                   triyaningsih\n",
       "2                       soerjadi\n",
       "3                      undunsyah\n",
       "4                       soeripto\n",
       "                   ...          \n",
       "297478             josé vizcaíno\n",
       "297479    felipe harboe bascuñán\n",
       "297480         guillermo lorenzo\n",
       "297481               elena ramos\n",
       "297482             miguel bedoya\n",
       "Name: fullname, Length: 297483, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just in case\n",
    "merged_df['fullname'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(merged_df['transliteration'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df['edit_distance'] = merged_df['fullname'].apply(edit_distance())\n",
    "merged_df['edit_distance'] = merged_df.apply(lambda row: edit_distance(row['fullname'], row['transliteration']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>original_fullname</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>char_ngrams</th>\n",
       "      <th>word_ngrams</th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>trigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>lang</th>\n",
       "      <th>detected_accents</th>\n",
       "      <th>num_alphabets</th>\n",
       "      <th>edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297478</th>\n",
       "      <td>josé vizcaíno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...</td>\n",
       "      <td>[j, o, s, e,  , v, i, z, c, a, i, n, o]</td>\n",
       "      <td>[(j, o), (o, s), (s, e), (e,  ), ( , v), (v, i...</td>\n",
       "      <td>[(j, o, s), (o, s, e), (s, e,  ), (e,  , v), (...</td>\n",
       "      <td>[(j,), (o,), (s,), (e,), ( ,), (v,), (i,), (z,...</td>\n",
       "      <td>[José, Vizcaíno]</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>José Vizcaíno</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>é, í</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297479</th>\n",
       "      <td>felipe harboe bascuñán</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>[f, e, l, i, p, e,  , h, a, r, b, o, e,  , b, ...</td>\n",
       "      <td>[(f, e), (e, l), (l, i), (i, p), (p, e), (e,  ...</td>\n",
       "      <td>[(f, e, l), (e, l, i), (l, i, p), (i, p, e), (...</td>\n",
       "      <td>[(f,), (e,), (l,), (i,), (p,), (e,), ( ,), (h,...</td>\n",
       "      <td>[Felipe, Harboe, Bascuñán]</td>\n",
       "      <td>22</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Felipe Harboe Bascuñán</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td>á, ñ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297480</th>\n",
       "      <td>guillermo lorenzo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...</td>\n",
       "      <td>[g, u, i, l, l, e, r, m, o,  , l, o, r, e, n, ...</td>\n",
       "      <td>[(g, u), (u, i), (i, l), (l, l), (l, e), (e, r...</td>\n",
       "      <td>[(g, u, i), (u, i, l), (i, l, l), (l, l, e), (...</td>\n",
       "      <td>[(g,), (u,), (i,), (l,), (l,), (e,), (r,), (m,...</td>\n",
       "      <td>[Guillermo, Lorenzo]</td>\n",
       "      <td>17</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guillermo Lorenzo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297481</th>\n",
       "      <td>elena ramos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...</td>\n",
       "      <td>[e, l, e, n, a,  , r, a, m, o, s]</td>\n",
       "      <td>[(e, l), (l, e), (e, n), (n, a), (a,  ), ( , r...</td>\n",
       "      <td>[(e, l, e), (l, e, n), (e, n, a), (n, a,  ), (...</td>\n",
       "      <td>[(e,), (l,), (e,), (n,), (a,), ( ,), (r,), (a,...</td>\n",
       "      <td>[Elena, Ramos]</td>\n",
       "      <td>11</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elena Ramos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297482</th>\n",
       "      <td>miguel bedoya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...</td>\n",
       "      <td>[m, i, g, u, e, l,  , b, e, d, o, y, a]</td>\n",
       "      <td>[(m, i), (i, g), (g, u), (u, e), (e, l), (l,  ...</td>\n",
       "      <td>[(m, i, g), (i, g, u), (g, u, e), (u, e, l), (...</td>\n",
       "      <td>[(m,), (i,), (g,), (u,), (e,), (l,), ( ,), (b,...</td>\n",
       "      <td>[Miguel, Bedoya]</td>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miguel Bedoya</td>\n",
       "      <td>1.0</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fullname original_fullname  \\\n",
       "297478           josé vizcaíno               NaN   \n",
       "297479  felipe harboe bascuñán               NaN   \n",
       "297480       guillermo lorenzo               NaN   \n",
       "297481             elena ramos               NaN   \n",
       "297482           miguel bedoya               NaN   \n",
       "\n",
       "                                                 alphabet  \\\n",
       "297478  [LATIN, LATIN, LATIN, LATIN, SPACE, LATIN, LAT...   \n",
       "297479  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "297480  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, LAT...   \n",
       "297481  [LATIN, LATIN, LATIN, LATIN, LATIN, SPACE, LAT...   \n",
       "297482  [LATIN, LATIN, LATIN, LATIN, LATIN, LATIN, SPA...   \n",
       "\n",
       "                                                 unigrams  \\\n",
       "297478            [j, o, s, e,  , v, i, z, c, a, i, n, o]   \n",
       "297479  [f, e, l, i, p, e,  , h, a, r, b, o, e,  , b, ...   \n",
       "297480  [g, u, i, l, l, e, r, m, o,  , l, o, r, e, n, ...   \n",
       "297481                  [e, l, e, n, a,  , r, a, m, o, s]   \n",
       "297482            [m, i, g, u, e, l,  , b, e, d, o, y, a]   \n",
       "\n",
       "                                                  bigrams  \\\n",
       "297478  [(j, o), (o, s), (s, e), (e,  ), ( , v), (v, i...   \n",
       "297479  [(f, e), (e, l), (l, i), (i, p), (p, e), (e,  ...   \n",
       "297480  [(g, u), (u, i), (i, l), (l, l), (l, e), (e, r...   \n",
       "297481  [(e, l), (l, e), (e, n), (n, a), (a,  ), ( , r...   \n",
       "297482  [(m, i), (i, g), (g, u), (u, e), (e, l), (l,  ...   \n",
       "\n",
       "                                                 trigrams  \\\n",
       "297478  [(j, o, s), (o, s, e), (s, e,  ), (e,  , v), (...   \n",
       "297479  [(f, e, l), (e, l, i), (l, i, p), (i, p, e), (...   \n",
       "297480  [(g, u, i), (u, i, l), (i, l, l), (l, l, e), (...   \n",
       "297481  [(e, l, e), (l, e, n), (e, n, a), (n, a,  ), (...   \n",
       "297482  [(m, i, g), (i, g, u), (g, u, e), (u, e, l), (...   \n",
       "\n",
       "                                              char_ngrams  \\\n",
       "297478  [(j,), (o,), (s,), (e,), ( ,), (v,), (i,), (z,...   \n",
       "297479  [(f,), (e,), (l,), (i,), (p,), (e,), ( ,), (h,...   \n",
       "297480  [(g,), (u,), (i,), (l,), (l,), (e,), (r,), (m,...   \n",
       "297481  [(e,), (l,), (e,), (n,), (a,), ( ,), (r,), (a,...   \n",
       "297482  [(m,), (i,), (g,), (u,), (e,), (l,), ( ,), (b,...   \n",
       "\n",
       "                       word_ngrams  name_length  avg_token_length  ...  \\\n",
       "297478            [José, Vizcaíno]           13          6.000000  ...   \n",
       "297479  [Felipe, Harboe, Bascuñán]           22          6.666667  ...   \n",
       "297480        [Guillermo, Lorenzo]           17          8.000000  ...   \n",
       "297481              [Elena, Ramos]           11          5.000000  ...   \n",
       "297482            [Miguel, Bedoya]           13          6.000000  ...   \n",
       "\n",
       "        trigrams_cosine_sim accent_count  language   id  \\\n",
       "297478                  NaN            2   Spanish  NaN   \n",
       "297479                  NaN            2   Spanish  NaN   \n",
       "297480                  NaN            0   Spanish  NaN   \n",
       "297481                  NaN            0   Spanish  NaN   \n",
       "297482                  NaN            0   Spanish  NaN   \n",
       "\n",
       "                          name  class lang detected_accents num_alphabets  \\\n",
       "297478           José Vizcaíno    1.0   es             é, í             2   \n",
       "297479  Felipe Harboe Bascuñán    1.0   es             á, ñ             2   \n",
       "297480       Guillermo Lorenzo    1.0   es                              2   \n",
       "297481             Elena Ramos    1.0   es                              2   \n",
       "297482           Miguel Bedoya    1.0   es                              2   \n",
       "\n",
       "        edit_distance  \n",
       "297478              2  \n",
       "297479              2  \n",
       "297480              0  \n",
       "297481              0  \n",
       "297482              0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redoing unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many total unique chars based on our unigrams?\n",
    "# print(merged_df['language'].unique())\n",
    "# unigrams_fdist = create_lang_char_distribution(merged_df, 'unigrams')\n",
    "# len(unigrams_fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigrams_fdist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigrams_fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique characters without transliteration: 172\n"
     ]
    }
   ],
   "source": [
    "# -------------- 1. Language relative frequency distributions --------------\n",
    "\n",
    "# ----- UNIGRAMS -----\n",
    "\n",
    "# Creating the unigrams frequency distribution for all languages\n",
    "unigram_fdist = create_lang_char_distribution(merged_df, 'unigrams')\n",
    "print('# unique characters without transliteration:', len(unigram_fdist))\n",
    "\n",
    "# Initializing all possible bigrams using all possible characters from unigrams frequency distribution\n",
    "# We are reusing this variable\n",
    "# initialized_bigrams = initialize_all_possible_bigrams(unigram_fdist.keys())\n",
    "# len(initialized_bigrams)\n",
    "\n",
    "# ----- BIGRAMS -----\n",
    "\n",
    "# Creating the bigrams frequency distribution for all languages\n",
    "# bigram_fdist = create_lang_gram_distribution(initialized_bigrams, merged_df, 'bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- 2. Individual relative frequency distributions --------------\n",
    "\n",
    "# ----- UNIGRAMS -----\n",
    "\n",
    "initialized_unigrams = {char: 0 for char in unigram_fdist.keys()}\n",
    "\n",
    "# UNIGRAMS individual frequency distributions\n",
    "merged_df['indiv_unigrams_fdist'] = merged_df['unigrams'].apply(lambda grams_list: create_indiv_gram_distribution(grams_list, initialized_unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- BIGRAMS -----\n",
    "\n",
    "# BIGRAMS individual frequency distributions\n",
    "# merged_df['indiv_bigrams_fdist'] = merged_df['bigrams'].apply(lambda grams_list: create_indiv_gram_distribution(grams_list, initialized_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell cannot be run more than once!\n",
    "# Converting fdists to numpy arrays first so we can pass them into cosine_similarity\n",
    "merged_df['indiv_unigrams_fdist'] = merged_df['indiv_unigrams_fdist'].apply(lambda fdist: np.fromiter(fdist.values(), dtype = float).reshape(1, -1))\n",
    "unigram_fdist = np.fromiter(unigram_fdist.values(), dtype = float).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating cosine similarity\n",
    "merged_df['unigrams_cosine_sim'] = merged_df['indiv_unigrams_fdist'].apply(lambda fdist: cosine_similarity(fdist, unigram_fdist)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Keeping numerical columns only for each dataset (Same process as step 4, except we don't have to repeat lines of code...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>class</th>\n",
       "      <th>num_alphabets</th>\n",
       "      <th>edit_distance</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635374</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682779</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661263</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541086</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297478</th>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724969</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297479</th>\n",
       "      <td>22</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775886</td>\n",
       "      <td>0.335940</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297480</th>\n",
       "      <td>17</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556957</td>\n",
       "      <td>0.347654</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297481</th>\n",
       "      <td>11</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730144</td>\n",
       "      <td>0.318310</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297482</th>\n",
       "      <td>13</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.683330</td>\n",
       "      <td>0.212596</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297483 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0                 9          9.000000           1            0          0   \n",
       "1                12         12.000000           1            0          0   \n",
       "2                 8          8.000000           1            0          0   \n",
       "3                 9          9.000000           1            0          0   \n",
       "4                 8          8.000000           1            0          0   \n",
       "...             ...               ...         ...          ...        ...   \n",
       "297478           13          6.000000           2            0          0   \n",
       "297479           22          6.666667           3            0          0   \n",
       "297480           17          8.000000           2            0          0   \n",
       "297481           11          5.000000           2            0          0   \n",
       "297482           13          6.000000           2            0          0   \n",
       "\n",
       "        apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                     0           0             0.635374            0.250640   \n",
       "1                     0           0             0.682779            0.353292   \n",
       "2                     0           0             0.661263            0.197139   \n",
       "3                     0           0             0.558394            0.155386   \n",
       "4                     0           0             0.541086            0.176917   \n",
       "...                 ...         ...                  ...                 ...   \n",
       "297478                0           1             0.724969            0.238011   \n",
       "297479                0           2             0.775886            0.335940   \n",
       "297480                0           1             0.556957            0.347654   \n",
       "297481                0           1             0.730144            0.318310   \n",
       "297482                0           1             0.683330            0.212596   \n",
       "\n",
       "        accent_count  class  num_alphabets  edit_distance    language  \n",
       "0                  0    NaN              1              0  Indonesian  \n",
       "1                  0    NaN              1              0  Indonesian  \n",
       "2                  0    NaN              1              0  Indonesian  \n",
       "3                  0    NaN              1              0  Indonesian  \n",
       "4                  0    NaN              1              0  Indonesian  \n",
       "...              ...    ...            ...            ...         ...  \n",
       "297478             2    1.0              2              2     Spanish  \n",
       "297479             2    1.0              2              2     Spanish  \n",
       "297480             0    1.0              2              0     Spanish  \n",
       "297481             0    1.0              2              0     Spanish  \n",
       "297482             0    1.0              2              0     Spanish  \n",
       "\n",
       "[297483 rows x 14 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col = merged_df['language']\n",
    "merged_df = merged_df.select_dtypes(exclude = 'object')\n",
    "merged_df.drop('trigrams_cosine_sim', inplace = True, axis = 1)\n",
    "merged_df['language'] = label_col\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(labels = ['class'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "      <th>num_alphabets</th>\n",
       "      <th>edit_distance</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635374</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682779</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661263</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541086</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0            9               9.0           1            0          0   \n",
       "1           12              12.0           1            0          0   \n",
       "2            8               8.0           1            0          0   \n",
       "3            9               9.0           1            0          0   \n",
       "4            8               8.0           1            0          0   \n",
       "\n",
       "   apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                0           0             0.635374            0.250640   \n",
       "1                0           0             0.682779            0.353292   \n",
       "2                0           0             0.661263            0.197139   \n",
       "3                0           0             0.558394            0.155386   \n",
       "4                0           0             0.541086            0.176917   \n",
       "\n",
       "   accent_count  num_alphabets  edit_distance    language  \n",
       "0             0              1              0  Indonesian  \n",
       "1             0              1              0  Indonesian  \n",
       "2             0              1              0  Indonesian  \n",
       "3             0              1              0  Indonesian  \n",
       "4             0              1              0  Indonesian  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that there are no null values\n",
    "np.any(merged_df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4247"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate values\n",
    "len(merged_df[merged_df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# dropping duplicates\n",
    "merged_df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "print(np.any(merged_df.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_pickle('merged_df.pkl.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE everything after this: we will be training in individual files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "1. Clean up columns so we can combine dataframes into one (focus on making an all-Latin dataset first)\n",
    "    - do not combine in this step\n",
    "2. Frequency distributions for Latin names -> redo\n",
    "3. Add a_hat_freq\n",
    "4. Only keep numerical columns\n",
    "    - turn some categorical features -> numerical so we have more things to feed into model\n",
    "5. Add in label (language) for each dataset\n",
    "6. Combine Latin and non-Latin names to make one big dataset\n",
    "    - may need to repeat some of the above steps for non-Latin names\n",
    "7. Train test split\n",
    "8. MODEL TRAINING!\n",
    "9. Model evaluation\n",
    "\n",
    "Reminder:\n",
    "- We decided to keep period_freq, dash_freq, apostrophe_freq for now. After our first run of model training, we can remove them to see if it improves the performance\n",
    "\n",
    "**You can work on these steps out of order** (act as if the previous steps r there), but in the end we ideally want all of these steps implemented in this order.\n",
    "\n",
    "For example, you could write the code for model training and train the model on one or a few datasets. Later on, we'll just replace the variables you used with the ones containing all the languages/names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    name  class lang\n",
      "0                The Canal of the Angels      0   en\n",
      "1                      Rescue Renovation      0   en\n",
      "2       Agatha Christie: The ABC Murders      0   en\n",
      "3                            Siti Akbari      0   ar\n",
      "4                                  Stany      0   pl\n",
      "...                                  ...    ...  ...\n",
      "199995                   Robber's Bridge      0   en\n",
      "199996                       Johan Renck      0   en\n",
      "199997                      Lyle Stewart      1   en\n",
      "199998           Thomas Colclough Watson      1   en\n",
      "199999                              Gavà      0   ca\n",
      "\n",
      "[200000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#can replace file names later\n",
    "filename = os.path.join(os.getcwd(), \"company_person_name_dataset.csv\")\n",
    "#filename = os.path.join(os.getcwd(), \"Name_Of_Origin_Project-\", \"company_person_name_dataset.csv\")\n",
    "df = pd.read_csv(filename, header=0)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name_length', 'avg_token_length', 'num_tokens', 'period_freq',\n",
      "       'dash_freq', 'apostrophe_freq', 'space_freq', 'unigrams_cosine_sim',\n",
      "       'bigrams_cosine_sim', 'accent_count', 'language'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_length</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>period_freq</th>\n",
       "      <th>dash_freq</th>\n",
       "      <th>apostrophe_freq</th>\n",
       "      <th>space_freq</th>\n",
       "      <th>unigrams_cosine_sim</th>\n",
       "      <th>bigrams_cosine_sim</th>\n",
       "      <th>accent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.664809</td>\n",
       "      <td>0.250640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686625</td>\n",
       "      <td>0.353292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.197139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.155386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_length  avg_token_length  num_tokens  period_freq  dash_freq  \\\n",
       "0            9               9.0           1            0          0   \n",
       "1           12              12.0           1            0          0   \n",
       "2            8               8.0           1            0          0   \n",
       "3            9               9.0           1            0          0   \n",
       "4            8               8.0           1            0          0   \n",
       "\n",
       "   apostrophe_freq  space_freq  unigrams_cosine_sim  bigrams_cosine_sim  \\\n",
       "0                0           0             0.664809            0.250640   \n",
       "1                0           0             0.686625            0.353292   \n",
       "2                0           0             0.688312            0.197139   \n",
       "3                0           0             0.581396            0.155386   \n",
       "4                0           0             0.463215            0.176917   \n",
       "\n",
       "   accent_count  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = merged_df['language']\n",
    "print(merged_df.columns)\n",
    "\n",
    "X = merged_df.drop(columns = 'language', axis = 1) # oops this code is a bit redundant with before but its ok\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training - Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb Cell 76\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid_search_rf \u001b[39m=\u001b[39m GridSearchCV(rf_classifier, param_grid\u001b[39m=\u001b[39mparam_grid_rf, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stefh/Documents/bttai/exiger/project_repo/DataConsolidation.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid_search_rf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/bttai/exiger/project_repo/.conda/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(rf_classifier, param_grid=param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_rf_model = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest model on the test set\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8428922708845618\n",
      "Random Forest Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Chinese (Characters)       0.79      0.88      0.83      2211\n",
      " Chinese (Romanized)       0.68      0.75      0.72      2096\n",
      "          Indonesian       0.73      0.80      0.76      2249\n",
      "              Korean       0.94      0.91      0.93      3844\n",
      "               Malay       0.55      0.23      0.33       582\n",
      "             Turkish       1.00      0.99      1.00      3607\n",
      "          Vietnamese       0.56      0.33      0.42       458\n",
      "\n",
      "            accuracy                           0.84     15047\n",
      "           macro avg       0.75      0.70      0.71     15047\n",
      "        weighted avg       0.84      0.84      0.84     15047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training - SVM\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid=param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_svm_model = grid_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the SVM model on the test set\n",
    "svm_predictions = best_svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will leave this commented for now\n",
    "# randomizing data - idk if this is correct or necessary?\n",
    "# X, y = shuffle(X, y)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change test data size\n",
    "# changed: 0.10 -> 0.30\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 1234) \n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline with a TfidfVectorizer and Multinomial Naive Bayes classifier\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()) # we want this probably\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid_nb = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'clf__alpha': (1e-2, 1e-3, 1e-4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_nb = GridSearchCV(pipeline_nb, param_grid_nb, cv = 5, n_jobs = -1)\n",
    "grid_search_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_nb_model = grid_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and best score\n",
    "# not in the other code parts but its ok\n",
    "print(\"Best Parameters: \", grid_search_nb.best_params_)\n",
    "print(\"Best Score: \", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = grid_search_nb.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "\n",
    "print(\"NB Accuracy:\", svm_accuracy)\n",
    "print(\"NB Classification Report:\")\n",
    "print(classification_report(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, SVM, RNNs, Naive Bayes\n",
    "\n",
    "use gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "# rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 20)\n",
    "# rf.fit(X_train, y_train)\n",
    "# rf_predictions = list(rf_20_model.predict_proba(X_test)[:,1])\n",
    "# in ML foundations we used ROC and AUC to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there r multiple types of support vector machines\n",
    "# not sure if this is correct\n",
    "# svc = svm.SVC()\n",
    "# svc.fit(X_train, y_train)\n",
    "# svc_predictions = svc.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNs - not sure if this is correct\n",
    "# mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, ... hidden_layer_sizes=(5, 2), random_state=1)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# mlp_predictions = mlp.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes - there r diff types\n",
    "# this is multinomialNB, is said to be used for text classification\n",
    "# mn_nb = MultinomialNB(force_alpha=True) # idk\n",
    "# mn_nb.fit(X_train, y_train)\n",
    "# mn_nb_predictions = mn_nb.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation: precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score\n",
    "# need multiple cells, one for each evaluation\n",
    "# rf_f1 = f1_score(y_test, rf_predictions, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
